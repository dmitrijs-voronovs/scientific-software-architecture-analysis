id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2436:3237,safety,error,error,3237,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3274,safety,log,logging,3274,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3274,security,log,logging,3274,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:935,testability,Trace,Traceback,935,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3274,testability,log,logging,3274,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:152,usability,confirm,confirmed,152,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:235,usability,confirm,confirmed,235,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:326,usability,guid,guide,326,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:381,usability,minim,minimal-bug-reports,381,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:487,usability,Minim,Minimal,487,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:752,usability,user,user-images,752,"scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'; - [ yes] I have checked that this issue has not already been reported. - [ yes] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). ```. ```pytb. ![Screenshot 2023-03-05 at 18 18 05](https://user-images.githubusercontent.com/22848603/222991823-36da6d04-44ca-4504-a030-b2b4256bfa9c.png). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_1797574/3779544909.py in <module>. ----> 1 sce.pp.mnn_correct(adata_ref_batch0, adata_ref_batch1, adata_ref_batch2, batch_categories = ['batch0', 'batch1', 'batch2']). /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/scanpy/external/pp/_mnn_correct.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2436:3237,usability,error,error,3237,", svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 133 . 134 n_jobs = settings.n_jobs if n_jobs is None else n_jobs. --> 135 datas, mnn_list, angle_list = mnn_correct(. 136 *datas,. 137 var_index=var_index,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 120 if var_subset is not None and set(adata_vars) == set(var_subset):. 121 var_subset = None. --> 122 corrected = mnn_correct(*(adata.X for adata in datas), var_index=adata_vars,. 123 var_subset=var_subset, k=k, sigma=sigma, cos_norm_in=cos_norm_in,. 124 cos_norm_out=cos_norm_out, svd_dim=svd_dim, var_adj=var_adj,. /mnt/md0/jin/anaconda3/lib/python3.9/site-packages/mnnpy/mnn.py in mnn_correct(var_index, var_subset, batch_key, index_unique, batch_categories, k, sigma, cos_norm_in, cos_norm_out, svd_dim, var_adj, compute_angle, mnn_order, svd_mode, do_concatenate, save_raw, n_jobs, *datas, **kwargs). 176 new_batch_out = out_batches[target]. 177 print(' Looking for MNNs...'). --> 178 mnn_ref, mnn_new = find_mutual_nn(data1=ref_batch_in, data2=new_batch_in, k1=k, k2=k,. 179 n_jobs=n_jobs). 180 print(' Computing correction vectors...'). _ckdtree.pyx in scipy.spatial._ckdtree.cKDTree.query(). _ckdtree.pyx in scipy.spatial._ckdtree.get_num_workers(). TypeError: Unexpected keyword argument {'n_jobs': 48}. ---------------------------------------------------------------------------. ```. #### Versions. python 3.9. <details>. The function scanpy.external.pp.mnn_correct has a n_jobs for the argument, but scipy.spatial.sKDTree does not have a keyword argument 'n_jobs'. I think you should remove it. It keeps showing an error. . [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2436
https://github.com/scverse/scanpy/issues/2438:86,availability,error,error,86,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:224,deployability,modul,module,224,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:315,deployability,modul,module,315,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:450,deployability,modul,module,450,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:605,deployability,modul,module,605,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:92,integrability,messag,message,92,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:92,interoperability,messag,message,92,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:224,modifiability,modul,module,224,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:273,modifiability,pac,packages,273,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:315,modifiability,modul,module,315,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:400,modifiability,pac,packages,400,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:450,modifiability,modul,module,450,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:545,modifiability,pac,packages,545,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:605,modifiability,modul,module,605,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:86,performance,error,error,86,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:86,safety,error,error,86,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:224,safety,modul,module,224,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:315,safety,modul,module,315,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:450,safety,modul,module,450,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:605,safety,modul,module,605,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:160,testability,Trace,Traceback,160,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:86,usability,error,error,86,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2438:872,usability,help,help,872,"Cannot import scanpy due to numba issues; Hello, I am unable to import scanpy and the error message shows below:. ```python. import scanpy as sc. ```. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 6, in <module>. from ._utils import check_versions. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/__init__.py"", line 29, in <module>. from .compute.is_constant import is_constant. File ""/opt/anaconda3/lib/python3.9/site-packages/scanpy/_utils/compute/is_constant.py"", line 5, in <module>. from numba import njit. ImportError: cannot import name 'njit' from 'numba' (unknown location)```. ```. Scanpy has been working well, but today it reports an issue. I have tried to uninstall and reinstall numba and scanpy, but it still did not work. Can you help? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2438
https://github.com/scverse/scanpy/issues/2439:282,availability,cluster,cluster,282,"Dotplot for merged group of genes ; Hello,. I was wondering how I could make a dot plot where instead of showing single genes on the x axis, I could show a one group at time of merged group of genes (i.e. markers for a cell type merged as 1 list) and its average expression in each cluster. Something like on the diagram below:. ![IMG_8599](https://user-images.githubusercontent.com/99988924/223526039-7fa72170-fe6e-475b-9f8c-2391e19c8825.JPG). Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2439
https://github.com/scverse/scanpy/issues/2439:282,deployability,cluster,cluster,282,"Dotplot for merged group of genes ; Hello,. I was wondering how I could make a dot plot where instead of showing single genes on the x axis, I could show a one group at time of merged group of genes (i.e. markers for a cell type merged as 1 list) and its average expression in each cluster. Something like on the diagram below:. ![IMG_8599](https://user-images.githubusercontent.com/99988924/223526039-7fa72170-fe6e-475b-9f8c-2391e19c8825.JPG). Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2439
https://github.com/scverse/scanpy/issues/2439:169,performance,time,time,169,"Dotplot for merged group of genes ; Hello,. I was wondering how I could make a dot plot where instead of showing single genes on the x axis, I could show a one group at time of merged group of genes (i.e. markers for a cell type merged as 1 list) and its average expression in each cluster. Something like on the diagram below:. ![IMG_8599](https://user-images.githubusercontent.com/99988924/223526039-7fa72170-fe6e-475b-9f8c-2391e19c8825.JPG). Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2439
https://github.com/scverse/scanpy/issues/2439:349,usability,user,user-images,349,"Dotplot for merged group of genes ; Hello,. I was wondering how I could make a dot plot where instead of showing single genes on the x axis, I could show a one group at time of merged group of genes (i.e. markers for a cell type merged as 1 list) and its average expression in each cluster. Something like on the diagram below:. ![IMG_8599](https://user-images.githubusercontent.com/99988924/223526039-7fa72170-fe6e-475b-9f8c-2391e19c8825.JPG). Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2439
https://github.com/scverse/scanpy/issues/2440:159,deployability,version,version,159,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1148,deployability,modul,module,1148," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1635,deployability,log,logreg,1635," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1942,deployability,log,log,1942," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2014,deployability,Version,Versions,2014," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2063,deployability,log,logging,2063," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:159,integrability,version,version,159,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2014,integrability,Version,Versions,2014," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:159,modifiability,version,version,159,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1148,modifiability,modul,module,1148," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1260,modifiability,pac,packages,1260," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1446,modifiability,layer,layer,1446," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1555,modifiability,layer,layer,1555," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1675,modifiability,pac,packages,1675," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1781,modifiability,layer,layer,1781," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2014,modifiability,Version,Versions,2014," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:872,safety,test,test,872,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:901,safety,test,test,901,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1122,safety,input,input-,1122,"med this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1148,safety,modul,module,1148," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1635,safety,log,logreg,1635," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1942,safety,log,log,1942," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2063,safety,log,logging,2063," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1635,security,log,logreg,1635," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1942,security,log,log,1942," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2063,security,log,logging,2063," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:872,testability,test,test,872,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:901,testability,test,test,901,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1078,testability,Trace,Traceback,1078,"already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1635,testability,log,logreg,1635," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1942,testability,log,log,1942," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:2063,testability,log,logging,2063," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:119,usability,confirm,confirmed,119,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:202,usability,confirm,confirmed,202,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:293,usability,guid,guide,293,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:348,usability,minim,minimal-bug-reports,348,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:454,usability,Minim,Minimal,454,"read harmonypy data can not find deg; - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'bas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1122,usability,input,input-,1122,"med this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1276,usability,tool,tools,1276," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2440:1691,usability,tool,tools,1691," on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import harmonypy as hm. h_data = hm.run_harmony(a_data.obsm['X_pca'], a_data.obs, ['donor']). har= h_data.Z_corr. har = har.T. a_data.obsm['X_harmony'] = har.copy(). sc.pp.neighbors(a_data, n_neighbors=30, n_pcs=50,use_rep='X_harmony'). res = 1. sc.tl.leiden(a_data,resolution=res,key_added = 'leiden_res_harmony%.2f'%res). a_data.write(test.h5ad). a_data = sc.read(test.h5ad). sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-6-8d70f4e1a0fa> in <module>. ----> 1 sc.tl.rank_genes_groups(a_data, 'condition', method='wilcoxon'). /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, tie_correct, layer, **kwds). 588 ). 589 . --> 590 test_obj = _RankGenes(adata, groups_order, groupby, reference, use_raw, layer, pts). 591 . 592 if check_nonnegative_integers(test_obj.X) and method != 'logreg':. /opt/conda/lib/python3.8/site-packages/scanpy/tools/_rank_genes_groups.py in __init__(self, adata, groups, groupby, reference, use_raw, layer, comp_pts). 91 ):. 92 . ---> 93 if 'log1p' in adata.uns_keys() and adata.uns['log1p']['base'] is not None:. 94 self.expm1_func = lambda x: np.expm1(x * np.log(adata.uns['log1p']['base'])). 95 else:. KeyError: 'base'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2440
https://github.com/scverse/scanpy/issues/2441:146,deployability,version,version,146,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:317,deployability,instal,install,317,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:349,deployability,instal,install,349,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:425,deployability,instal,installed,425,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1303,deployability,instal,install,1303,": ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1335,deployability,instal,install,1335," via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1427,deployability,modul,module,1427,"lled. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1527,deployability,modul,module,1527,"uecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1767,deployability,Version,Versions,1767," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2685,deployability,log,logical,2685," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2693,energy efficiency,CPU,CPU,2693," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2697,energy efficiency,core,cores,2697," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:146,integrability,version,version,146,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1767,integrability,Version,Versions,1767," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:146,modifiability,version,version,146,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:332,modifiability,pac,package,332,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:958,modifiability,pac,packages,958,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1159,modifiability,pac,packages,1159,". - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1318,modifiability,pac,package,1318,"ll skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1427,modifiability,modul,module,1427,"lled. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1478,modifiability,pac,packages,1478,"ttps://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1527,modifiability,modul,module,1527,"uecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1656,modifiability,pac,packages,1656," ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1767,modifiability,Version,Versions,1767," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2264,modifiability,pac,packaging,2264," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2559,modifiability,pac,packaged,2559," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2693,performance,CPU,CPU,2693," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:609,reliability,Doe,Does,609,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1427,safety,modul,module,1427,"lled. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1527,safety,modul,module,1527,"uecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yam",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2685,safety,log,logical,2685," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2685,security,log,logical,2685," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1363,testability,Trace,Traceback,1363,"it-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:2685,testability,log,logical,2685," any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing 3.0.9. pytz 2022.7.1. scanpy 1.8.2. scipy 1.8.0. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. skmisc 0.1.4. tables 3.6.1. threadpoolctl 3.1.0. typing_extensions NA. yaml 6.0. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-3.10.0-1127.el7.x86_64-x86_64-with-glibc2.17. 8 logical CPU cores, x86_64. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:106,usability,confirm,confirmed,106,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:189,usability,confirm,confirmed,189,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:359,usability,user,user,359,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:665,usability,Minim,Minimal,665,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:914,usability,USER,USER,914,"cannot read file data; - [ y] I have checked that this issue has not already been reported. - [ y] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1115,usability,USER,USER,1115,"his bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi all, . I encountered a problem that it keeps saying : ""Please install skmisc package via `pip install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2441:1345,usability,user,user,1345,"p install --user scikit-misc"", but I have checked pip/conda and it is already installed. . I followed the instructions here:. [#2073](https://github.com/scverse/scanpy/issues/2073#issuecomment-996270340). checked the ouput of ""from skmisc.loess import loess"". . Does anyone know how to solve this problem? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. from skmisc.loess import loess. ```. ```pytb. sc.pp.highly_variable_genes(all_exp_merged_bins_ad, n_top_genes=2000, flavor='seurat_v3', span=1.0). File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 419, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""/ldfssz1/ST_BI/USER/ywu/.conda/envs/scs/lib/python3.9/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. ImportError: /home/wyu/.local/lib/python3.9/site-packages/skmisc/loess/../../scikit_misc.libs/libopenblasp-r0-085ca80a.3.9.so: cannot read file data. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.5. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 9.4.0. anndata 0.7.5. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. defusedxml 0.7.1. google NA. h5py 3.8.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.5.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. numba 0.56.4. numexpr 2.8.3. numpy 1.22.4. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyexpat NA. pyparsing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2441
https://github.com/scverse/scanpy/issues/2442:124,availability,cluster,cluster,124,"Regress_out function sets means of genes to zero; I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me? _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442
https://github.com/scverse/scanpy/issues/2442:350,availability,reliab,reliably,350,"Regress_out function sets means of genes to zero; I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me? _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442
https://github.com/scverse/scanpy/issues/2442:124,deployability,cluster,cluster,124,"Regress_out function sets means of genes to zero; I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me? _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442
https://github.com/scverse/scanpy/issues/2442:120,integrability,sub,sub-cluster,120,"Regress_out function sets means of genes to zero; I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me? _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442
https://github.com/scverse/scanpy/issues/2442:350,reliability,reliab,reliably,350,"Regress_out function sets means of genes to zero; I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me? _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442
https://github.com/scverse/scanpy/issues/2442:391,usability,close,closed,391,"Regress_out function sets means of genes to zero; I want to use the regress_out function, analyse my data set, and then sub-cluster (for which I want to run highly_variable_genes again). However, this is not possible as the regress_out function removes the offset and therefore sets the means of genes to zero, so then the hvg function cannot be run reliably (see previous issue). I found a closed issue mentioning this problem and suggesting to ''add the offset again'. However I do not know how to do this. Could someone explain it to me? _Originally posted by @VivianeSchulz in https://github.com/scverse/scanpy/issues/707#issuecomment-1446770111_.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2442
https://github.com/scverse/scanpy/issues/2443:370,availability,error,error,370,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:386,availability,error,error,386,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:564,availability,error,error,564,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:860,availability,error,error,860,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:161,deployability,version,version,161,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:610,deployability,version,version,610,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:725,deployability,version,versions,725,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1040,deployability,Version,Versions,1040,"] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1423,energy efficiency,cloud,cloudpickle,1423,"r which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:161,integrability,version,version,161,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:610,integrability,version,version,610,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:725,integrability,version,versions,725,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1040,integrability,Version,Versions,1040,"] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:3248,integrability,wrap,wrapt,3248,"e NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.3. requests 2.25.1. rpy2 3.4.2. ruamel NA. scanorama 1.7.1. scipy 1.6.2. scrublet NA. scvelo 0.2.5. seaborn 0.11.1. send2trash NA. session_info 1.0.0. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sparse 0.13.0. sphinxcontrib NA. stack_data 0.1.4. statsmodels 0.12.2. tblib 1.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 20.0.0. zope NA. -----. IPython 8.0.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:161,modifiability,version,version,161,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:602,modifiability,pac,package,602,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:610,modifiability,version,version,610,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:690,modifiability,pac,packages,690,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:725,modifiability,version,versions,725,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1040,modifiability,Version,Versions,1040,"] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1575,modifiability,deco,decorator,1575,"eve it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:2280,modifiability,pac,packaging,2280,backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.3. requests 2.25.1. rpy2 3.4.2. ruamel NA. scanorama 1.7.1. scipy 1.6.2. scrublet NA. scvelo 0.2.5. seaborn 0.11.1. send2trash NA. session_info 1.0.0. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sparse 0.13.0. sphinxcontrib NA. stack_data 0.1.4. statsmodels 0.12.2. tblib 1.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zipp NA. zm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:370,performance,error,error,370,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:386,performance,error,error,386,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:564,performance,error,error,564,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:860,performance,error,error,860,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1346,performance,bottleneck,bottleneck,1346,"oom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:490,reliability,doe,does,490,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:370,safety,error,error,370,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:386,safety,error,error,386,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:564,safety,error,error,564,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:860,safety,error,error,860,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1375,security,certif,certifi,1375,"de and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:1458,security,cryptograph,cryptography,1458,"ked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pure_eval 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:2923,security,soc,socks,2923,"e NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.3. requests 2.25.1. rpy2 3.4.2. ruamel NA. scanorama 1.7.1. scipy 1.6.2. scrublet NA. scvelo 0.2.5. seaborn 0.11.1. send2trash NA. session_info 1.0.0. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sparse 0.13.0. sphinxcontrib NA. stack_data 0.1.4. statsmodels 0.12.2. tblib 1.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 20.0.0. zope NA. -----. IPython 8.0.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:121,usability,confirm,confirmed,121,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:204,usability,confirm,confirmed,204,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:370,usability,error,error,370,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:386,usability,error,error,386,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:442,usability,command,command,442,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:564,usability,error,error,564,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:760,usability,help,help,760,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:860,usability,error,error,860,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:938,usability,user,user-images,938,"Problems with scv.utils.merge function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. I am trying to run a velocity analysis, however whenever I try to merge my data with my loom files I get an error (code and error attached). I've tried it on a file for which this command previously worked (but now it no longer does) as well as trying to merge two loom files, which also gives me this error. So I believe it's to do with a package version rather than the files themselves, but I cannot seem to figure out which packages are responsible and which versions I would need instead. Any help would be greatly appreciated! My code:. adata_vel = scv.utils.merge(adata, adatal). This is my error:. <img width=""844"" alt=""Screenshot 2023-03-09 at 11 43 11"" src=""https://user-images.githubusercontent.com/85882727/224000508-fb6a0e9a-c49d-4186-a531-88233f3cfc82.png"">. #### Versions. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 20.0.1. PIL 8.2.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. anndata2ri 1.0.6. annoy NA. anyio NA. appnope 0.1.2. asttokens NA. astunparse 1.6.3. attr 21.4.0. babel 2.9.0. backcall 0.2.0. backports NA. boto3 1.26.7. botocore 1.29.7. bottleneck 1.3.2. brotli NA. certifi 2020.12.05. cffi 1.14.6. chardet 4.0.0. cloudpickle 1.6.0. colorama 0.4.4. cryptography 3.4.7. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2443:3127,usability,tool,toolz,3127,"e NA. cytoolz 0.11.0. dask 2021.04.0. dateutil 2.8.1. debugpy 1.5.1. decorator 5.0.6. dot_parser NA. dunamai 1.6.0. executing 0.8.2. fbpca NA. flatbuffers NA. fsspec 0.7.4. gast 0.5.3. get_version 3.5. google NA. gprofiler 1.0.0. h5py 3.7.0. idna 2.10. igraph 0.10.2. importlib_resources NA. intervaltree NA. ipykernel 6.8.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.17.2. jinja2 3.0.2. jmespath 1.0.1. joblib 1.0.1. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.4.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.3.1. leidenalg 0.7.0. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.7.1. matplotlib_inline NA. mpl_toolkits NA. natsort 7.1.1. nbclassic NA. nbformat 5.1.3. numba 0.53.1. numpy 1.22.0. opt_einsum v3.3.0. packaging 20.9. pandas 1.2.5. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.17. psutil 5.8.0. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.8.1. pynndescent 0.5.4. pyparsing 2.4.7. pyrsistent NA. pytz 2021.3. requests 2.25.1. rpy2 3.4.2. ruamel NA. scanorama 1.7.1. scipy 1.6.2. scrublet NA. scvelo 0.2.5. seaborn 0.11.1. send2trash NA. session_info 1.0.0. six 1.15.0. sklearn 0.24.1. sniffio 1.2.0. socks 1.7.1. sortedcontainers 2.3.0. sparse 0.13.0. sphinxcontrib NA. stack_data 0.1.4. statsmodels 0.12.2. tblib 1.7.0. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.1. urllib3 1.26.4. wcwidth 0.2.5. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 20.0.0. zope NA. -----. IPython 8.0.1. jupyter_client 6.1.12. jupyter_core 4.7.1. jupyterlab 3.0.14. notebook 6.3.0. -----. Python 3.8.8 (default, Apr 13 2021, 12:59:45) [Clang 10.0.0 ]. macOS-10.15.7-x86_64-i386-64bit.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2443
https://github.com/scverse/scanpy/issues/2444:11,deployability,Integr,Integrate,11,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:541,deployability,version,version,541,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1143,deployability,API,API,1143,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1217,deployability,API,API,1217,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1402,deployability,API,API,1402,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:365,energy efficiency,Heat,Heatgraphy,365,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:396,energy efficiency,Heat,Heatgraphy,396,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:407,energy efficiency,heat,heatgraphy,407,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:572,energy efficiency,Heat,Heatgraphy,572,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:621,energy efficiency,Heat,Heatgraphy,621,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:705,energy efficiency,heat,heatgraphy,705,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:818,energy efficiency,Heat,Heatgraphy,818,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:936,energy efficiency,heat,heatmap,936,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1029,energy efficiency,heat,heatgraphy,1029,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1153,energy efficiency,Heat,Heatgraphy,1153,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1259,energy efficiency,heat,heatgraphy,1259,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:11,integrability,Integr,Integrate,11,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:541,integrability,version,version,541,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1143,integrability,API,API,1143,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1217,integrability,API,API,1217,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1402,integrability,API,API,1402,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:11,interoperability,Integr,Integrate,11,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1143,interoperability,API,API,1143,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1217,interoperability,API,API,1217,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1402,interoperability,API,API,1402,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1716,interoperability,specif,specific,1716,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:11,modifiability,Integr,Integrate,11,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:175,modifiability,pac,package,175,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:438,modifiability,pac,package,438,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:541,modifiability,version,version,541,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:11,reliability,Integr,Integrate,11,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:552,safety,compl,complexHeatmap,552,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:11,security,Integr,Integrate,11,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:552,security,compl,complexHeatmap,552,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:11,testability,Integr,Integrate,11,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:33,usability,visual,visualize,33,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:144,usability,tool,tools,144,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:315,usability,help,helps,315,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:449,usability,visual,visualize,449,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:601,usability,Person,Personally,601,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:636,usability,help,help,636,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:641,usability,visual,visualize,641,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:663,usability,intuit,intuitively,663,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:776,usability,visual,visualization,776,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:882,usability,visual,visualization,882,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1167,usability,help,help,1167,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1172,usability,visual,visualize,1172,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1447,usability,custom,customization,1447,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2444:1725,usability,visual,visualization,1725,"[Proposal] Integrate Marsilea to visualize AnnData; - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? Hi, thanks for developing such a fantastic framework for analyzing single-cell data, it really helps a lot in my research. I'm the developer of [Heatgraphy](https://github.com/Heatgraphy/heatgraphy), which is a python package to visualize multi-dimensional data using the x-layout system. You may think of it as python's version of complexHeatmap, but Heatgraphy can do much more. Personally, I think Heatgraphy can help visualize the AnnData intuitively. Here is [an example](https://heatgraphy.readthedocs.io/en/latest/auto_examples/plot_pbmc3k.html) of visualization of the PBMC3K dataset using Heatgraphy. The structure of AnnData fits the structure of this visualization quite well. We can plot the `.X` as the heatmap, and other attributes in `.obs`/`.var` or `.obsm`/`.varm` as side plots. ![](https://heatgraphy.readthedocs.io/en/latest/_images/sphx_glr_plot_pbmc3k_001_2_0x.png). Therefore, I propose adding a new API using Heatgraphy to help visualize AnnData. If adding to `sc.pl`, the API may look like this:. ```python. sc.pl.heatgraphy(adata, left=[(""cell_type"", ""color""), (""cell_type"", ""label"")], right=[(""gene_name"", ""label"")]). ```. If added as an extra class, the API can be more flexible and offer much more customization. It may look like this:. ```python. viz = AnnDataViz(adata). viz.add_left(key=""cell_type"", plot=""color"", cmap=""Set2"") # use a key from .obs and plot as color strip. viz.add_left(key=""cell_type"", plot=""label""). viz.render(). ```. It can also be applied to specific visualization for analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2444
https://github.com/scverse/scanpy/issues/2445:1496,availability,error,error,1496,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:266,deployability,modul,module,266,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:364,deployability,modul,module,364,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:500,deployability,modul,module,500,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:632,deployability,modul,module,632,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:759,deployability,modul,module,759,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1077,deployability,version,version,1077,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1553,deployability,Version,Versions,1553,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1602,deployability,log,logging,1602,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:798,integrability,Sub,SubplotBase,798,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:905,integrability,sub,subclass,905,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1077,integrability,version,version,1077,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1553,integrability,Version,Versions,1553,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:10,interoperability,conflict,conflict,10,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:839,interoperability,conflict,conflict,839,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:266,modifiability,modul,module,266,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:321,modifiability,pac,packages,321,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:364,modifiability,modul,module,364,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:449,modifiability,pac,packages,449,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:500,modifiability,modul,module,500,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:580,modifiability,pac,packages,580,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:632,modifiability,modul,module,632,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:709,modifiability,pac,packages,709,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:759,modifiability,modul,module,759,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1077,modifiability,version,version,1077,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1553,modifiability,Version,Versions,1553,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1496,performance,error,error,1496,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:266,safety,modul,module,266,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:364,safety,modul,module,364,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:500,safety,modul,module,500,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:632,safety,modul,module,632,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:759,safety,modul,module,759,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1496,safety,error,error,1496,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1602,safety,log,logging,1602,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1602,security,log,logging,1602,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:202,testability,Trace,Traceback,202,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1602,testability,log,logging,1602,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:118,usability,help,help,118,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:287,usability,user,user,287,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:415,usability,user,user,415,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:546,usability,user,user,546,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:675,usability,user,user,675,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1037,usability,confirm,confirmed,1037,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1120,usability,confirm,confirmed,1120,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1211,usability,guid,guide,1211,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1266,usability,minim,minimal-bug-reports,1266,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1372,usability,Minim,Minimal,1372,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2445:1496,usability,error,error,1496,"metaclass conflict; ```. Python 3.9.15 (main, Nov 24 2022, 14:31:59) . [GCC 11.2.0] :: Anaconda, Inc. on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/__init__.py"", line 16, in <module>. from . import plotting as pl. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/__init__.py"", line 1, in <module>. from ._anndata import (. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py"", line 28, in <module>. from . import _utils. File ""/home/user/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ```. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. ```pytb. [Paste the error output produced by the above code here]. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2445
https://github.com/scverse/scanpy/issues/2446:90,deployability,pipelin,pipelines,90,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:287,deployability,version,version,287,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:446,deployability,version,versions,446,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:90,integrability,pipelin,pipelines,90,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:287,integrability,version,version,287,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:446,integrability,version,versions,446,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:287,modifiability,version,version,287,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:446,modifiability,version,versions,446,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:14,usability,support,support,14,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:117,usability,learn,learn,117,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/issues/2446:384,usability,support,support,384,"Azure removes support for Ubuntu 18; https://github.com/scverse/scanpy/blob/master/.azure-pipelines.yml#L14. https://learn.microsoft.com/en-us/answers/questions/1181262/what-happens-to-azure-vms-with-ubuntu-18-04-lts-af. and our CI already cries about it. Let's up this to a more recent version, maybe even 22.04? While we're at it, I'd also remove 3.7 from the CI because it'll lose support very soon. We could add one of the more recent Python versions instead.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2446
https://github.com/scverse/scanpy/pull/2447:16,deployability,version,version,16,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/pull/2447:33,deployability,version,version,33,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/pull/2447:16,integrability,version,version,16,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/pull/2447:33,integrability,version,version,33,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/pull/2447:16,modifiability,version,version,16,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/pull/2447:33,modifiability,version,version,33,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/pull/2447:174,performance,time,time,174,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/pull/2447:147,usability,support,supported,147,Increase ubuntu version & python version for azure CI; Fixes #2446 . Python 3.7 is EOL in 3 months https://endoflife.date/python and Pandas hasn't supported it for a loooong time already.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2447
https://github.com/scverse/scanpy/issues/2448:451,availability,avail,available,451,"How to read in the Spatial dataset directly from gene count matrix (.mtx) file and related images (without HDF5 files)?; <!-- What kind of feature would you like to request? -->. How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)? - [ +] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy? Thank you very much in advance. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448
https://github.com/scverse/scanpy/issues/2448:442,integrability,pub,publicly,442,"How to read in the Spatial dataset directly from gene count matrix (.mtx) file and related images (without HDF5 files)?; <!-- What kind of feature would you like to request? -->. How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)? - [ +] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy? Thank you very much in advance. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448
https://github.com/scverse/scanpy/issues/2448:324,modifiability,paramet,parameters,324,"How to read in the Spatial dataset directly from gene count matrix (.mtx) file and related images (without HDF5 files)?; <!-- What kind of feature would you like to request? -->. How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)? - [ +] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy? Thank you very much in advance. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448
https://github.com/scverse/scanpy/issues/2448:451,reliability,availab,available,451,"How to read in the Spatial dataset directly from gene count matrix (.mtx) file and related images (without HDF5 files)?; <!-- What kind of feature would you like to request? -->. How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)? - [ +] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy? Thank you very much in advance. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448
https://github.com/scverse/scanpy/issues/2448:451,safety,avail,available,451,"How to read in the Spatial dataset directly from gene count matrix (.mtx) file and related images (without HDF5 files)?; <!-- What kind of feature would you like to request? -->. How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)? - [ +] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy? Thank you very much in advance. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448
https://github.com/scverse/scanpy/issues/2448:451,security,availab,available,451,"How to read in the Spatial dataset directly from gene count matrix (.mtx) file and related images (without HDF5 files)?; <!-- What kind of feature would you like to request? -->. How to read in the Spatial object directly from gene count matrix (.mtx) file and related images (without HDF5 file)? - [ +] Additional function parameters / changed functionality / changed defaults? <!-- Please describe your wishes below: -->. I am working on a publicly available dataset which only has provided the gene count (matrix.mtx), features (features.tsv) and barcodes (barcodes.tsv) in addition to the spatial folder (the output of spaceranger). How should I read in this dataset using scanpy? Thank you very much in advance. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2448
https://github.com/scverse/scanpy/issues/2449:1453,availability,error,error,1453,"inimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1927,availability,error,error,1927,"anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3791,availability,Error,Error,3791,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3818,availability,Error,Error,3818,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:160,deployability,version,version,160,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:724,deployability,resourc,resource,724,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1794,deployability,resourc,resource,1794,"f/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2427,deployability,resourc,resource,2427,"esponse = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3284,deployability,resourc,resource,3284,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3891,deployability,Version,Versions,3891,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:7,energy efficiency,load,load,7,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:724,energy efficiency,resourc,resource,724,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1794,energy efficiency,resourc,resource,1794,"f/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2427,energy efficiency,resourc,resource,2427,"esponse = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3284,energy efficiency,resourc,resource,3284,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:160,integrability,version,version,160,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3891,integrability,Version,Versions,3891,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:160,modifiability,version,version,160,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3891,modifiability,Version,Versions,3891,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:7,performance,load,load,7,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:724,performance,resourc,resource,724,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1453,performance,error,error,1453,"inimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1794,performance,resourc,resource,1794,"f/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1927,performance,error,error,1927,"anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2427,performance,resourc,resource,2427,"esponse = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3284,performance,resourc,resource,3284,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3791,performance,Error,Error,3791,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3818,performance,Error,Error,3818,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:724,safety,resourc,resource,724,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1453,safety,error,error,1453,"inimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1794,safety,resourc,resource,1794,"f/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1927,safety,error,error,1927,"anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2427,safety,resourc,resource,2427,"esponse = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3284,safety,resourc,resource,3284,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3791,safety,Error,Error,3791,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3818,safety,Error,Error,3818,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:724,testability,resourc,resource,724,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1794,testability,resourc,resource,1794,"f/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2427,testability,resourc,resource,2427,"esponse = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3284,testability,resourc,resource,3284,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:120,usability,confirm,confirmed,120,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:203,usability,confirm,confirmed,203,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:294,usability,guid,guide,294,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:349,usability,minim,minimal-bug-reports,349,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:455,usability,Minim,Minimal,455,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:748,usability,User,Users,748,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:915,usability,User,Users,915,"Cannot load EBI Expression Datasets; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1029,usability,indicat,indicates,1029,"s; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1072,usability,User,Users,1072,"has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///U",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1227,usability,User,Users,1227,"n the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1352,usability,User,Users,1352,"l-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anacond",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1453,usability,error,error,1453,"inimal code sample (that we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1475,usability,User,Users,1475,"at we can copy&paste without having any data). ```python. import scanpy. acc = ""E-MTAB-4888"". ad_df = scanpy.datasets.ebi_expression_atlas(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1612,usability,User,Users,1612,"s(acc). ```. ```pytb. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1818,usability,User,Users,1818,"/request.py:634), in HTTPErrorProcessor.http_response(self, request, response). [631](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1927,usability,error,error,1927,"anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:1968,usability,User,Users,1968,"/request.py?line=630) # According to RFC 2616, ""2xx"" code indicates that the client's. [632](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2074,usability,User,Users,2074,"/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=631) # request was successfully received, understood, and accepted. [633](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2230,usability,User,Users,2230,"kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=632) if not (200 <= code < 300):. --> [634](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=633) response = self.parent.error(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2451,usability,User,Users,2451,"rror(. [635](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=634) 'http', request, response, code, msg, hdrs). [637](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2624,usability,User,Users,2624,"anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=636) return response. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2742,usability,User,Users,2742,"3.10/urllib/request.py:563](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.fu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2874,usability,User,Users,2874,"hon3.10/urllib/request.py:563), in OpenerDirector.error(self, proto, *args). [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:2988,usability,User,Users,2988,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3104,usability,User,Users,3104,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3308,usability,User,Users,3308,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3492,usability,User,Users,3492,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3645,usability,User,Users,3645,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3791,usability,Error,Error,3791,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2449:3818,usability,Error,Error,3818,". [561](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=560) if http_err:. [562](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=561) args = (dict, 'default', 'http_error_default') + orig_args. --> [563](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=562) return self._call_chain(*args). File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:496), in OpenerDirector._call_chain(self, chain, kind, meth_name, *args). [494](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=493) for handler in handlers:. [495](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=494) func = getattr(handler, meth_name). --> [496](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=495) result = func(*args). [497](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=496) if result is not None:. [498](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=497) return result. File [~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643](https://file+.vscode-resource.vscode-cdn.net/Users/kakranaa/github/geno-ai/~/anaconda3/envs/binf/lib/python3.10/urllib/request.py:643), in HTTPDefaultErrorHandler.http_error_default(self, req, fp, code, msg, hdrs). [642](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=641) def http_error_default(self, req, fp, code, msg, hdrs):. --> [643](file:///Users/kakranaa/anaconda3/envs/binf/lib/python3.10/urllib/request.py?line=642) raise HTTPError(req.full_url, code, msg, hdrs, fp). HTTPError: HTTP Error 500: Internal Server Error (https://www.ebi.ac.uk/gxa/sc/experiments/E-MTAB-4888/). ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.3. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2449
https://github.com/scverse/scanpy/issues/2450:113,modifiability,paramet,parameters,113,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:391,modifiability,pac,package,391,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:522,safety,prevent,prevent,522,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:501,security,expos,exposed,501,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:522,security,preven,prevent,522,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:195,testability,simpl,simple,195,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:187,usability,tool,tool,187,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:195,usability,simpl,simple,195,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:211,usability,tool,tool,211,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:259,usability,tool,tools,259,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2450:360,usability,tool,tools,360,"sc.settings.plot_use_prefix; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... 1. exposed a setting to prevent `sc.pp.<fn>` from saving with a ""prefix"" (default filename) if `type(save) == str`. Why? I don't want my files having that prefix. . 2. please add PHATE and magic-impute to embedding options :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2450
https://github.com/scverse/scanpy/issues/2451:507,safety,except,except,507,"Diagonal of connectivities for diffusion maps is zero - is this intended?; My question is about the `connectivities` used within this function: https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/tools/_dpt.py#L16. the computation that uses `connectivities` is as follows:. https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/neighbors/__init__.py#L914-L925. I can follow most of this computation and link it back to the main reference, except for the fact that the `connectivities` (i.e. `adata.obsp['connectivities']`), when calculated using `scanpy.pp.neighbors` as suggested in the `diffmap` docstring, ***have a zero diagonal***. Could someone confirm whether this is the intended calculation? And if so, provide a reference that confirms this? I've not read [the reference](https://www.sciencedirect.com/science/article/pii/S1063520306000546) in detail, but I would've thought (following section 3.1 and 5) that, as all the computations revolve around the usage of a *kernel*, the connectivities should be positive definite before normalization, which wouldn't be the case if the diagonal was zeroed out. At a glance, I also cannot find anywhere in that reference that talks about `P(xi, xi)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2451
https://github.com/scverse/scanpy/issues/2451:231,usability,tool,tools,231,"Diagonal of connectivities for diffusion maps is zero - is this intended?; My question is about the `connectivities` used within this function: https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/tools/_dpt.py#L16. the computation that uses `connectivities` is as follows:. https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/neighbors/__init__.py#L914-L925. I can follow most of this computation and link it back to the main reference, except for the fact that the `connectivities` (i.e. `adata.obsp['connectivities']`), when calculated using `scanpy.pp.neighbors` as suggested in the `diffmap` docstring, ***have a zero diagonal***. Could someone confirm whether this is the intended calculation? And if so, provide a reference that confirms this? I've not read [the reference](https://www.sciencedirect.com/science/article/pii/S1063520306000546) in detail, but I would've thought (following section 3.1 and 5) that, as all the computations revolve around the usage of a *kernel*, the connectivities should be positive definite before normalization, which wouldn't be the case if the diagonal was zeroed out. At a glance, I also cannot find anywhere in that reference that talks about `P(xi, xi)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2451
https://github.com/scverse/scanpy/issues/2451:719,usability,confirm,confirm,719,"Diagonal of connectivities for diffusion maps is zero - is this intended?; My question is about the `connectivities` used within this function: https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/tools/_dpt.py#L16. the computation that uses `connectivities` is as follows:. https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/neighbors/__init__.py#L914-L925. I can follow most of this computation and link it back to the main reference, except for the fact that the `connectivities` (i.e. `adata.obsp['connectivities']`), when calculated using `scanpy.pp.neighbors` as suggested in the `diffmap` docstring, ***have a zero diagonal***. Could someone confirm whether this is the intended calculation? And if so, provide a reference that confirms this? I've not read [the reference](https://www.sciencedirect.com/science/article/pii/S1063520306000546) in detail, but I would've thought (following section 3.1 and 5) that, as all the computations revolve around the usage of a *kernel*, the connectivities should be positive definite before normalization, which wouldn't be the case if the diagonal was zeroed out. At a glance, I also cannot find anywhere in that reference that talks about `P(xi, xi)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2451
https://github.com/scverse/scanpy/issues/2451:805,usability,confirm,confirms,805,"Diagonal of connectivities for diffusion maps is zero - is this intended?; My question is about the `connectivities` used within this function: https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/tools/_dpt.py#L16. the computation that uses `connectivities` is as follows:. https://github.com/scverse/scanpy/blob/0692ef9ea30335b95f7e7f9aab7be856469d9f35/scanpy/neighbors/__init__.py#L914-L925. I can follow most of this computation and link it back to the main reference, except for the fact that the `connectivities` (i.e. `adata.obsp['connectivities']`), when calculated using `scanpy.pp.neighbors` as suggested in the `diffmap` docstring, ***have a zero diagonal***. Could someone confirm whether this is the intended calculation? And if so, provide a reference that confirms this? I've not read [the reference](https://www.sciencedirect.com/science/article/pii/S1063520306000546) in detail, but I would've thought (following section 3.1 and 5) that, as all the computations revolve around the usage of a *kernel*, the connectivities should be positive definite before normalization, which wouldn't be the case if the diagonal was zeroed out. At a glance, I also cannot find anywhere in that reference that talks about `P(xi, xi)`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2451
https://github.com/scverse/scanpy/pull/2452:407,modifiability,pac,packaging,407,Add more metadata to pyproject.toml; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/. Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/pull/2452:256,safety,review,review,256,Add more metadata to pyproject.toml; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/. Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/pull/2452:256,testability,review,review,256,Add more metadata to pyproject.toml; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/. Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/pull/2452:107,usability,guid,guidelines,107,Add more metadata to pyproject.toml; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/. Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/pull/2452:138,usability,guid,guide,138,Add more metadata to pyproject.toml; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/. Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/pull/2452:234,usability,workflow,workflow,234,Add more metadata to pyproject.toml; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Code changes pertaining to this issue: https://github.com/scverse/scanpy/issues/1673/. Added Discourse and twitter links to scanpy's pypi packaging.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2452
https://github.com/scverse/scanpy/issues/2453:591,energy efficiency,Current,Currently,591,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:734,interoperability,specif,specifies,734,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:115,modifiability,paramet,parameters,115,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:392,modifiability,pac,package,392,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:197,testability,simpl,simple,197,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:189,usability,tool,tool,189,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:197,usability,simpl,simple,197,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:213,usability,tool,tool,213,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:261,usability,tool,tools,261,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:361,usability,tool,tools,361,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/issues/2453:574,usability,tool,tools,574,"Precomputed distance matrices; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. I would like to use a precomputed distance or affinity matrix with many of the tools in scanpy. Currently this feature is unsupported. It should be a relatively small PR - essentially adding ""precomputed_key"" to `sc.pp.neighbors` etc that specifies a key in `obsp` to look for distances.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2453
https://github.com/scverse/scanpy/pull/2454:0,performance,Parallel,Parallel,0,"Parallel read; We have replaced the existing sc.read() implementation with our parallel read implementation using numba. By using this implementation , we get upto **31x faster** reading for large files as compared to the traditional sc.read() approach .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2454
https://github.com/scverse/scanpy/pull/2454:79,performance,parallel,parallel,79,"Parallel read; We have replaced the existing sc.read() implementation with our parallel read implementation using numba. By using this implementation , we get upto **31x faster** reading for large files as compared to the traditional sc.read() approach .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2454
https://github.com/scverse/scanpy/pull/2455:0,integrability,Filter,Filter,0,"Filter; In this contribution , we have introduced a new flow for filtering in the form of a function 'filter' in the already existing filtering implementation by combining 'filter cells' , 'filter genes', 'normtotal_log1p' and 'highly_variabe_gene(use_fastpp) for overall faster preprocessing. This new flow also introduces changes in log1p in the form of a new function 'normtotal_log1p' ,combining normalisation and log1p functionalities together. It also introduced a new flavour 'use_fastpp' in already existing 'highly_variable_gene' function for faster preprocessing. The filter function gives an overall speedup of approx **~2x** from the normal preprocessing flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2455
https://github.com/scverse/scanpy/pull/2455:65,integrability,filter,filtering,65,"Filter; In this contribution , we have introduced a new flow for filtering in the form of a function 'filter' in the already existing filtering implementation by combining 'filter cells' , 'filter genes', 'normtotal_log1p' and 'highly_variabe_gene(use_fastpp) for overall faster preprocessing. This new flow also introduces changes in log1p in the form of a new function 'normtotal_log1p' ,combining normalisation and log1p functionalities together. It also introduced a new flavour 'use_fastpp' in already existing 'highly_variable_gene' function for faster preprocessing. The filter function gives an overall speedup of approx **~2x** from the normal preprocessing flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2455
https://github.com/scverse/scanpy/pull/2455:102,integrability,filter,filter,102,"Filter; In this contribution , we have introduced a new flow for filtering in the form of a function 'filter' in the already existing filtering implementation by combining 'filter cells' , 'filter genes', 'normtotal_log1p' and 'highly_variabe_gene(use_fastpp) for overall faster preprocessing. This new flow also introduces changes in log1p in the form of a new function 'normtotal_log1p' ,combining normalisation and log1p functionalities together. It also introduced a new flavour 'use_fastpp' in already existing 'highly_variable_gene' function for faster preprocessing. The filter function gives an overall speedup of approx **~2x** from the normal preprocessing flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2455
https://github.com/scverse/scanpy/pull/2455:134,integrability,filter,filtering,134,"Filter; In this contribution , we have introduced a new flow for filtering in the form of a function 'filter' in the already existing filtering implementation by combining 'filter cells' , 'filter genes', 'normtotal_log1p' and 'highly_variabe_gene(use_fastpp) for overall faster preprocessing. This new flow also introduces changes in log1p in the form of a new function 'normtotal_log1p' ,combining normalisation and log1p functionalities together. It also introduced a new flavour 'use_fastpp' in already existing 'highly_variable_gene' function for faster preprocessing. The filter function gives an overall speedup of approx **~2x** from the normal preprocessing flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2455
https://github.com/scverse/scanpy/pull/2455:173,integrability,filter,filter,173,"Filter; In this contribution , we have introduced a new flow for filtering in the form of a function 'filter' in the already existing filtering implementation by combining 'filter cells' , 'filter genes', 'normtotal_log1p' and 'highly_variabe_gene(use_fastpp) for overall faster preprocessing. This new flow also introduces changes in log1p in the form of a new function 'normtotal_log1p' ,combining normalisation and log1p functionalities together. It also introduced a new flavour 'use_fastpp' in already existing 'highly_variable_gene' function for faster preprocessing. The filter function gives an overall speedup of approx **~2x** from the normal preprocessing flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2455
https://github.com/scverse/scanpy/pull/2455:190,integrability,filter,filter,190,"Filter; In this contribution , we have introduced a new flow for filtering in the form of a function 'filter' in the already existing filtering implementation by combining 'filter cells' , 'filter genes', 'normtotal_log1p' and 'highly_variabe_gene(use_fastpp) for overall faster preprocessing. This new flow also introduces changes in log1p in the form of a new function 'normtotal_log1p' ,combining normalisation and log1p functionalities together. It also introduced a new flavour 'use_fastpp' in already existing 'highly_variable_gene' function for faster preprocessing. The filter function gives an overall speedup of approx **~2x** from the normal preprocessing flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2455
https://github.com/scverse/scanpy/pull/2455:578,integrability,filter,filter,578,"Filter; In this contribution , we have introduced a new flow for filtering in the form of a function 'filter' in the already existing filtering implementation by combining 'filter cells' , 'filter genes', 'normtotal_log1p' and 'highly_variabe_gene(use_fastpp) for overall faster preprocessing. This new flow also introduces changes in log1p in the form of a new function 'normtotal_log1p' ,combining normalisation and log1p functionalities together. It also introduced a new flavour 'use_fastpp' in already existing 'highly_variable_gene' function for faster preprocessing. The filter function gives an overall speedup of approx **~2x** from the normal preprocessing flow.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2455
https://github.com/scverse/scanpy/pull/2456:164,security,modif,modification,164,Regress out; This contribution also holds a faster implementation for regress_out function in the form of a new function 'numpy_regress_out'. The numpy_regress_out modification provides an overall speedup of approx **~18x** in comparison to the already existing 'regress_out' function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2456
https://github.com/scverse/scanpy/pull/2456:0,testability,Regress,Regress,0,Regress out; This contribution also holds a faster implementation for regress_out function in the form of a new function 'numpy_regress_out'. The numpy_regress_out modification provides an overall speedup of approx **~18x** in comparison to the already existing 'regress_out' function,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2456
https://github.com/scverse/scanpy/pull/2457:0,deployability,Scale,Scale,0,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:62,deployability,scale,scale,62,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:254,deployability,scale,scale,254,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:273,deployability,scale,scale,273,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:386,deployability,scale,scale,386,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:421,deployability,scale,scale,421,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:0,energy efficiency,Scale,Scale,0,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:62,energy efficiency,scale,scale,62,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:254,energy efficiency,scale,scale,254,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:273,energy efficiency,scale,scale,273,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:386,energy efficiency,scale,scale,386,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:421,energy efficiency,scale,scale,421,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:0,modifiability,Scal,Scale,0,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:62,modifiability,scal,scale,62,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:254,modifiability,scal,scale,254,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:273,modifiability,scal,scale,273,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:386,modifiability,scal,scale,386,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:421,modifiability,scal,scale,421,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:0,performance,Scale,Scale,0,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:62,performance,scale,scale,62,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:254,performance,scale,scale,254,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:273,performance,scale,scale,273,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:386,performance,scale,scale,386,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:421,performance,scale,scale,421,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:31,security,modif,modifications,31,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2457:288,security,modif,modification,288,"Scale; This contribution holds modifications to the existing 'scale function' which turns out to be a faster implementation than the original one. We have introduced flavors - default and use_fastpp , where use_fastpp is our faster implementation of the scale function.The scale function modification provides an overall speedup of approx **~2x** in comparison to the already existing 'scale' function. **Usage** : sc.pp.scale(adata,max_value=10,flavor='use_fastpp')",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2457
https://github.com/scverse/scanpy/pull/2458:310,deployability,pipelin,pipelines,310,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:477,deployability,API,API,477,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:567,deployability,version,version,567,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:429,energy efficiency,load,load,429,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:310,integrability,pipelin,pipelines,310,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:477,integrability,API,API,477,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:567,integrability,version,version,567,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:71,interoperability,Specif,Specifically,71,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:477,interoperability,API,API,477,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:567,modifiability,version,version,567,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:429,performance,load,load,429,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:490,security,sign,signature,490,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:253,usability,support,support,253,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/pull/2458:535,usability,document,documentation,535,"Read visium v2; The ""outs"" from `spaceranger count` v2 differ from v1. Specifically, `tissue_positions_list.csv` has been renamed `tissue_positions.csv` and now has headers. Fortunately the column names exactly match those used by `scanpy`. See https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/spatial (search for `tissue_positions.csv`). This PR adjusts `sc.read_visium()` so that it can load the outputs of `spaceranger count` v2. The API / method signature is unchanged, so no changes to the documentation are required. The version is inferred from the presence or otherwise of the old `tissue_positions_list.csv` (implying v1) and then the files in `spatial/` are handled accordingly, including differential handling of headers / column names. @linhuawang. @sopvdl. @TaopengWang",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2458
https://github.com/scverse/scanpy/issues/2459:1246,availability,FAILUR,FAILURES,1246,"anch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),. (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),. (. ""master_paga_continuous_mu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:10,deployability,fail,fails,10,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:35,deployability,instal,install,35,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:165,deployability,version,version,165,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:289,deployability,instal,installing,289,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:308,deployability,version,version,308,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:493,deployability,instal,installation,493,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:523,deployability,version,version,523,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:636,deployability,fail,fail,636,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1001,deployability,updat,update,1001," test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1102,deployability,instal,install,1102,"rted. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1246,deployability,FAIL,FAILURES,1246,"anch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),. (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),. (. ""master_paga_continuous_mu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5548,deployability,FAIL,FAILED,5548,"sinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5649,deployability,FAIL,FAILED,5649,"ports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5761,deployability,fail,failed,5761,"e-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5901,deployability,Version,Versions,5901,"ort generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6890,deployability,updat,updated,6890," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6012,energy efficiency,cloud,cloudpickle,6012," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:165,integrability,version,version,165,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:308,integrability,version,version,308,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:523,integrability,version,version,523,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:991,integrability,sub,submodule,991,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4203,integrability,protocol,protocol,4203,"/anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5017,integrability,filter,filtering,5017,"ite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5901,integrability,Version,Versions,5901,"ort generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4203,interoperability,protocol,protocol,4203,"/anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:165,modifiability,version,version,165,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:308,modifiability,version,version,308,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:523,modifiability,version,version,523,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:2017,modifiability,paramet,parametrize,2017,"ive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),. (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),. (. ""master_paga_continuous_multiple"",. partial(sc.pl.paga, color=['CST3', 'GATA2']),. ),. (""master_paga_compare"", partial(sc.pl.paga_compare, legend_fontoutline=2)),. (. ""master_paga_compare_continuous"",. partial(sc.pl.paga_compare, color='CST3', legend_fontsize=5),. ),. (. ""master_paga_compare_pca"",. partial(sc.pl.paga_compare, basis='X_pca', legend_fontweight='normal'),. ),. ],. ). def test_paga_plots(image_comparer, pbmc, test_id, func):. save_and_compare_images = image_comparer(ROOT, FIGS, tol=30). common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False). . > func(pbmc, **common). scanpy/tests/test_paga.py:57: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:3253,modifiability,pac,packages,3253,",. partial(sc.pl.paga, color=['CST3', 'GATA2']),. ),. (""master_paga_compare"", partial(sc.pl.paga_compare, legend_fontoutline=2)),. (. ""master_paga_compare_continuous"",. partial(sc.pl.paga_compare, color='CST3', legend_fontsize=5),. ),. (. ""master_paga_compare_pca"",. partial(sc.pl.paga_compare, basis='X_pca', legend_fontweight='normal'),. ),. ],. ). def test_paga_plots(image_comparer, pbmc, test_id, func):. save_and_compare_images = image_comparer(ROOT, FIGS, tol=30). common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False). . > func(pbmc, **common). scanpy/tests/test_paga.py:57: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. scanpy/plotting/_tools/paga.py:576: in paga. sct = _paga_graph(. scanpy/plotting/_tools/paga.py:911: in _paga_graph. sct = ax.scatter(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:3416,modifiability,pac,packages,3416,"us"",. partial(sc.pl.paga_compare, color='CST3', legend_fontsize=5),. ),. (. ""master_paga_compare_pca"",. partial(sc.pl.paga_compare, basis='X_pca', legend_fontweight='normal'),. ),. ],. ). def test_paga_plots(image_comparer, pbmc, test_id, func):. save_and_compare_images = image_comparer(ROOT, FIGS, tol=30). common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False). . > func(pbmc, **common). scanpy/tests/test_paga.py:57: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. scanpy/plotting/_tools/paga.py:576: in paga. sct = _paga_graph(. scanpy/plotting/_tools/paga.py:911: in _paga_graph. sct = ax.scatter(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:3558,modifiability,pac,packages,3558,"ca', legend_fontweight='normal'),. ),. ],. ). def test_paga_plots(image_comparer, pbmc, test_id, func):. save_and_compare_images = image_comparer(ROOT, FIGS, tol=30). common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False). . > func(pbmc, **common). scanpy/tests/test_paga.py:57: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. scanpy/plotting/_tools/paga.py:576: in paga. sct = _paga_graph(. scanpy/plotting/_tools/paga.py:911: in _paga_graph. sct = ax.scatter(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5313,modifiability,pac,packages,5313," is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5901,modifiability,Version,Versions,5901,"ort generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6392,modifiability,pac,packaging,6392," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6757,modifiability,pac,packaged,6757," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1246,performance,FAILUR,FAILURES,1246,"anch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),. (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),. (. ""master_paga_continuous_mu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:10,reliability,fail,fails,10,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:636,reliability,fail,fail,636,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1246,reliability,FAIL,FAILURES,1246,"anch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),. (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),. (. ""master_paga_continuous_mu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4892,reliability,doe,does,4892,"n, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5131,reliability,doe,does,5131,"irst non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5548,reliability,FAIL,FAILED,5548,"sinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5649,reliability,FAIL,FAILED,5649,"ports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5761,reliability,fail,failed,5761,"e-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | package",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5,safety,test,test,5,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:545,safety,test,tests,545,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1001,safety,updat,update,1001," test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1124,safety,test,test,1124,"onfirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:2840,safety,test,tests,2840,"es', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),. (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),. (. ""master_paga_continuous_multiple"",. partial(sc.pl.paga, color=['CST3', 'GATA2']),. ),. (""master_paga_compare"", partial(sc.pl.paga_compare, legend_fontoutline=2)),. (. ""master_paga_compare_continuous"",. partial(sc.pl.paga_compare, color='CST3', legend_fontsize=5),. ),. (. ""master_paga_compare_pca"",. partial(sc.pl.paga_compare, basis='X_pca', legend_fontweight='normal'),. ),. ],. ). def test_paga_plots(image_comparer, pbmc, test_id, func):. save_and_compare_images = image_comparer(ROOT, FIGS, tol=30). common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False). . > func(pbmc, **common). scanpy/tests/test_paga.py:57: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. scanpy/plotting/_tools/paga.py:576: in paga. sct = _paga_graph(. scanpy/plotting/_tools/paga.py:911: in _paga_graph. sct = ax.scatter(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4403,safety,except,except,4403,"n3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ==============================",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4629,safety,input,input,4629,"isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4836,safety,except,except,4836," _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4927,safety,input,input,4927,"rst_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5166,safety,input,input,5166,"oth index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5455,safety,test,test,5455,"not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5562,safety,test,tests,5562," collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5663,safety,test,tests,5663,"stance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6890,safety,updat,updated,6890," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1001,security,updat,update,1001," test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4179,security,access,access,4179," ax.scatter(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6870,security,Session,Session,6870," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6890,security,updat,updated,6890," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5,testability,test,test,5,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:545,testability,test,tests,545,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:1124,testability,test,test,1124,"onfirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:2840,testability,test,tests,2840,"es', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igraph. @pytest.mark.parametrize(. ""test_id,func"",. [. (""master_paga"", sc.pl.paga),. (""master_paga_continuous"", partial(sc.pl.paga, color=""CST3"")),. (""master_paga_continuous_obs"", partial(sc.pl.paga, color=""cool_feature"")),. (. ""master_paga_continuous_multiple"",. partial(sc.pl.paga, color=['CST3', 'GATA2']),. ),. (""master_paga_compare"", partial(sc.pl.paga_compare, legend_fontoutline=2)),. (. ""master_paga_compare_continuous"",. partial(sc.pl.paga_compare, color='CST3', legend_fontsize=5),. ),. (. ""master_paga_compare_pca"",. partial(sc.pl.paga_compare, basis='X_pca', legend_fontweight='normal'),. ),. ],. ). def test_paga_plots(image_comparer, pbmc, test_id, func):. save_and_compare_images = image_comparer(ROOT, FIGS, tol=30). common = dict(threshold=0.5, max_edge_width=1.0, random_state=0, show=False). . > func(pbmc, **common). scanpy/tests/test_paga.py:57: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. scanpy/plotting/_tools/paga.py:576: in paga. sct = _paga_graph(. scanpy/plotting/_tools/paga.py:911: in _paga_graph. sct = ax.scatter(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5455,testability,test,test,5455,"not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5562,testability,test,tests,5562," collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5663,testability,test,tests,5663,"stance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5701,testability,Assert,AssertionError,5701,"still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:125,usability,confirm,confirmed,125,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:208,usability,confirm,confirmed,208,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:687,usability,guid,guide,687,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:742,usability,minim,minimal-bug-reports,742,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:848,usability,Minim,Minimal,848,"paga test fails on master on a dev install; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### Description. I was installing the dev version of scanpy following the instructions [here](https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#working-with-git) and [here](https://scanpy.readthedocs.io/en/stable/installation.html#development-version). However two tests : `test_paga_plots[master_paga_continuous_obs-func2]` and `test_pca_chunked` seem to fail on master. . ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```bash. git clone https://github.com/scverse/scanpy.git. cd scanpy. git submodule update --init --recursive. conda create --name scanpy-dev python=3.8. conda activate scanpy-dev. pip install -e '.[dev,doc,test]'. pytest. ```. ```pytb. =========================================================================================== FAILURES ============================================================================================. _______________________________________________________________________ test_paga_plots[master_paga_continuous_obs-func2] _______________________________________________________________________. image_comparer = <function image_comparer.<locals>.make_comparer at 0x7fbbf032dc10>. pbmc = AnnData object with n_obs × n_vars = 700 × 765. obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score...roups', 'paga', 'bulk_labels_sizes'. obsm: 'X_pca', 'X_umap'. varm: 'PCs'. obsp: 'distances', 'connectivities'. test_id = 'master_paga_continuous_obs', func = functools.partial(<function paga at 0x7fc009276e50>, color='cool_feature'). @needs_igra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4157,usability,support,supporting,4157,"n _paga_graph. sct = ax.scatter(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/__init__.py:1442: in inner. return func(ax, *map(sanitize_sequence, args), **kwargs). ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4602: in scatter. self._parse_scatter_color_args(. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/axes/_axes.py:4400: in _parse_scatter_color_args. and isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4629,usability,input,input,4629,"isinstance(cbook._safe_first_finite(c), str))). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. obj = [nan, nan, nan, nan, nan, nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4901,usability,support,support,4901,", nan, ...]. def _safe_first_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:4927,usability,input,input,4927,"rst_finite(obj, *, skip_nonfinite=True):. """""". Return the first non-None (and optionally finite) element in *obj*. . This is a method for internal use. . This is a type-independent way of obtaining the first non-None element,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5144,usability,support,support,5144,"lement,. supporting both index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5166,usability,input,input,5166,"oth index access and the iterator protocol. The first non-None element will be obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5241,usability,Stop,StopIteration,5241,"obtained when skip_none is True. """""". def safe_isfinite(val):. if val is None:. return False. try:. return np.isfinite(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5357,usability,Stop,StopIteration,5357,"te(val) if np.isscalar(val) else True. except TypeError:. # This is something that numpy can not make heads or tails. # of, assume ""finite"". return True. if skip_nonfinite is False:. if isinstance(obj, collections.abc.Iterator):. # needed to accept `array.flat` as input. # np.flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:5634,usability,Stop,StopIteration,5634,"flatiter reports as an instance of collections.Iterator. # but can still be indexed via []. # This has the side effect of re-setting the iterator, but. # that is acceptable. try:. return obj[0]. except TypeError:. pass. raise RuntimeError(""matplotlib does not support generators "". ""as input""). return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/issues/2459:6651,usability,tool,toolz,6651," return next(iter(obj)). elif isinstance(obj, np.flatiter):. # TODO do the finite filtering on this. return obj[0]. elif isinstance(obj, collections.abc.Iterator):. raise RuntimeError(""matplotlib does not "". ""support generators as input""). else:. > return next(val for val in obj if safe_isfinite(val)). E StopIteration. ../../../../anaconda3/envs/scanpy-dev/lib/python3.8/site-packages/matplotlib/cbook/__init__.py:1715: StopIteration. ... ======================================================================== short test summary info =========================================================================. FAILED scanpy/tests/test_paga.py::test_paga_plots[master_paga_continuous_obs-func2] - StopIteration. FAILED scanpy/tests/test_pca.py::test_pca_chunked - AssertionError: . ======================================= 2 failed, 929 passed, 50 skipped, 1 xfailed, 1 xpassed, 814 warnings in 482.45s (0:08:02) ========================================. ```. #### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev47+g99697347. -----. PIL 9.5.0. asciitree NA. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.18. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. packaging 23.0. pandas 1.5.3. pkg_resources NA. psutil 5.9.4. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.6.1. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zipp NA. -----. Python 3.8.16 | packaged by conda-forge | (default, Feb 1 2023, 16:05:36) [Clang 14.0.6 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-04-01 09:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2459
https://github.com/scverse/scanpy/pull/2460:20,modifiability,variab,variables,20,Coloring by boolean variables ; Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/pull/2460:79,modifiability,variab,variables,79,Coloring by boolean variables ; Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/pull/2460:128,safety,compl,complete,128,Coloring by boolean variables ; Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/pull/2460:152,safety,test,test,152,Coloring by boolean variables ; Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/pull/2460:128,security,compl,complete,128,Coloring by boolean variables ; Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/pull/2460:152,testability,test,test,152,Coloring by boolean variables ; Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/pull/2460:50,usability,support,supports,50,Coloring by boolean variables ; Fixes #1646 . Now supports coloring by boolean variables such as `True` and `False`. **Tasks to complete:** . - [x] Add test.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2460
https://github.com/scverse/scanpy/issues/2461:111,availability,Error,Error,111,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:273,deployability,modul,module,273,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:273,modifiability,modul,module,273,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:340,modifiability,pac,packages,340,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:485,modifiability,pac,packages,485,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:677,modifiability,pac,packages,677,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:111,performance,Error,Error,111,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:111,safety,Error,Error,111,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:273,safety,modul,module,273,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:209,testability,Trace,Traceback,209,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:54,usability,tool,tools,54,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:111,usability,Error,Error,111,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2461:910,usability,help,help,910,"Can not read loom file ; Dears. Thanks for this great tools. We had loom file from Seurat(V4), while got those Error when used 'sc.read_loom' function:. ```pytb. sc_adata=sc.read_loom(sc_input,sparse = True). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/compat/__init__.py"", line 253, in inner_f. return f(*args, **kwargs). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 280, in read_loom. obs, obsm = _fmt_loom_axis_attrs(dict(lc.col_attrs), obs_names, obsm_mapping). File ""./miniconda/miniconda/envs/scrna/lib/python3.8/site-packages/anndata/_io/read.py"", line 159, in _fmt_loom_axis_attrs. if v.ndim > 1 and v.shape[1] > 1:. AttributeError: 'NoneType' object has no attribute 'ndim' . ```. We want to know how to solve this, we are looking forward for your help, thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2461
https://github.com/scverse/scanpy/issues/2462:32,deployability,api,api,32,scanpy.read_visium ; . Will the api of “scanpy.read_visium” be upgraded to be compatible with the new space information file name tissue_positions.csv which was previously named tissue_positions_list.csv ，after Space Ranger 2.0?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462
https://github.com/scverse/scanpy/issues/2462:63,deployability,upgrad,upgraded,63,scanpy.read_visium ; . Will the api of “scanpy.read_visium” be upgraded to be compatible with the new space information file name tissue_positions.csv which was previously named tissue_positions_list.csv ，after Space Ranger 2.0?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462
https://github.com/scverse/scanpy/issues/2462:32,integrability,api,api,32,scanpy.read_visium ; . Will the api of “scanpy.read_visium” be upgraded to be compatible with the new space information file name tissue_positions.csv which was previously named tissue_positions_list.csv ，after Space Ranger 2.0?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462
https://github.com/scverse/scanpy/issues/2462:32,interoperability,api,api,32,scanpy.read_visium ; . Will the api of “scanpy.read_visium” be upgraded to be compatible with the new space information file name tissue_positions.csv which was previously named tissue_positions_list.csv ，after Space Ranger 2.0?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462
https://github.com/scverse/scanpy/issues/2462:78,interoperability,compatib,compatible,78,scanpy.read_visium ; . Will the api of “scanpy.read_visium” be upgraded to be compatible with the new space information file name tissue_positions.csv which was previously named tissue_positions_list.csv ，after Space Ranger 2.0?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462
https://github.com/scverse/scanpy/issues/2462:63,modifiability,upgrad,upgraded,63,scanpy.read_visium ; . Will the api of “scanpy.read_visium” be upgraded to be compatible with the new space information file name tissue_positions.csv which was previously named tissue_positions_list.csv ，after Space Ranger 2.0?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2462
https://github.com/scverse/scanpy/pull/2463:95,deployability,pipelin,pipelines,95,Add scverse citation & restructure scanpy citation; Following what nf-core did to all of their pipelines and tools.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2463
https://github.com/scverse/scanpy/pull/2463:70,energy efficiency,core,core,70,Add scverse citation & restructure scanpy citation; Following what nf-core did to all of their pipelines and tools.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2463
https://github.com/scverse/scanpy/pull/2463:95,integrability,pipelin,pipelines,95,Add scverse citation & restructure scanpy citation; Following what nf-core did to all of their pipelines and tools.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2463
https://github.com/scverse/scanpy/pull/2463:109,usability,tool,tools,109,Add scverse citation & restructure scanpy citation; Following what nf-core did to all of their pipelines and tools.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2463
https://github.com/scverse/scanpy/issues/2464:566,energy efficiency,draw,draw,566,"plot tSNE stratified by conditions in separate plots; I have an anndata object like this . > adata_all:. > AnnData object with n_obs × n_vars = 10000 × 14. > obs: 'sample', 'batch', 'condition'. > var: 'n', 'channel', 'marker', '$PnB', '$PnG', '$PnE', 'signal_type', '$PnR-0', '$PnR-1', '$PnR-2', 'AB'. > uns: 'meta', 'neighbors', 'pca', 'sample_colors', 'umap', 'condition_colors'. > obsm: 'X_pca', 'X_umap', 'X_tsne'. > varm: 'PCs'. > layers: 'original'. > obsp: 'connectivities', 'distances'. The conditions are as follow: conditions = ['a', 'b', 'c']. How can I draw tSNEs for each marker separated by each condition in a row? As you can see condition is a feature of obstacles and marker is a feature of variables. I want to plot tSNEs for each marker in three different tSNEs based on conditions. Is this possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2464
https://github.com/scverse/scanpy/issues/2464:174,integrability,batch,batch,174,"plot tSNE stratified by conditions in separate plots; I have an anndata object like this . > adata_all:. > AnnData object with n_obs × n_vars = 10000 × 14. > obs: 'sample', 'batch', 'condition'. > var: 'n', 'channel', 'marker', '$PnB', '$PnG', '$PnE', 'signal_type', '$PnR-0', '$PnR-1', '$PnR-2', 'AB'. > uns: 'meta', 'neighbors', 'pca', 'sample_colors', 'umap', 'condition_colors'. > obsm: 'X_pca', 'X_umap', 'X_tsne'. > varm: 'PCs'. > layers: 'original'. > obsp: 'connectivities', 'distances'. The conditions are as follow: conditions = ['a', 'b', 'c']. How can I draw tSNEs for each marker separated by each condition in a row? As you can see condition is a feature of obstacles and marker is a feature of variables. I want to plot tSNEs for each marker in three different tSNEs based on conditions. Is this possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2464
https://github.com/scverse/scanpy/issues/2464:437,modifiability,layer,layers,437,"plot tSNE stratified by conditions in separate plots; I have an anndata object like this . > adata_all:. > AnnData object with n_obs × n_vars = 10000 × 14. > obs: 'sample', 'batch', 'condition'. > var: 'n', 'channel', 'marker', '$PnB', '$PnG', '$PnE', 'signal_type', '$PnR-0', '$PnR-1', '$PnR-2', 'AB'. > uns: 'meta', 'neighbors', 'pca', 'sample_colors', 'umap', 'condition_colors'. > obsm: 'X_pca', 'X_umap', 'X_tsne'. > varm: 'PCs'. > layers: 'original'. > obsp: 'connectivities', 'distances'. The conditions are as follow: conditions = ['a', 'b', 'c']. How can I draw tSNEs for each marker separated by each condition in a row? As you can see condition is a feature of obstacles and marker is a feature of variables. I want to plot tSNEs for each marker in three different tSNEs based on conditions. Is this possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2464
https://github.com/scverse/scanpy/issues/2464:709,modifiability,variab,variables,709,"plot tSNE stratified by conditions in separate plots; I have an anndata object like this . > adata_all:. > AnnData object with n_obs × n_vars = 10000 × 14. > obs: 'sample', 'batch', 'condition'. > var: 'n', 'channel', 'marker', '$PnB', '$PnG', '$PnE', 'signal_type', '$PnR-0', '$PnR-1', '$PnR-2', 'AB'. > uns: 'meta', 'neighbors', 'pca', 'sample_colors', 'umap', 'condition_colors'. > obsm: 'X_pca', 'X_umap', 'X_tsne'. > varm: 'PCs'. > layers: 'original'. > obsp: 'connectivities', 'distances'. The conditions are as follow: conditions = ['a', 'b', 'c']. How can I draw tSNEs for each marker separated by each condition in a row? As you can see condition is a feature of obstacles and marker is a feature of variables. I want to plot tSNEs for each marker in three different tSNEs based on conditions. Is this possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2464
https://github.com/scverse/scanpy/issues/2464:174,performance,batch,batch,174,"plot tSNE stratified by conditions in separate plots; I have an anndata object like this . > adata_all:. > AnnData object with n_obs × n_vars = 10000 × 14. > obs: 'sample', 'batch', 'condition'. > var: 'n', 'channel', 'marker', '$PnB', '$PnG', '$PnE', 'signal_type', '$PnR-0', '$PnR-1', '$PnR-2', 'AB'. > uns: 'meta', 'neighbors', 'pca', 'sample_colors', 'umap', 'condition_colors'. > obsm: 'X_pca', 'X_umap', 'X_tsne'. > varm: 'PCs'. > layers: 'original'. > obsp: 'connectivities', 'distances'. The conditions are as follow: conditions = ['a', 'b', 'c']. How can I draw tSNEs for each marker separated by each condition in a row? As you can see condition is a feature of obstacles and marker is a feature of variables. I want to plot tSNEs for each marker in three different tSNEs based on conditions. Is this possible?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2464
https://github.com/scverse/scanpy/issues/2465:408,availability,error,error,408,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:588,availability,error,error,588,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:688,availability,error,error,688,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:784,availability,error,error,784,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3199,availability,sli,slice,3199,"malization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:173,deployability,version,version,173,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:390,deployability,build,builds,390,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:526,deployability,releas,released,526,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:555,deployability,version,version,555,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:727,deployability,instal,install,727,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1493,deployability,Fail,Failed,1493,"operly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3964,deployability,Version,Versions,3964,""""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:5010,deployability,updat,updated,5010,"#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34. -----. Session information updated at 2023-04-11 15:57. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3915,energy efficiency,core,core,3915,"ned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:4133,energy efficiency,cloud,cloudpickle,4133,"#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34. -----. Session information updated at 2023-04-11 15:57. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:173,integrability,version,version,173,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:555,integrability,version,version,555,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:2955,integrability,sub,subclass,2955,"=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3964,integrability,Version,Versions,3964,""""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:173,modifiability,version,version,173,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:555,modifiability,version,version,555,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1673,modifiability,paramet,parametrize,1673," see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3899,modifiability,pac,packages,3899,"array is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3964,modifiability,Version,Versions,3964,""""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:4528,modifiability,pac,packaging,4528,"#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34. -----. Session information updated at 2023-04-11 15:57. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:408,performance,error,error,408,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:588,performance,error,error,588,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:688,performance,error,error,688,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:784,performance,error,error,784,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3377,performance,perform,performance,3377," highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3606,performance,time,time,3606,"bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3680,performance,overhead,overhead,3680," """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:22,reliability,doe,does,22,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1493,reliability,Fail,Failed,1493,"operly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3199,reliability,sli,slice,3199,"malization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:408,safety,error,error,408,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:467,safety,prevent,prevents,467,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:488,safety,test,tests,488,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:588,safety,error,error,588,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:631,safety,test,tests,631,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:688,safety,error,error,688,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:784,safety,error,error,784,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1425,safety,test,tests,1425,"://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered du",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:2188,safety,test,tests,2188," indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:2795,safety,valid,valid,2795,". sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indic",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3263,safety,avoid,avoid,3263,"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:5010,safety,updat,updated,5010,"#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34. -----. Session information updated at 2023-04-11 15:57. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:467,security,preven,prevents,467,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:4990,security,Session,Session,4990,"#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34. -----. Session information updated at 2023-04-11 15:57. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:5010,security,updat,updated,5010,"#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34. -----. Session information updated at 2023-04-11 15:57. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:488,testability,test,tests,488,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:631,testability,test,tests,631,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1210,testability,trace,traceback,1210," confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1425,testability,test,tests,1425,"://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered du",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1852,testability,assert,assert,1852,"427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:1987,testability,assert,assert,1987,"et]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._da",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:2188,testability,test,tests,2188," indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:31,usability,support,support,31,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:133,usability,confirm,confirmed,133,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:216,usability,confirm,confirmed,216,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:283,usability,Minim,Minimal,283,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:408,usability,error,error,408,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:588,usability,error,error,588,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:623,usability,minim,minimal,623,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:688,usability,error,error,688,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:784,usability,error,error,784,"sc.pp.normalize_total does not support dask arrays; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). This issue is not yet visible in any builds, since the error fixed by https://github.com/scverse/anndata/pull/970 prevents running the tests properly. Once that PR’s fix is released in a stable anndata version, we’ll start seeing this error unless we fix it first. (the minimal tests + anndata dev don’t have dask, so we don’t see the error there either). ```console. $ pip install dask. $ pytest -k test_normalize_total. ```. The error happens in this line:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L186. i.e. in this expression: `adata.var_names[~gene_subset]`, where `gene_subset` is a `dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>`. ```pytb. IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ```. The traceback pytest shows is a bit incorrect and shows this line instead:. https://github.com/scverse/scanpy/blob/3e3427d0072e82144711b581113ee10b873a1ba3/scanpy/preprocessing/_normalization.py#L185. ```pytb. ./scanpy/tests/test_normalization.py::test_normalize_total[dask-array-int64] Failed: [undefined]IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. typ = <function from_array at 0x7f6c35f8d940>, dtype = 'int64'. @pytest.mark.parametrize('dtype', ['float32', 'int64']). def test_normalize_total(typ, dtype):. adata = AnnData(typ(X_total), dtype=dtype). sc.pp.normalize_total(adata, key_added='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.all",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:2834,usability,support,supports,2834,"='n_counts'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [3.0, 3.0, 3.0]). sc.pp.normalize_total(adata, target_sum=1, key_added='n_counts2'). assert np.allclose(np.ravel(adata.X.sum(axis=1)), [1.0, 1.0, 1.0]). . adata = AnnData(typ(X_frac), dtype=dtype). > sc.pp.normalize_total(adata, exclude_highly_expressed=True, max_fraction=0.7). scanpy/tests/test_normalization.py:45: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/preprocessing/_normalization.py:185: in normalize_total. ' The following highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, bu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:3377,usability,perform,performance,3377," highly-expressed genes are not considered during '. _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = Index(['0', '1', '2'], dtype='object'). key = dask.array<invert, shape=(3,), dtype=bool, chunksize=(3,), chunktype=numpy.ndarray>. def __getitem__(self, key):. """""". Override numpy.ndarray's __getitem__ method to work as desired. . This function adds lists and Series as valid boolean indexers. (ndarrays only supports ndarray with dtype=bool). . If resulting ndim != 1, plain ndarray is returned instead of. corresponding `Index` subclass. . """""". getitem = self._data.__getitem__. . if is_integer(key) or is_float(key):. # GH#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/issues/2465:4786,usability,tool,toolz,4786,"#44051 exclude bool, which would return a 2d ndarray. key = com.cast_scalar_indexer(key, warn_float=True). return getitem(key). . if isinstance(key, slice):. # This case is separated from the conditional above to avoid. # pessimization com.is_bool_indexer and ndim checks. result = getitem(key). # Going through simple_new for performance. return type(self)._simple_new(result, name=self._name). . if com.is_bool_indexer(key):. # if we have list[bools, length=1e5] then doing this check+convert. # takes 166 µs + 2.1 ms and cuts the ndarray.__getitem__. # time below from 3.8 ms to 496 µs. # if we already have ndarray[bool], the overhead is 1.4 µs or .25%. key = np.asarray(key, dtype=bool). . > result = getitem(key). E IndexError: too many indices for array: array is 1-dimensional, but 3 were indexed. ../../venvs/single-cell/lib/python3.8/site-packages/pandas/core/indexes/base.py:5055: IndexError. ```. #### Versions. <details>. -----. anndata 0.9.0rc2.dev18+g7771f6ee. scanpy 1.10.0.dev50+g3e3427d0. -----. PIL 9.1.1. asciitree NA. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.2.1. cycler 0.10.0. cython_runtime NA. dask 2023.3.2. dateutil 2.8.2. defusedxml 0.7.1. entrypoints 0.4. fasteners 0.17.3. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.4. jinja2 3.1.2. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.9.1. llvmlite 0.38.1. markupsafe 2.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.2. numcodecs 0.10.2. numpy 1.22.4. packaging 21.3. pandas 1.4.3. pkg_resources NA. psutil 5.9.1. pyparsing 3.0.9. pytz 2022.1. scipy 1.8.1. session_info 1.0.0. setuptools 67.2.0. setuptools_scm NA. six 1.16.0. sklearn 1.1.1. sphinxcontrib NA. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zarr 2.12.0. zipp NA. -----. Python 3.8.16 (default, Dec 7 2022, 12:42:00) [GCC 12.2.0]. Linux-6.2.10-zen1-1-zen-x86_64-with-glibc2.34. -----. Session information updated at 2023-04-11 15:57. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2465
https://github.com/scverse/scanpy/pull/2466:89,availability,error,error,89,"Fix normalize_total for dask; Fixes #2465. `adata.var_names[~gene_subset]` will throw an error if `gene_subset` is an 1D dask array, so we convert it to a numpy array.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2466
https://github.com/scverse/scanpy/pull/2466:89,performance,error,error,89,"Fix normalize_total for dask; Fixes #2465. `adata.var_names[~gene_subset]` will throw an error if `gene_subset` is an 1D dask array, so we convert it to a numpy array.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2466
https://github.com/scverse/scanpy/pull/2466:89,safety,error,error,89,"Fix normalize_total for dask; Fixes #2465. `adata.var_names[~gene_subset]` will throw an error if `gene_subset` is an 1D dask array, so we convert it to a numpy array.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2466
https://github.com/scverse/scanpy/pull/2466:89,usability,error,error,89,"Fix normalize_total for dask; Fixes #2465. `adata.var_names[~gene_subset]` will throw an error if `gene_subset` is an 1D dask array, so we convert it to a numpy array.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2466
https://github.com/scverse/scanpy/pull/2468:70,safety,test,tests,70,Fix CheckBuild job; Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468
https://github.com/scverse/scanpy/pull/2468:102,safety,test,test,102,Fix CheckBuild job; Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468
https://github.com/scverse/scanpy/pull/2468:70,testability,test,tests,70,Fix CheckBuild job; Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468
https://github.com/scverse/scanpy/pull/2468:102,testability,test,test,102,Fix CheckBuild job; Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468
https://github.com/scverse/scanpy/pull/2468:77,usability,help,helps,77,Fix CheckBuild job; Also do `pytest -v` for more immediate display of tests (helps to see e.g. when a test hangs),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2468
https://github.com/scverse/scanpy/pull/2469:241,safety,review,review,241,"PCA fix random_state; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hello scanpy,. I noticed some inconsistencies in the [scanpy pca function](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html) even when fixing the random seed. I looked at the pca code and it looks like the random seed in the PCA initialization is not set. I fixed it. Best,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2469
https://github.com/scverse/scanpy/pull/2469:241,testability,review,review,241,"PCA fix random_state; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hello scanpy,. I noticed some inconsistencies in the [scanpy pca function](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html) even when fixing the random seed. I looked at the pca code and it looks like the random seed in the PCA initialization is not set. I fixed it. Best,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2469
https://github.com/scverse/scanpy/pull/2469:92,usability,guid,guidelines,92,"PCA fix random_state; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hello scanpy,. I noticed some inconsistencies in the [scanpy pca function](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html) even when fixing the random seed. I looked at the pca code and it looks like the random seed in the PCA initialization is not set. I fixed it. Best,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2469
https://github.com/scverse/scanpy/pull/2469:123,usability,guid,guide,123,"PCA fix random_state; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hello scanpy,. I noticed some inconsistencies in the [scanpy pca function](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html) even when fixing the random seed. I looked at the pca code and it looks like the random seed in the PCA initialization is not set. I fixed it. Best,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2469
https://github.com/scverse/scanpy/pull/2469:219,usability,workflow,workflow,219,"PCA fix random_state; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hello scanpy,. I noticed some inconsistencies in the [scanpy pca function](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.pca.html) even when fixing the random seed. I looked at the pca code and it looks like the random seed in the PCA initialization is not set. I fixed it. Best,.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2469
https://github.com/scverse/scanpy/pull/2470:568,availability,down,downstream,568,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:717,availability,down,downstream,717,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:905,availability,down,downsampled,905,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:45,deployability,probe,probe,45,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:99,deployability,probe,probe,99,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:124,deployability,probe,probe,124,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:187,deployability,probe,probe,187,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:278,deployability,probe,probe-sets,278,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:375,deployability,probe,probe-sets,375,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:427,deployability,probe,probes,427,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:478,deployability,probe,probes,478,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:549,deployability,probe,probes,549,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:692,deployability,probe,probe-barcode,692,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:884,deployability,probe,probe,884,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:976,deployability,probe,probe,976,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:1558,deployability,Probe,Probe,1558,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:268,energy efficiency,profil,profiling,268,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:397,energy efficiency,current,currently,397,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:937,energy efficiency,reduc,reduce,937,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2012,energy efficiency,current,currently,2012,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:268,performance,profil,profiling,268,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:746,reliability,doe,does,746,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:819,safety,test,tests,819,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2137,safety,test,test,2137,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2402,safety,review,review,2402,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:19,security,Modif,Modify,19,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:819,testability,test,tests,819,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2137,testability,test,test,2137,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2402,testability,review,review,2402,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:234,usability,support,support,234,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:322,usability,support,support,322,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:657,usability,user,users,657,"Spaceranger 2.1.0: Modify 10x reader to read probe barcode matrix; Spaceranger 2.1.0 will output a probe barcode matrix for probe based assays. The reasoning behind that is that v2 human probe ensemble (for both [single cell](https://support.10xgenomics.com/fixed-rna-profiling/probe-sets/overview), and [spatial](https://support.10xgenomics.com/spatial-gene-expression-ffpe/probe-sets/overview)) currently has an average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:1536,usability,Mous,Mouse,1536,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:1934,usability,behavi,behaviour,1934,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2253,usability,guid,guidelines,2253,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2284,usability,guid,guide,2284,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/pull/2470:2380,usability,workflow,workflow,2380,average of 3 probes per gene. Additionally around 1/3-rd of our probes span splice junctions and can be treated differently from other probes for various downstream analyses like gDNA characterization and RNA-velocity. This matrix will enable users to use the more fine grained probe-barcode matrix for downstream analyses. This PR does the following:. - Adds an example `raw_probe_barcode_matrix.h5` to `tests/_data/visium_data/2.1.0/raw_probe_bc_matrix.h5` (this is a probe barcode matrix downsampled to 1000 features to reduce the size). - The structure of a probe barcode h5 file is. ```. /matrix Group. /matrix/barcodes Dataset {4987}. /matrix/data Dataset {17581240/Inf}. /matrix/features Group. /matrix/features/feature_type Dataset {21178}. /matrix/features/filtered_probes Dataset {21178}. /matrix/features/gene_id Dataset {21178}. /matrix/features/gene_name Dataset {21178}. /matrix/features/genome Dataset {21178}. /matrix/features/id Dataset {21178}. /matrix/features/name Dataset {21178}. /matrix/features/probe_region Dataset {21178}. /matrix/features/target_sets Group. /matrix/features/target_sets/Visium\ Mouse\ Transcriptome\ Probe\ Set Dataset {19779}. /matrix/filtered_barcodes Dataset {4987}. /matrix/indices Dataset {17581240/Inf}. /matrix/indptr Dataset {4988}. /matrix/shape Dataset {2}. ```. - Enables `_read_v3_10x_h5` to read all the metadata that is in the output H5 files into an anndata. This is done by reading all the metadata in the `h5` files into the anndata. This changes the default behaviour of while reading 10x H5 files to read in all the metadata (the code currently reads all the metadata we usually put in - this will read any additional fields if we put them in too). . - Adds a test to make sure the reader works correctly. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2470
https://github.com/scverse/scanpy/issues/2471:10,availability,cluster,clustering,10,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:592,availability,cluster,clustering,592,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:632,availability,down,downloaded,632,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:691,availability,cluster,clusters,691,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:10,deployability,cluster,clustering,10,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:163,deployability,version,version,163,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:592,deployability,cluster,clustering,592,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:691,deployability,cluster,clusters,691,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:774,deployability,Version,Versions,774,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:2626,deployability,updat,updated,2626,"### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 6.0. zipp NA. zmq 22.3.0. zope NA. -----. IPython 8.2.0. jupyter_client 6.1.12. jupyter_core 4.9.2. jupyterlab 3.3.2. notebook 6.4.8. -----. Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. </details>. -----. Session information updated at 2023-04-18 14:50. ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:941,energy efficiency,cloud,cloudpickle,941,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:163,integrability,version,version,163,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:774,integrability,Version,Versions,774,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:163,modifiability,version,version,163,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:774,modifiability,Version,Versions,774,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:1073,modifiability,deco,decorator,1073,"has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:1543,modifiability,pac,packaging,1543,"```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 6.0. zipp NA. zmq 22.3.0. zope NA. -----. IPython 8.2.0. jupyter_client 6.1.12. jupyter_core 4.9.2. jupyterlab 3.3.2. notebook 6.4.8. -----. Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:910,performance,bottleneck,bottleneck,910,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:573,reliability,doe,does,573,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:2626,safety,updat,updated,2626,"### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 6.0. zipp NA. zmq 22.3.0. zope NA. -----. IPython 8.2.0. jupyter_client 6.1.12. jupyter_core 4.9.2. jupyterlab 3.3.2. notebook 6.4.8. -----. Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. </details>. -----. Session information updated at 2023-04-18 14:50. ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:2606,security,Session,Session,2606,"### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 6.0. zipp NA. zmq 22.3.0. zope NA. -----. IPython 8.2.0. jupyter_client 6.1.12. jupyter_core 4.9.2. jupyterlab 3.3.2. notebook 6.4.8. -----. Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. </details>. -----. Session information updated at 2023-04-18 14:50. ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:2626,security,updat,updated,2626,"### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 6.0. zipp NA. zmq 22.3.0. zope NA. -----. IPython 8.2.0. jupyter_client 6.1.12. jupyter_core 4.9.2. jupyterlab 3.3.2. notebook 6.4.8. -----. Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. </details>. -----. Session information updated at 2023-04-18 14:50. ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:123,usability,confirm,confirmed,123,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:206,usability,confirm,confirmed,206,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:273,usability,Minim,Minimal,273,"Incorrect clustering on PBMC tutorial.; - [ X] I have checked that this issue has not already been reported. - [ X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.umap(adata). sc.pl.umap(adata, color=['CST3', 'NKG7', 'PPBP']). sc.tl.leiden(adata). sc.pl.umap(adata, color=['leiden', 'CST3', 'NKG7']). ```. ```pytb. The output does not match the clustering of the PBMC3k tutorial. I've downloaded the PBMC notebook from github and my output has clusters 4 and 5 switched., see my output below. How can I rectify this? ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. sess",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:2192,usability,tool,toolz,2192,"### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 6.0. zipp NA. zmq 22.3.0. zope NA. -----. IPython 8.2.0. jupyter_client 6.1.12. jupyter_core 4.9.2. jupyterlab 3.3.2. notebook 6.4.8. -----. Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. </details>. -----. Session information updated at 2023-04-18 14:50. ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2471:2675,usability,user,user-images,2675,"### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.0.1. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.4. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.02.1. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. fsspec 2022.02.0. google NA. h5py 3.6.0. igraph 0.10.4. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.13.5. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.3.1. nbinom_ufunc NA. nt NA. ntsecuritycon NA. numba 0.55.1. numexpr 2.8.1. numpy 1.21.5. packaging 21.3. pandas 1.4.2. parso 0.8.3. patsy 0.5.2. pickleshare 0.7.5. pkg_resources NA. plotly 5.6.0. prompt_toolkit 3.0.20. psutil 5.8.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.8. pyparsing 3.0.4. pythoncom NA. pytz 2021.3. pywintypes NA. ruamel NA. scipy 1.7.3. seaborn 0.11.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.13.2. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. tornado 6.1. tqdm 4.64.0. traitlets 5.1.1. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. win32api NA. win32com NA. win32security NA. yaml 6.0. zipp NA. zmq 22.3.0. zope NA. -----. IPython 8.2.0. jupyter_client 6.1.12. jupyter_core 4.9.2. jupyterlab 3.3.2. notebook 6.4.8. -----. Python 3.9.12 (main, Apr 4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.17763-SP0. </details>. -----. Session information updated at 2023-04-18 14:50. ![image-tr](https://user-images.githubusercontent.com/80623801/232782829-c209af87-b1de-41c1-9a00-f11529a24bcd.JPG).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2471
https://github.com/scverse/scanpy/issues/2472:824,availability,error,error,824,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6004,availability,sli,slice,6004,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6086,availability,error,error,6086,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:31,deployability,fail,fails,31,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:161,deployability,version,version,161,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:878,deployability,log,logging,878,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:966,deployability,version,version,966,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1152,deployability,modul,module,1152,"atest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6048,deployability,Version,Versions,6048,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6102,deployability,log,logging,6102,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6296,deployability,modul,module,6296,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6316,deployability,log,logging,6316,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6386,deployability,log,logging,6386,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6487,deployability,depend,dependencies,6487,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6612,deployability,depend,dependencies,6612,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6778,deployability,modul,modules,6778,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6809,deployability,modul,modules,6809,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6856,deployability,version,version,6856,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6598,energy efficiency,cpu,cpu,6598,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:161,integrability,version,version,161,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:966,integrability,version,version,966,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3941,integrability,messag,message,3941,"batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6048,integrability,Version,Versions,6048,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6487,integrability,depend,dependencies,6487,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6612,integrability,depend,dependencies,6612,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6856,integrability,version,version,6856,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3581,interoperability,share,sharedmem,3581,"9 X,. 330 n_neighbors=n_neighbors,. ~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py in __init__(self, data, metric, metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE054",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3941,interoperability,messag,message,3941,"batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:161,modifiability,version,version,161,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:966,modifiability,version,version,966,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1152,modifiability,modul,module,1152,"atest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1257,modifiability,pac,packages,1257," ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose). 303 random_state = check_random_state(random_state). 304 . --> 305 knn_indices, knn_dists, forest = ne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1595,modifiability,pac,packages,1595,"7928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose). 303 random_state = check_random_state(random_state). 304 . --> 305 knn_indices, knn_dists, forest = nearest_neighbors(. 306 X,. 307 n_neighbors,. ~/.local/lib/python3.8/site-packages/umap/umap_.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, random_state, low_memory, use_pynndescent, n_jobs, verbose). 326 n_iters = max(5, int(round(np.log2(X.shape[0])))). 327 . --> 328 knn_search_index = NNDescent(. 329 X,. 330 n_n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:2025,modifiability,pac,packages,2025,"---------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose). 303 random_state = check_random_state(random_state). 304 . --> 305 knn_indices, knn_dists, forest = nearest_neighbors(. 306 X,. 307 n_neighbors,. ~/.local/lib/python3.8/site-packages/umap/umap_.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, random_state, low_memory, use_pynndescent, n_jobs, verbose). 326 n_iters = max(5, int(round(np.log2(X.shape[0])))). 327 . --> 328 knn_search_index = NNDescent(. 329 X,. 330 n_neighbors=n_neighbors,. ~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py in __init__(self, data, metric, metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:2333,modifiability,pac,packages,2333,"e_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose). 303 random_state = check_random_state(random_state). 304 . --> 305 knn_indices, knn_dists, forest = nearest_neighbors(. 306 X,. 307 n_neighbors,. ~/.local/lib/python3.8/site-packages/umap/umap_.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, random_state, low_memory, use_pynndescent, n_jobs, verbose). 326 n_iters = max(5, int(round(np.log2(X.shape[0])))). 327 . --> 328 knn_search_index = NNDescent(. 329 X,. 330 n_neighbors=n_neighbors,. ~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py in __init__(self, data, metric, metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:2650,modifiability,pac,packages,2650,"self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbose). 303 random_state = check_random_state(random_state). 304 . --> 305 knn_indices, knn_dists, forest = nearest_neighbors(. 306 X,. 307 n_neighbors,. ~/.local/lib/python3.8/site-packages/umap/umap_.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, random_state, low_memory, use_pynndescent, n_jobs, verbose). 326 n_iters = max(5, int(round(np.log2(X.shape[0])))). 327 . --> 328 knn_search_index = NNDescent(. 329 X,. 330 n_neighbors=n_neighbors,. ~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py in __init__(self, data, metric, metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3127,modifiability,pac,packages,3127,"ic_kwds, angular, verbose). 303 random_state = check_random_state(random_state). 304 . --> 305 knn_indices, knn_dists, forest = nearest_neighbors(. 306 X,. 307 n_neighbors,. ~/.local/lib/python3.8/site-packages/umap/umap_.py in nearest_neighbors(X, n_neighbors, metric, metric_kwds, angular, random_state, low_memory, use_pynndescent, n_jobs, verbose). 326 n_iters = max(5, int(round(np.log2(X.shape[0])))). 327 . --> 328 knn_search_index = NNDescent(. 329 X,. 330 n_neighbors=n_neighbors,. ~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py in __init__(self, data, metric, metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3397,modifiability,pac,packages,3397,"metric_kwds, angular, random_state, low_memory, use_pynndescent, n_jobs, verbose). 326 n_iters = max(5, int(round(np.log2(X.shape[0])))). 327 . --> 328 knn_search_index = NNDescent(. 329 X,. 330 n_neighbors=n_neighbors,. ~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py in __init__(self, data, metric, metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3770,modifiability,pac,packages,3770,"egree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4115,modifiability,pac,packages,4115,".8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4252,modifiability,exten,extend,4252," > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4319,modifiability,exten,extend,4319,"t)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/inter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5033,modifiability,pac,packages,5033,"s/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5386,modifiability,pac,packages,5386,"/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5727,modifiability,pac,packages,5727,"tasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6048,modifiability,Version,Versions,6048,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6296,modifiability,modul,module,6296,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6370,modifiability,pac,packages,6370,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6487,modifiability,depend,dependencies,6487,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6552,modifiability,pac,packages,6552,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6612,modifiability,depend,dependencies,6612,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6778,modifiability,modul,modules,6778,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6809,modifiability,modul,modules,6809,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6856,modifiability,version,version,6856,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:824,performance,error,error,824,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3552,performance,Parallel,Parallel,3552,"_search_index = NNDescent(. 329 X,. 330 n_neighbors=n_neighbors,. ~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py in __init__(self, data, metric, metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3786,performance,parallel,parallel,3786,", diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3993,performance,time,time,3993," 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3998,performance,time,time,3998,"). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4131,performance,parallel,parallel,4131,"/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4267,performance,time,timeout,4267,"eturn np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4280,performance,time,timeout,4280,"ck(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and rer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4460,performance,time,timeout,4460,"orest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5402,performance,parallel,parallel,5402,"is/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5743,performance,parallel,parallel,5743,"ption). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.appen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6086,performance,error,error,6086,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6598,performance,cpu,cpu,6598,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:31,reliability,fail,fails,31,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:904,reliability,doe,doesn,904,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6004,reliability,sli,slice,6004,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:824,safety,error,error,824,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:878,safety,log,logging,878,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1125,safety,input,input-,1125,"ed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1152,safety,modul,module,1152,"atest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, metric_kwds, angular, verbos",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4267,safety,timeout,timeout,4267,"eturn np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4280,safety,timeout,timeout,4280,"ck(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and rer",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4460,safety,timeout,timeout,4460,"orest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4852,safety,except,except,4852,"nd.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(sel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4859,safety,Except,Exception,4859,"val_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5206,safety,except,except,5206,"ts_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ----------------------------------------------------------------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6015,safety,input,input,6015,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6086,safety,error,error,6086,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6102,safety,log,logging,6102,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6269,safety,input,input-,6269,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6296,safety,modul,module,6296,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6316,safety,log,logging,6316,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6386,safety,log,logging,6386,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6487,safety,depend,dependencies,6487,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6612,safety,depend,dependencies,6612,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6778,safety,modul,modules,6778,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6809,safety,modul,modules,6809,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:878,security,log,logging,878,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6102,security,log,logging,6102,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6316,security,log,logging,6316,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6386,security,log,logging,6386,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:878,testability,log,logging,878,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1081,testability,Trace,Traceback,1081,"ready been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_um",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6102,testability,log,logging,6102,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6225,testability,Trace,Traceback,6225,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6316,testability,log,logging,6316,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6386,testability,log,logging,6386,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6487,testability,depend,dependencies,6487,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6612,testability,depend,dependencies,6612,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:121,usability,confirm,confirmed,121,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:204,usability,confirm,confirmed,204,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:295,usability,guid,guide,295,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:350,usability,minim,minimal-bug-reports,350,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:456,usability,Minim,Minimal,456,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:802,usability,command,command,802,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:824,usability,error,error,824,"neighborhood graph computation fails; - [ x] I have checked that this issue has not already been reported. - [ x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:1125,usability,input,input-,1125,"ed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). The data looks like this. ```pytb. AnnData object with n_obs × n_vars = 17928 × 3101. obs: 'n_genes_by_counts', 'total_counts'. var: 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'log1p', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. This is the command that leads to error:. ```python. sc.pp.neighbors(adata ). ```. ` sc.logging.print_versions()` doesn't produce the correct output (see bellow), but scanpy's version is 1.9.3. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-79-c7d46fa554b4> in <module>. ----> 1 sc.pp.neighbors(adata,n_pcs = num_comp,n_neighbors = 100 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, key_added, copy). 137 adata._init_as_actual(adata.copy()). 138 neighbors = Neighbors(adata). --> 139 neighbors.compute_neighbors(. 140 n_neighbors=n_neighbors,. 141 knn=knn,. ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 792 X = pairwise_distances(X, metric=metric, **metric_kwds). 793 metric = 'precomputed'. --> 794 knn_indices, knn_distances, forest = compute_neighbors_umap(. 795 X, n_neighbors, random_state, metric=metric, metric_kwds=metric_kwds. 796 ). ~/.local/lib/python3.8/site-packages/scanpy/neighbors/__init__.py in compute_neighbors_umap(X, n_neighbors, random_state, metric, m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:3715,usability,user,users,3715," metric_kwds, n_neighbors, n_trees, leaf_size, pruning_degree_multiplier, diversify_prob, n_search_trees, tree_init, init_graph, init_dist, random_state, low_memory, max_candidates, n_iters, delta, n_jobs, compressed, parallel_batch_queries, verbose). 802 self._angular_trees,. 803 ). --> 804 leaf_array = rptree_leaf_array(self._rp_forest). 805 else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4060,usability,user,users,4060," else:. 806 self._rp_forest = None. ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array(rp_forest). 1095 def rptree_leaf_array(rp_forest):. 1096 if len(rp_forest) > 0:. -> 1097 return np.vstack(rptree_leaf_array_parallel(rp_forest)). 1098 else:. 1099 return np.array([[-1]]). ~/.local/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_back",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4373,usability,user,users,4373,"l/lib/python3.8/site-packages/pynndescent/rp_trees.py in rptree_leaf_array_parallel(rp_forest). 1087 . 1088 def rptree_leaf_array_parallel(rp_forest):. -> 1089 result = joblib.Parallel(n_jobs=-1, require=""sharedmem"")(. 1090 joblib.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/pytho",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4602,usability,user,users,4602,"b.delayed(get_leaves_from_tree)(rp_tree) for rp_tree in rp_forest. 1091 ). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self, iterable). 1054 . 1055 with self._backend.retrieval_context():. -> 1056 self.retrieve(). 1057 # Make sure that we get a last message telling us we are done. 1058 elapsed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:4978,usability,user,users,4978,"psed_time = time.time() - self._start_time. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in retrieve(self). 933 try:. 934 if getattr(self._backend, 'supports_timeout', False):. --> 935 self._output.extend(job.get(timeout=self.timeout)). 936 else:. 937 self._output.extend(job.get()). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . Val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5331,usability,user,users,5331,")). /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in get(self, timeout). 769 return self._value. 770 else:. --> 771 raise self._value. 772 . 773 def _set(self, i, obj):. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/multiprocessing/pool.py in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:5672,usability,user,users,5672," in worker(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception). 123 job, i, func, args, kwds = task. 124 try:. --> 125 result = (True, func(*args, **kwds)). 126 except Exception as e:. 127 if wrap_exception and func is not _helper_reraises_exception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6015,usability,input,input,6015,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6086,usability,error,error,6086,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2472:6269,usability,input,input-,6269,"xception:. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/_parallel_backends.py in __call__(self, *args, **kwargs). 593 def __call__(self, *args, **kwargs):. 594 try:. --> 595 return self.func(*args, **kwargs). 596 except KeyboardInterrupt as e:. 597 # We capture the KeyboardInterrupt and reraise it as. /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in __call__(self). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . /omics/groups/OE0540/internal/B260/users/olga/.conda/envs/10x_analysis/lib/python3.8/site-packages/joblib/parallel.py in <listcomp>(.0). 260 # change the default number of processes to -1. 261 with parallel_backend(self._backend, n_jobs=self._n_jobs):. --> 262 return [func(*args, **kwargs). 263 for func, args, kwargs in self.items]. 264 . ValueError: cannot assign slice from input of different size```. #### Versions. ```. <details>. here is the error from ` sc.logging.print_versions()` . ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-81-c71c26e11b3b> in <module>. ----> 1 sc.logging.print_versions(). ~/.local/lib/python3.8/site-packages/scanpy/logging.py in print_versions(file). 178 print_versions(). 179 else:. --> 180 session_info.show(. 181 dependencies=True,. 182 html=False,. ~/.local/lib/python3.8/site-packages/session_info/main.py in show(na, os, cpu, jupyter, dependencies, std_lib, private, write_req_file, req_file_name, html, excludes). 207 for mod_name in clean_modules:. 208 mod_names.append(mod_name). --> 209 mod = sys.modules[mod_name]. 210 # Since modules use different attribute names to store version info,. 211 # try the most common ones. KeyError: 'dask'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2472
https://github.com/scverse/scanpy/issues/2473:100,availability,cluster,clustering,100,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:260,availability,error,error,260,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:546,availability,Error,Error,546,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2327,availability,error,error,2327,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:100,deployability,cluster,clustering,100,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:795,deployability,modul,module,795,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2350,deployability,build,build,2350,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2546,deployability,Version,Versions,2546,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2416,energy efficiency,current,current,2416,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2525,energy efficiency,alloc,allocated,2525,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1115,integrability,wrap,wrapped,1115,"](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2546,integrability,Version,Versions,2546,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:795,modifiability,modul,module,795,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:908,modifiability,pac,packages,908,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1062,modifiability,pac,packages,1062,"he tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1233,modifiability,pac,packages,1233," run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, info",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1250,modifiability,deco,decomposition,1250,"ng error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1392,modifiability,pac,packages,1392,"c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) retu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1409,modifiability,deco,decomposition,1409,"842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1584,modifiability,pac,packages,1584,"able, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1601,modifiability,deco,decomposition,1601,"e block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1776,modifiability,pac,packages,1776,", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1968,modifiability,pac,packages,1968,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2127,modifiability,pac,packages,2127,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2546,modifiability,Version,Versions,2546,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:260,performance,error,error,260,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:546,performance,Error,Error,546,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:708,performance,memor,memory-tcell-scRNA-seq,708,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2327,performance,error,error,2327,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:260,safety,error,error,260,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:546,safety,Error,Error,546,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:772,safety,test,test,772,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:795,safety,modul,module,795,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2327,safety,error,error,2327,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:632,testability,Trace,Traceback,632,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:772,testability,test,test,772,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:260,usability,error,error,260,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:546,usability,Error,Error,546,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:675,usability,User,Users,675,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:708,usability,memor,memory-tcell-scRNA-seq,708,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:850,usability,User,Users,850,"ArpackError in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_ei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1004,usability,User,Users,1004,"rror in sc.tl.pca ; <!-- Describe the bug -->. I followed the tutorial on [Preprocessing and clustering 3k PBMCs](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1175,usability,User,Users,1175,"html). The first steps worked quit well, but when I want to run PCA the following error occurs (see below). <!-- To reproduce -->. Follow the tutorial ([pbmc3k.ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1334,usability,User,Users,1334,".ipynb](https://github.com/scverse/scanpy-tutorials/blob/75c5ebb5b63769aee65f38842a34b7f7e1bbd476/pbmc3k.ipynb)) until the following line:. ```python. sc.tl.pca(adata, svd_solver='arpack'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -999",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1526,usability,User,Users,1526,"`. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""/Users/pbinder/Nextcloud/projects/memory-tcell-scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1718,usability,User,Users,1718,"scRNA-seq/tutorials/scanpy/scanpy-tutorials-master/test.py"", line 51, in <module>. sc.tl.pca(adata, svd_solver='arpack'). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:1910,usability,User,Users,1910,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2069,usability,User,Users,2069,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2327,usability,error,error,2327,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2451,usability,user,user,2451,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2601,usability,tool,tools,2601,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2473:2720,usability,learn,learn,2720,"conda3/envs/scRNA/lib/python3.9/site-packages/scanpy/preprocessing/_pca.py"", line 188, in pca. X_pca = pca_.fit_transform(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/utils/_set_output.py"", line 140, in wrapped. data_to_wrap = f(self, X, *args, **kwargs). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 462, in fit_transform. U, S, Vt = self._fit(X). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 514, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/sklearn/decomposition/_pca.py"", line 609, in _fit_truncated. U, S, Vt = svds(X, k=n_components, tol=self.tol, v0=v0). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/_svds.py"", line 532, in svds. _, eigvec = eigsh(XH_X, k=k, tol=tol ** 2, maxiter=maxiter,. File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 1697, in eigsh. params.iterate(). File ""/Users/pbinder/opt/anaconda3/envs/scRNA/lib/python3.9/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py"", line 573, in iterate. raise ArpackError(self.info, infodict=self.iterate_infodict). scipy.sparse.linalg._eigen.arpack.arpack.ArpackError: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated. ```. #### Versions:. <!-- Output of scvi.__version__ -->. > scvi-tools==0.20.3 python==3.9.16 scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==1.5.3 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.4 pynndescent==0.5.10. and macOS 13.2 (intel). > . <!-- Relevant screenshots -->. Thanks. Patrick.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2473
https://github.com/scverse/scanpy/issues/2474:218,deployability,version,version,218,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1016,deployability,log,log,1016,"r: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3311,deployability,Version,Versions,3311,"ect.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5606,deployability,updat,updated,5606,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:90,energy efficiency,model,model,90,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:337,energy efficiency,model,model,337,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:384,energy efficiency,model,model,384,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:428,energy efficiency,model,model,428,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:480,energy efficiency,model,model,480,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:501,energy efficiency,model,model,501,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1946,energy efficiency,core,core,1946,"oublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2504,energy efficiency,core,core,2504,"ategories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2628,energy efficiency,core,core,2628,"_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2907,energy efficiency,core,core,2907,"/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:218,integrability,version,version,218,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3311,integrability,Version,Versions,3311,"ect.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:4514,interoperability,platform,platformdirs,4514,"_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [G",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:218,modifiability,version,version,218,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:796,modifiability,pac,packages,796,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1322,modifiability,pac,packages,1322,"did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1930,modifiability,pac,packages,1930,"kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:23",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2488,modifiability,pac,packages,2488,"'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2891,modifiability,pac,packages,2891,"a3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidget",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3311,modifiability,Version,Versions,3311,"ect.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3660,modifiability,deco,decorator,3660,"e. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:4419,modifiability,pac,packaging,4419,ckcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. no,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5462,modifiability,pac,packaged,5462,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1971,performance,Cach,CachedAccessor,1971,"p.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2269,performance,cach,cached-property,2269,"~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1016,safety,log,log,1016,"r: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5606,safety,updat,updated,5606,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:39,security,access,accessor,39,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:90,security,model,model,90,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:337,security,model,model,337,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:384,security,model,model,384,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:428,security,model,model,428,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:480,security,model,model,480,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:501,security,model,model,501,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1016,security,log,log,1016,"r: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1951,security,access,accessor,1951,"adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2044,security,access,accessing,2044,"201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dty",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2208,security,access,accessor,2208,"BELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2517,security,access,accessor,2517," 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:2920,security,access,accessor,2920,"/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if obj is None:. 222 # we're accessing the attribute of the class, i.e., Dataset.geo. 223 return self._accessor. --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3123,security,access,accessor,3123," --> 224 accessor_obj = self._accessor(obj). 225 # Replace the property with the accessor object. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3216,security,access,accessor,3216,"ect. Inspired by:. 226 # https://www.pydanny.com/cached-property.html. 227 # We need to use object.__setattr__ because we overwrite __setattr__ on. 228 # NDFrame. 229 object.__setattr__(obj, self._name, accessor_obj). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:3480,security,certif,certifi,3480,"ite-packages/pandas/core/strings/accessor.py:181, in StringMethods.__init__(self, data). 178 def __init__(self, data) -> None:. 179 from pandas.core.arrays.string_ import StringDtype. --> 181 self._inferred_dtype = self._validate(data). 182 self._is_categorical = is_categorical_dtype(data.dtype). 183 self._is_string = isinstance(data.dtype, StringDtype). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/strings/accessor.py:235, in StringMethods._validate(data). 232 inferred_dtype = lib.infer_dtype(values, skipna=True). 234 if inferred_dtype not in allowed_types:. --> 235 raise AttributeError(""Can only use .str accessor with string values!""). 236 return inferred_dtype. AttributeError: Can only use .str accessor with string values! ```. I did try to eleminate empty cells, but it didn't work. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. absl NA. asttokens NA. attr 22.1.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. chex 0.1.7. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickles",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5007,security,soc,socks,5007,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5586,security,Session,Session,5586,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5606,security,updat,updated,5606,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:634,testability,Trace,Traceback,634,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:1016,testability,log,log,1016,"r: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, obj, cls). 221 if ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:178,usability,confirm,confirmed,178,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:261,usability,confirm,confirmed,261,"Got `AttributeError: Can only use .str accessor with string values!` when initiating solo model; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I did create model with adata. ```python. import scvi. scvi.model.SCVI.setup_anndata(adata). vae = scvi.model.SCVI(adata). vae.train(). ```. initialize the model using the scvi.model.SCVI object. ```python. solo = scvi.external.SOLO.from_scvi_model(vae). ```. And I got AttributeError. ```pytb. AttributeError Traceback (most recent call last). Cell In[29], line 1. ----> 1 solo = scvi.external.SOLO.from_scvi_model(vae). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/scvi/external/solo/_model.py:204, in SOLO.from_scvi_model(cls, scvi_model, adata, restrict_to_batch, doublet_ratio, **classifier_kwargs). 199 doublet_adata = AnnData(. 200 np.concatenate([doublet_latent_rep, np.log(doublet_lib_size)], axis=1). 201 ). 202 doublet_adata.obs[LABELS_KEY] = ""doublet"". --> 204 full_adata = latent_adata.concatenate(doublet_adata). 205 cls.setup_anndata(full_adata, labels_key=LABELS_KEY). 206 return cls(full_adata, **classifier_kwargs). File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/anndata/_core/anndata.py:1808, in AnnData.concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1799 pat = rf""-({'|'.join(batch_categories)})$"". 1800 out.var = merge_dataframes(. 1801 [a.var for a in all_adatas],. 1802 out.var_names,. 1803 partial(merge_outer, batch_keys=batch_categories, merge=merge_same),. 1804 ). 1805 out.var = out.var.iloc[. 1806 :,. 1807 (. -> 1808 out.var.columns.str.extract(pat, expand=False). 1809 .fillna(""""). 1810 .argsort(kind=""stable""). 1811 ),. 1812 ]. 1814 return out. File ~/miniconda3/envs/scanpy/lib/python3.10/site-packages/pandas/core/accessor.py:224, in CachedAccessor.__get__(self, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5110,usability,tool,toolz,5110,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2474:5663,usability,help,help,5663,"or 5.1.1. defusedxml 0.7.1. docrep 0.3.2. executing 0.8.3. flax 0.6.1. fsspec 2023.4.0. gmpy2 2.1.2. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.19.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. jax 0.4.8. jaxlib 0.4.7. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.4. lightning_utilities 0.8.0. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mkl 2.4.0. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. mpmath 1.2.1. msgpack 1.0.5. mudata 0.2.2. multipledispatch 0.6.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. numpyro 0.11.0. nvfuser NA. opt_einsum v3.3.0. optax 0.1.5. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.2.0. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pytorch_lightning 1.9.4. pytz 2023.3. requests 2.28.1. rich NA. scipy 1.10.1. scvi 0.20.3. seaborn 0.12.2. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. skmisc 0.1.4. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.5. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. toolz 0.12.0. torch 2.0.0. torchmetrics 0.11.4. torchvision 0.15.0. tornado 6.2. tqdm 4.65.0. traitlets 5.7.1. tree 0.1.7. typing_extensions NA. unicodedata2 NA. urllib3 1.26.15. wcwidth 0.2.5. yaml 6.0. zmq 23.2.0. zoneinfo NA. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-40-generic-x86_64-with-glibc2.35. -----. Session information updated at 2023-04-26 05:02. </details>. Thanks for your help",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2474
https://github.com/scverse/scanpy/issues/2475:22,deployability,API,API,22,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:816,deployability,compos,compositional,816,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:951,deployability,scale,scale,951,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1022,deployability,compos,compositional,1022,"riant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replace",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1166,deployability,compos,compositions,1166,"ction parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.compositi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1356,deployability,compos,compositional,1356,"kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicativ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1663,deployability,version,versions,1663,"rap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1707,deployability,API,API,1707,"cology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2163,deployability,compos,composition,2163," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2196,deployability,compos,composition,2196," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2488,deployability,log,log,2488," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:951,energy efficiency,scale,scale,951,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1346,energy efficiency,model,model,1346,"g function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1512,energy efficiency,adapt,adapting,1512,"- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1564,energy efficiency,power,power,1564,"n the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:7,integrability,transform,transformation,7,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:22,integrability,API,API,22,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:666,integrability,wrap,wrap,666,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1512,integrability,adapt,adapting,1512,"- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1636,integrability,transform,transformations,1636,"olespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1663,integrability,version,versions,1663,"rap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1707,integrability,API,API,1707,"cology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2681,integrability,transform,transformation,2681," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:7,interoperability,transform,transformation,7,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:22,interoperability,API,API,22,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1466,interoperability,soap,soap,1466,"should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1512,interoperability,adapt,adapting,1512,"- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1636,interoperability,transform,transformations,1636,"olespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1707,interoperability,API,API,1707,"cology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2681,interoperability,transform,transformation,2681," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:178,modifiability,paramet,parameters,178,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:455,modifiability,pac,package,455,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:816,modifiability,compos,compositional,816,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:951,modifiability,scal,scale,951,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1022,modifiability,compos,compositional,1022,"riant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replace",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1166,modifiability,compos,compositions,1166,"ction parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.compositi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1356,modifiability,compos,compositional,1356,"kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicativ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1466,modifiability,soa,soap,1466,"should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1512,modifiability,adapt,adapting,1512,"- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1663,modifiability,version,versions,1663,"rap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata ob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2163,modifiability,compos,composition,2163," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2196,modifiability,compos,composition,2196," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2710,modifiability,layer,layers,2710," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:951,performance,scale,scale,951,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1195,safety,review,review,1195," functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2488,safety,log,log,2488," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1346,security,model,model,1346,"g function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2488,security,log,log,2488," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:260,testability,simpl,simple,260,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1133,testability,Understand,Understanding,1133,"quest? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1195,testability,review,review,1195," functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2218,testability,assert,assert,2218," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:2488,testability,log,log,2488," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:0,usability,Custom,Custom,0,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:252,usability,tool,tool,252,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:260,usability,simpl,simple,260,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:276,usability,tool,tool,276,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:324,usability,tool,tools,324,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:424,usability,tool,tools,424,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:609,usability,workflow,workflows,609,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:748,usability,learn,learning,748,"Custom transformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1008,usability,guid,guide,1008,"sformation API (variant of scanpy.pp.normalize_total such as scanpy.pp.normalize); <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], mult",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1524,usability,workflow,workflows,1524,"ribe your wishes below: -->. ... I'm in the process of redesigning my most used workflows from https://github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1629,usability,custom,custom,1629,"github.com/jolespin/soothsayer to wrap around ScanPy. I come from microbial ecology but do a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, fun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2475:1857,usability,custom,custom,1857," a good amount of machine learning. In microbial ecology, the community is shifting towards a compositional data analysis (CoDA) approach which has fundamentals firmly rooted in mathematics. . Here is some literature about broad-scale applications across all NGS datasets: . * [A field guide for the compositional analysis of any-omics data](https://academic.oup.com/gigascience/article/8/9/giz107/5572529). * [Understanding sequencing data as compositions: an outlook and review](https://academic.oup.com/bioinformatics/article/34/16/2870/4956011). it is even catching attention in scRNA-seq too: . * [scCODA is a Bayesian model for compositional single-cell data analysis](https://www.nature.com/articles/s41467-021-27150-6). Anyways, off my soap box. As mentioned, I'm in the process of adapting my workflows to take advantage of ScanPy's power but I'm having a few difficulties. The first incorporating custom transformations. In future versions, would it be possible to create an API that is similar to [scanpy.pp.normalize_total)(https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.normalize_total.html) but allows for a custom metric? . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. kwargs = {""multiplicative_replacement"":""auto""}. sc.pp.normalize(adata, function=clr, **kwargs) # -> addata object with the transformation as one of the layers. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2475
https://github.com/scverse/scanpy/issues/2476:543,deployability,compos,compositional,543,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1090,deployability,compos,composition,1090,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1123,deployability,compos,composition,1123,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1415,deployability,log,log,1415,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:520,energy efficiency,adapt,adapting,520,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:520,integrability,adapt,adapting,520,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:520,interoperability,adapt,adapting,520,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:32,modifiability,layer,layer,32,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:132,modifiability,paramet,parameters,132,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:409,modifiability,pac,package,409,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:520,modifiability,adapt,adapting,520,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:543,modifiability,compos,compositional,543,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1090,modifiability,compos,composition,1090,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1123,modifiability,compos,composition,1123,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1498,modifiability,layer,layers,1498,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1512,modifiability,layer,layers,1512,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1647,modifiability,layer,layer,1647,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:685,performance,perform,perform,685,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1699,performance,perform,performed,1699,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1415,safety,log,log,1415,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1415,security,log,log,1415,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:214,testability,simpl,simple,214,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1145,testability,assert,assert,1145,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1415,testability,log,log,1415,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:206,usability,tool,tool,206,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:214,usability,simpl,simple,214,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:230,usability,tool,tool,230,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:278,usability,tool,tools,278,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:378,usability,tool,tools,378,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:685,usability,perform,perform,685,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2476:1699,usability,perform,performed,1699,"Allow scanpy.tl.pca to accept a layer argument; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... I'm adapting ScanPy for my compositional data analysis (CoDA) methodologies in the same vein as https://github.com/scverse/scanpy/issues/2475 . In this, I would like to perform Aitchison PCA but I'd also like to keep my Anndata object in counts form instead of creating another one. . For example: . ```python. import numpy as np. import pandas as pd. from typing import Union. def clr(x:Union[np.ndarray, pd.Series], multiplicative_replacement:Union[None,str,float,int]=""auto"") -> Union[np.ndarray, pd.Series]:. """""". http://scikit-bio.org/docs/latest/generated/skbio.stats.composition.clr.html#skbio.stats.composition.clr. """""". assert np.all(x >= 0). if multiplicative_replacement == ""auto"":. if np.any(x == 0):. multiplicative_replacement = 1/(len(x)**2). if multiplicative_replacement is None:. multiplicative_replacement = 0. x = x.copy() + multiplicative_replacement. x = x/x.sum(). log_x = np.log(x). geometric_mean = log_x.mean(). return log_x - geometric_mean. # Add CLR to layers. adata.layers[""clr""] = adata.to_df().apply(clr, axis=1) # Not the fastest way but just to show example. sc.tl.pca(adata, svd_solver='arpack', layer=""clr"") # -> Return addata object where PCA is performed on CLR. ```. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2476
https://github.com/scverse/scanpy/issues/2477:176,deployability,version,version,176,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1003,deployability,Version,Versions,1003,"map not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1310,deployability,compos,compositional,1310,"https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:3172,deployability,updat,updated,3172," 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]. macOS-12.6-x86_64-i386-64bit. -----. Session information updated at 2023-04-27 15:56. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:176,integrability,version,version,176,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:608,integrability,sub,subplots,608,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1003,integrability,Version,Versions,1003,"map not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:2149,interoperability,platform,platformdirs,2149,"0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]. macOS-12.6-x86_64-i386-64bit. -----. Ses",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:176,modifiability,version,version,176,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1003,modifiability,Version,Versions,1003,"map not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1310,modifiability,compos,compositional,1310,"https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1400,modifiability,deco,decorator,1400,"ovide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:2023,modifiability,pac,packaging,2023,-. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:3042,modifiability,pac,packaged,3042," 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]. macOS-12.6-x86_64-i386-64bit. -----. Session information updated at 2023-04-27 15:56. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1200,performance,cach,cachecontrol,1200,"onal) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1979,performance,network,networkx,1979,2c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:3172,safety,updat,updated,3172," 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]. macOS-12.6-x86_64-i386-64bit. -----. Session information updated at 2023-04-27 15:56. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1222,security,certif,certifi,1222,"ed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:1979,security,network,networkx,1979,2c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:2603,security,soc,socks,2603," 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]. macOS-12.6-x86_64-i386-64bit. -----. Session information updated at 2023-04-27 15:56. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:3152,security,Session,Session,3152," 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]. macOS-12.6-x86_64-i386-64bit. -----. Session information updated at 2023-04-27 15:56. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:3172,security,updat,updated,3172," 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba 0.55.1. numpy 1.21.5. packaging 21.3. palettable 3.3.0. pandas 1.4.0. parso 0.8.3. patsy 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.3.0. prompt_toolkit 3.0.26. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.1. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pynndescent 0.5.6. pyparsing 3.0.7. pytz 2021.3. pytz_deprecation_shim NA. requests 2.27.1. rpy2 3.5.6. scipy 1.8.0. seaborn 0.11.2. session_info 1.0.0. setuptools 60.7.1. sip NA. six 1.16.0. skbio 0.5.6. sklearn 1.0.2. socks 1.7.1. soothsayer 2022.8.31. soothsayer_utils 2022.6.24. stack_data 0.1.4. statsmodels 0.13.1. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. tqdm 4.62.3. traitlets 5.1.1. typing_extensions NA. tzlocal NA. umap 0.5.2. unicodedata2 NA. urllib3 1.26.8. wcwidth 0.2.5. xarray 2023.1.0. zmq 24.0.1. zoneinfo NA. -----. IPython 8.0.1. jupyter_client 7.3.4. jupyter_core 5.0.0. jupyterlab 3.5.2. notebook 6.5.2. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) [Clang 14.0.6 ]. macOS-12.6-x86_64-i386-64bit. -----. Session information updated at 2023-04-27 15:56. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:567,testability,context,context,567,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:136,usability,confirm,confirmed,136,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:219,usability,confirm,confirmed,219,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:310,usability,guid,guide,310,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:365,usability,minim,minimal-bug-reports,365,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:471,usability,Minim,Minimal,471,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/issues/2477:903,usability,user,user-images,903,"sc.pl.umap not properly handling Matplotlib ax object; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. with plt.style.context(""seaborn-white""):. fig, ax = plt.subplots(figsize=(8,8)). sc.pl.umap(adata_clr, color=['id_jira'], ax=ax, s=200 ). fig.suptitle(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE SUPTITLE]"", fontsize=15). ax.set_title(""SOLEXASEQ-1672/1680 | Aitchison Distance [THIS SHOULD BE TITLE]"", fontsize=15). ```. ![image](https://user-images.githubusercontent.com/9061708/235007925-b7e1c2ae-924c-4fb3-b840-b2d12c15725f.png). #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.3. -----. Bio 1.79. PIL 9.0.1. PyQt5 NA. adjustText NA. appnope 0.1.2. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. cachecontrol 0.12.10. certifi 2022.12.07. cffi 1.15.0. charset_normalizer 2.0.11. colorama 0.4.4. comm 0.1.1. compositional 2022.8.31. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.4. decorator 5.1.1. defusedxml 0.7.1. ensemble_networkx 2023.1.23. entrypoints 0.4. ete3 3.1.2. executing 0.8.2. fastcluster 1.1.26. fontTools 4.29.1. h5py 3.7.0. hdmedians NA. hive_networkx 2021.05.18. hypergeom_ufunc NA. idna 3.3. igraph 0.10.2. ipykernel 6.19.4. ipython_genutils 0.2.0. ipywidgets 8.0.4. jedi 0.18.1. jinja2 3.0.3. joblib 1.1.0. jupyter_server 1.23.4. kiwisolver 1.3.2. leidenalg 0.9.1. llvmlite 0.38.0. lxml 4.7.1. markupsafe 2.0.1. matplotlib 3.5.1. matplotlib_inline NA. matplotlib_venn 0.11.6. mpl_toolkits NA. msgpack 1.0.3. natsort 8.1.0. nbinom_ufunc NA. networkx 2.6.3. numba",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2477
https://github.com/scverse/scanpy/pull/2478:17,deployability,releas,release,17,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:25,deployability,depend,dependencies,25,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:104,deployability,pipelin,pipelines,104,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:39,energy efficiency,adapt,adapted,39,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:25,integrability,depend,dependencies,25,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:39,integrability,adapt,adapted,39,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:104,integrability,pipelin,pipelines,104,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:39,interoperability,adapt,adapted,39,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:25,modifiability,depend,dependencies,25,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:39,modifiability,adapt,adapted,39,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:0,safety,Test,Test,0,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:25,safety,depend,dependencies,25,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:338,safety,review,review,338,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:0,testability,Test,Test,0,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:25,testability,depend,dependencies,25,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:338,testability,review,review,338,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:189,usability,guid,guidelines,189,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:220,usability,guid,guide,220,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/pull/2478:316,usability,workflow,workflow,316,Test against pre-release dependencies; adapted from https://github.com/scverse/anndata/blob/main/.azure-pipelines.yml. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2478
https://github.com/scverse/scanpy/issues/2479:1057,availability,Error,Error,1057," have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:174,deployability,version,version,174,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:535,deployability,modul,modules,535,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:599,deployability,instal,installed,599,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:620,deployability,version,version,620,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:639,deployability,instal,installed,639,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:660,deployability,version,version,660,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:723,deployability,instal,installed,723,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8412,deployability,Version,Versions,8412,"iniconda3/envs/scvi/lib/libzstd.so.1.5.5. 7f7411603000-7f7411604000 rw-p 0010e000 fd:03 277081168 /home/dgc88/miniconda3/envs/scvi/lib/libzstd.so.1.5.5. 7f7411604000-7f7411607000 r--p 00000000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411607000-7f7411679000 r-xp 00003000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_ME",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8631,deployability,version,version,8631,"8/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411607000-7f7411679000 r-xp 00003000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8826,deployability,version,versions,8826,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8961,deployability,version,version,8961,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:9589,energy efficiency,load,loaded,9589,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:174,integrability,version,version,174,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:620,integrability,version,version,620,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:660,integrability,version,version,660,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8412,integrability,Version,Versions,8412,"iniconda3/envs/scvi/lib/libzstd.so.1.5.5. 7f7411603000-7f7411604000 rw-p 0010e000 fd:03 277081168 /home/dgc88/miniconda3/envs/scvi/lib/libzstd.so.1.5.5. 7f7411604000-7f7411607000 r--p 00000000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411607000-7f7411679000 r-xp 00003000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_ME",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8631,integrability,version,version,8631,"8/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411607000-7f7411679000 r-xp 00003000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8826,integrability,version,versions,8826,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8961,integrability,version,version,8961,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8989,interoperability,Platform,Platform,8989,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:174,modifiability,version,version,174,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:535,modifiability,modul,modules,535,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:620,modifiability,version,version,620,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:660,modifiability,version,version,660,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:3885,modifiability,pac,packages,3885,0x40079b]. ======= Memory map: ========. 00400000-00401000 r-xp 00000000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 00600000-00601000 r--p 00000000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 00601000-00602000 rw-p 00001000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 010fc000-12e0b000 rw-p 00000000 00:00 0 [heap]. 7f7410d3d000-7f7410d6c000 r--p 00000000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410d6c000-7f7410f35000 r-xp 0002f000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410f35000-7f7410fe3000 r--p 001f8000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe3000-7f7410fe7000 r--p 002a6000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe7000-7f7410fe8000 rw-p 002aa000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7410ff6000-7f7411012000 r-xp 0000e000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7411012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:4054,modifiability,pac,packages,4054,opt/R/4.2.3/lib64/R/bin/exec/R. 00601000-00602000 rw-p 00001000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 010fc000-12e0b000 rw-p 00000000 00:00 0 [heap]. 7f7410d3d000-7f7410d6c000 r--p 00000000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410d6c000-7f7410f35000 r-xp 0002f000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410f35000-7f7410fe3000 r--p 001f8000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe3000-7f7410fe7000 r--p 002a6000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe7000-7f7410fe8000 rw-p 002aa000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7410ff6000-7f7411012000 r-xp 0000e000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7411012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 2770,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:4223,modifiability,pac,packages,4223,000-7f7410d6c000 r--p 00000000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410d6c000-7f7410f35000 r-xp 0002f000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410f35000-7f7410fe3000 r--p 001f8000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe3000-7f7410fe7000 r--p 002a6000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe7000-7f7410fe8000 rw-p 002aa000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7410ff6000-7f7411012000 r-xp 0000e000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7411012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 27707,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:4392,modifiability,pac,packages,4392,/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410f35000-7f7410fe3000 r--p 001f8000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe3000-7f7410fe7000 r--p 002a6000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe7000-7f7410fe8000 rw-p 002aa000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7410ff6000-7f7411012000 r-xp 0000e000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7411012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:4561,modifiability,pac,packages,4561,0-7f7410fe7000 r--p 002a6000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe7000-7f7410fe8000 rw-p 002aa000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7410ff6000-7f7411012000 r-xp 0000e000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7411012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411342000-7f7411343000 rw-p 00025000 fd:03 2770763,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:4781,modifiability,pac,packages,4781,e8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7410ff6000-7f7411012000 r-xp 0000e000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7411012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411342000-7f7411343000 rw-p 00025000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411343000-7f7411443000 rw-p 00000000 00:00 0. 7f7411443000-7f7411444000 r--p 00000000 fd:03 106254919 ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:4949,modifiability,pac,packages,4949,ff6000-7f7411012000 r-xp 0000e000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f7411012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411342000-7f7411343000 rw-p 00025000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411343000-7f7411443000 rw-p 00000000 00:00 0. 7f7411443000-7f7411444000 r--p 00000000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411444000-7f7411451000 r-xp 00001000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f74,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:5117,modifiability,pac,packages,5117,1012000-7f741101a000 r--p 0002a000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411342000-7f7411343000 rw-p 00025000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411343000-7f7411443000 rw-p 00000000 00:00 0. 7f7411443000-7f7411444000 r--p 00000000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411444000-7f7411451000 r-xp 00001000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411451000-7f7411456000 r--p 0000e000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411456000-7f7411457000 r--p 00012000 fd:03 106254919 /home/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:5285,modifiability,pac,packages,5285,1101a000-7f741101b000 r--p 00032000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411342000-7f7411343000 rw-p 00025000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411343000-7f7411443000 rw-p 00000000 00:00 0. 7f7411443000-7f7411444000 r--p 00000000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411444000-7f7411451000 r-xp 00001000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411451000-7f7411456000 r--p 0000e000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411456000-7f7411457000 r--p 00012000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411457000-7f7411458000 rw-p 00013000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f74114580,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:5453,modifiability,pac,packages,5453,41101b000-7f741101c000 rw-p 00033000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leiden.cpython-310-x86_64-linux-gnu.so. 7f741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411342000-7f7411343000 rw-p 00025000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411343000-7f7411443000 rw-p 00000000 00:00 0. 7f7411443000-7f7411444000 r--p 00000000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411444000-7f7411451000 r-xp 00001000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411451000-7f7411456000 r--p 0000e000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411456000-7f7411457000 r--p 00012000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411457000-7f7411458000 rw-p 00013000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411458000-7f7411462000 r--p 00000000 fd:03 71866262 /home/dgc88/miniconda3/envs/scvi/lib/libLerc.so. 7f7411462000-7f74114e9000 r-xp 0000a000 fd:03 71866262 /home/dgc88/minicon,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:5621,modifiability,pac,packages,5621,741101c000-7f741131c000 rw-p 00000000 00:00 0. 7f741131c000-7f741131f000 r--p 00000000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741131f000-7f741133c000 r-xp 00003000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f741133c000-7f7411340000 r--p 00020000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411340000-7f7411341000 ---p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411341000-7f7411342000 r--p 00024000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411342000-7f7411343000 rw-p 00025000 fd:03 277076332 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/matplotlib/_path.cpython-310-x86_64-linux-gnu.so. 7f7411343000-7f7411443000 rw-p 00000000 00:00 0. 7f7411443000-7f7411444000 r--p 00000000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411444000-7f7411451000 r-xp 00001000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411451000-7f7411456000 r--p 0000e000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411456000-7f7411457000 r--p 00012000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411457000-7f7411458000 rw-p 00013000 fd:03 106254919 /home/dgc88/miniconda3/envs/scvi/lib/libdeflate.so.0. 7f7411458000-7f7411462000 r--p 00000000 fd:03 71866262 /home/dgc88/miniconda3/envs/scvi/lib/libLerc.so. 7f7411462000-7f74114e9000 r-xp 0000a000 fd:03 71866262 /home/dgc88/miniconda3/envs/scvi/lib/libLerc.so. 7f74114e9000-7f74114f1000 r--p 00091000 fd:03 71866262 /home/dgc88/miniconda3/envs/scvi/lib/libLerc.so. 7f74114f1000-7f74114f2000 ---p 000,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8412,modifiability,Version,Versions,8412,"iniconda3/envs/scvi/lib/libzstd.so.1.5.5. 7f7411603000-7f7411604000 rw-p 0010e000 fd:03 277081168 /home/dgc88/miniconda3/envs/scvi/lib/libzstd.so.1.5.5. 7f7411604000-7f7411607000 r--p 00000000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411607000-7f7411679000 r-xp 00003000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_ME",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8631,modifiability,version,version,8631,"8/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411607000-7f7411679000 r-xp 00003000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8650,modifiability,pac,packaged,8650,"cvi/lib/libwebp.so.7.1.5. 7f7411607000-7f7411679000 r-xp 00003000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8780,modifiability,pac,packages,8780,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8826,modifiability,version,versions,8826,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:8961,modifiability,version,version,8961,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:9473,modifiability,pac,packages,9473,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:9557,modifiability,pac,packages,9557,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:1057,performance,Error,Error,1057," have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:2908,performance,Memor,Memory,2908,lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClosure+0x1c1)[0x7f78842cadf1]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x14394a)[0x7f78842b894a]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClosure+0x1c1)[0x7f78842cadf1]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x2ae)[0x7f78842c894e]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15818a)[0x7f78842cd18a]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x51f)[0x7f78842c8bbf]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_ReplIteration+0x252)[0x7f78842fd852]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x188bc1)[0x7f78842fdbc1]. /opt/R/4.2.3/lib64/R/lib/libR.so(run_Rmainloop+0x48)[0x7f78842fdc58]. /opt/R/4.2.3/lib64/R/bin/exec/R(main+0x1b)[0x40076b]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f788375a555]. /opt/R/4.2.3/lib64/R/bin/exec/R[0x40079b]. ======= Memory map: ========. 00400000-00401000 r-xp 00000000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 00600000-00601000 r--p 00000000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 00601000-00602000 rw-p 00001000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 010fc000-12e0b000 rw-p 00000000 00:00 0 [heap]. 7f7410d3d000-7f7410d6c000 r--p 00000000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410d6c000-7f7410f35000 r-xp 0002f000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410f35000-7f7410fe3000 r--p 001f8000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe3000-7f7410fe7000 r--p 002a6000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe7000-7f7410fe8000 rw-p 002aa000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leid,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:9589,performance,load,loaded,9589,"88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f7411679000-7f741168d000 r--p 00075000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168d000-7f741168e000 r--p 00088000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168e000-7f741168f000 rw-p 00089000 fd:03 177974808 /home/dgc88/miniconda3/envs/scvi/lib/libwebp.so.7.1.5. 7f741168f000-7f7411691000 rw-p 00000000 00:00 0. 7f7411691000-7f741169a000 r--p 00000000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0. 7f741169a000-7f74116e8000 r-xp 00009000 fd:03 339598995 /home/dgc88/miniconda3/envs/scvi/lib/libtiff.so.6.0.0Aborted. ```. #### Versions. <details>. python: /home/dgc88/miniconda3/envs/scvi/bin/python. libpython: /home/dgc88/miniconda3/envs/scvi/lib/libpython3.10.so. pythonhome: /home/dgc88/miniconda3/envs/scvi:/home/dgc88/miniconda3/envs/scvi. version: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. numpy: /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/numpy. numpy_version: 1.23.5. python versions found:. /home/dgc88/miniconda3/bin/python3. /home/dgc88/miniconda3/bin/python. /home/dgc88/miniconda3/envs/scvi/bin/python. R version 4.2.3 (2023-03-15). Platform: x86_64-pc-linux-gnu (64-bit). Running under: Red Hat Enterprise Linux. Matrix products: default. BLAS: /opt/R/4.2.3/lib64/R/lib/libRblas.so. LAPACK: /opt/R/4.2.3/lib64/R/lib/libRlapack.so. locale:. [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C. [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8. [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8. [7] LC_PAPER=en_US.UTF-8 LC_NAME=C. [9] LC_ADDRESS=C LC_TELEPHONE=C. [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C. attached base packages:. [1] stats graphics grDevices utils datasets methods base. other attached packages:. [1] reticulate_1.28. loaded via a namespace (and not attached):. [1] compiler_4.2.3 Matrix_1.5-4 Rcpp_1.0.10 grid_4.2.3 jsonlite_1.8.4. [6] png_0.1-8 lattice_0.21-8. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:815,reliability,doe,does,815,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:535,safety,modul,modules,535,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:1057,safety,Error,Error,1057," have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:134,usability,confirm,confirmed,134,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:217,usability,confirm,confirmed,217,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:383,usability,Confirm,Confirmed,383,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:494,usability,Confirm,Confirmed,494,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:556,usability,tool,tools,556,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:771,usability,command,command,771,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:920,usability,help,help,920,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:959,usability,Minim,Minimal,959,"Importing scanpy using reticulate causes R to crash; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:1057,usability,Error,Error,1057," have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. When I attempt to import scanpy using reticulate, R crashes. Here's what I've done to troubleshoot:. - Confirmed that I do not have an issue importing scanpy within python, the issue only exists with reticulate. - Confirmed that I can import other python modules such as scvi-tools using reticulate without issue. - Re-installed the latest version of R. - Re-installed the latest version of miniconda. - Created a new conda environment and re-installed scanpy. - Ran the code in Rstudio and command line. - Determined that the problem does not exist on MacOS 13.3.1, but only occurs on Linux, Red Hat Enterprise Linux. - Asked ChatGPT4 for help, which recommended the above. ### Minimal code sample. ```R. sc <- reticulate::import(""scanpy"", convert = FALSE). ```. ```bash. *** Error in `/opt/R/4.2.3/lib64/R/bin/exec/R': free(): invalid pointer: 0x0000000012cb0928 ***. ======= Backtrace: =========. /lib64/libc.so.6(+0x81329)[0x7f78837b9329]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp9exception18record_stack_traceEv+0x1af)[0x7f78765331ef]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_ZN4Rcpp4stopERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE+0x7b)[0x7f787652278e]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_Z16py_module_importRKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb+0x81)[0x7f7876545b51]. /opt/R/4.2.3/lib64/R/library/reticulate/libs/reticulate.so(_reticulate_py_module_import+0x94)[0x7f787652f664]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x101c3a)[0x7f7884276c3a]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x145c8d)[0x7f78842bac8d]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2479:2908,usability,Memor,Memory,2908,lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClosure+0x1c1)[0x7f78842cadf1]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x14394a)[0x7f78842b894a]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x178)[0x7f78842c8818]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15506b)[0x7f78842ca06b]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_applyClosure+0x1c1)[0x7f78842cadf1]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x2ae)[0x7f78842c894e]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x15818a)[0x7f78842cd18a]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_eval+0x51f)[0x7f78842c8bbf]. /opt/R/4.2.3/lib64/R/lib/libR.so(Rf_ReplIteration+0x252)[0x7f78842fd852]. /opt/R/4.2.3/lib64/R/lib/libR.so(+0x188bc1)[0x7f78842fdbc1]. /opt/R/4.2.3/lib64/R/lib/libR.so(run_Rmainloop+0x48)[0x7f78842fdc58]. /opt/R/4.2.3/lib64/R/bin/exec/R(main+0x1b)[0x40076b]. /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f788375a555]. /opt/R/4.2.3/lib64/R/bin/exec/R[0x40079b]. ======= Memory map: ========. 00400000-00401000 r-xp 00000000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 00600000-00601000 r--p 00000000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 00601000-00602000 rw-p 00001000 fd:07 37756457 /opt/R/4.2.3/lib64/R/bin/exec/R. 010fc000-12e0b000 rw-p 00000000 00:00 0 [heap]. 7f7410d3d000-7f7410d6c000 r--p 00000000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410d6c000-7f7410f35000 r-xp 0002f000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410f35000-7f7410fe3000 r--p 001f8000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe3000-7f7410fe7000 r--p 002a6000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe7000-7f7410fe8000 rw-p 002aa000 fd:03 42141823 /home/dgc88/miniconda3/envs/scvi/lib/libigraph.so.3.0.0. 7f7410fe8000-7f7410ff6000 r--p 00000000 fd:03 6833466 /home/dgc88/miniconda3/envs/scvi/lib/python3.10/site-packages/leidenalg/_c_leid,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2479
https://github.com/scverse/scanpy/issues/2480:7,availability,state,state,7,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:454,availability,cluster,clusters,454,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:537,availability,sli,slightly,537,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:619,availability,state,state,619,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:153,deployability,version,version,153,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:454,deployability,cluster,clusters,454,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:556,deployability,version,versions,556,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:867,deployability,scale,scale,867,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:1030,deployability,Version,Versions,1030,"[X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:2659,deployability,updat,updated,2659,"mc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. torch 2.0.0. tornado 6.3. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zmq 25.0.2. zoneinfo NA. -----. IPython 8.12.1. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-41-generic-x86_64-with-glibc2.36. -----. Session information updated at 2023-05-02 16:27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:867,energy efficiency,scale,scale,867,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:7,integrability,state,state,7,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:153,integrability,version,version,153,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:556,integrability,version,versions,556,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:619,integrability,state,state,619,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:1030,integrability,Version,Versions,1030,"[X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:1814,interoperability,platform,platformdirs,1814,"mc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. torch 2.0.0. tornado 6.3. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zmq 25.0.2. zoneinfo NA. -----. IPython 8.12.1. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-41-generic-x86_64-with-glibc2.36. -----. Session information updated at 2023-05-02 16:27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:153,modifiability,version,version,153,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:556,modifiability,version,versions,556,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:867,modifiability,scal,scale,867,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:1030,modifiability,Version,Versions,1030,"[X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:1272,modifiability,deco,decorator,1272,"fficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:1719,modifiability,pac,packaging,1719,"mc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. torch 2.0.0. tornado 6.3. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zmq 25.0.2. zoneinfo NA. -----. IPython 8.12.1. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-41-generic-x86_64-with-glibc2.36. -----. Session information updated at 2023-05-02 16:27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:2515,modifiability,pac,packaged,2515,"mc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. torch 2.0.0. tornado 6.3. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zmq 25.0.2. zoneinfo NA. -----. IPython 8.12.1. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-41-generic-x86_64-with-glibc2.36. -----. Session information updated at 2023-05-02 16:27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:867,performance,scale,scale,867,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:537,reliability,sli,slightly,537,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:571,reliability,doe,does,571,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:2659,safety,updat,updated,2659,"mc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. torch 2.0.0. tornado 6.3. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zmq 25.0.2. zoneinfo NA. -----. IPython 8.12.1. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-41-generic-x86_64-with-glibc2.36. -----. Session information updated at 2023-05-02 16:27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:444,security,ident,identical,444,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:2639,security,Session,Session,2639,"mc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. torch 2.0.0. tornado 6.3. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zmq 25.0.2. zoneinfo NA. -----. IPython 8.12.1. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-41-generic-x86_64-with-glibc2.36. -----. Session information updated at 2023-05-02 16:27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:2659,security,updat,updated,2659,"mc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pytz 2023.3. scipy 1.10.1. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. texttable 1.6.7. threadpoolctl 3.1.0. torch 2.0.0. tornado 6.3. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.6. yaml 6.0. zmq 25.0.2. zoneinfo NA. -----. IPython 8.12.1. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]. Linux-5.19.0-41-generic-x86_64-with-glibc2.36. -----. Session information updated at 2023-05-02 16:27. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:113,usability,confirm,confirmed,113,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2480:196,usability,confirm,confirmed,196,"Random state not reproducible.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have suddenly difficulties with reproducibility with scanpy's umap and leiden methods. I use the PBMC dataset as an example. Running twice the methods in the same notebook results in identical clusters and UMAP. But rerunning the whole notebook (restart kernel and run) gives slightly different versions. This does not change if I explicitly pass the random state to leiden and umap calls. ```. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata). adata = adata[:, adata.var.highly_variable].copy(). sc.pp.scale(adata). sc.pp.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata). sc.tl.umap(adata). sc.pl.umap(adata, color=""leiden"", legend_loc=""on data""). ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. executing 1.2.0. gmpy2 2.1.2. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.4. invgauss_ufunc NA. ipykernel 6.22.0. ipywidgets 8.0.6. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.39.1. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.3.1. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. nvfuser NA. opt_einsum v3.3.0. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.0. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2480
https://github.com/scverse/scanpy/issues/2481:0,integrability,Filter,Filtering,0,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:84,integrability,filter,filter,84,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:236,integrability,filter,filter,236,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:25,interoperability,coordinat,coordinates,25,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:121,interoperability,coordinat,coordinate,121,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:335,interoperability,coordinat,coordinates,335,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:401,reliability,doe,does,401,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:384,testability,simpl,simple,384,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:56,usability,interact,interactively,56,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:70,usability,visual,visualize,70,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/issues/2481:384,usability,simpl,simple,384,"Filtering spots based on coordinates; Is there a way to interactively visualize and filter spots in Visium data based on coordinate values from `adata.obsm['spatial']`? There are some spots lying outside of the tissue which I'd like to filter from the data or even removing rows/ columns of spots from the array. Since the spaceranger coordinates are not perfectly aligned, writing a simple condition does not extract all spots of interest.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2481
https://github.com/scverse/scanpy/pull/2482:250,safety,review,review,250,Benchmarking support with asv; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2482:250,testability,review,review,250,Benchmarking support with asv; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2482:13,usability,support,support,13,Benchmarking support with asv; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2482:101,usability,guid,guidelines,101,Benchmarking support with asv; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2482:132,usability,guid,guide,132,Benchmarking support with asv; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2482:228,usability,workflow,workflow,228,Benchmarking support with asv; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR introduces benchmarking for Scanpy with airspeed-velocity (asv) ([Link](https://asv.readthedocs.io/en/stable/index.html)),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2482
https://github.com/scverse/scanpy/pull/2483:186,deployability,scale,scale,186,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:235,deployability,scale,scale,235,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:186,energy efficiency,scale,scale,186,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:235,energy efficiency,scale,scale,235,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:322,energy efficiency,current,current,322,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:75,interoperability,compatib,compatible,75,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:186,modifiability,scal,scale,186,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:235,modifiability,scal,scale,235,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:186,performance,scale,scale,186,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:235,performance,scale,scale,235,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:405,safety,test,tested,405,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:405,testability,test,tested,405,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2483:535,usability,support,supported,535,"add reader for 10x Xenium output; I tried to keep the resulting AnnData as compatible as possible with the Visium output, but it is still going to break sc.pl.spatial due to the lack of scale factors. In theory, we could calculate the scale factors ourselves, but that's probably not useful for plotting anyway, since the current spatial plotting function also requires spot sizes, which we don't have. I tested it on the example Xenium data set from the 10x web site. The images in this data set are JPEG2000-compressed, which is not supported by Pillow. Manually creating an image with zlib compression and passing that to the reader works. I don't know if the 10x Xenium software can only output this type of image file or if it can also produce TIFFs with another compression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2483
https://github.com/scverse/scanpy/pull/2484:128,usability,responsiv,responsive,128,"Fix generated path; The previous docs PRs moved the generated docs path, which breaks old urls. This fixes that. This also adds responsive handling of the grid on the main index page.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2484
https://github.com/scverse/scanpy/issues/2485:455,availability,cluster,cluster,455,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:455,deployability,cluster,cluster,455,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:682,deployability,build,build,682,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:769,energy efficiency,current,currently,769,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:14,integrability,sub,subset,14,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:124,integrability,sub,subset-vs-all-cells,124,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:347,integrability,sub,subset,347,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:338,interoperability,specif,specific,338,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:441,interoperability,specif,specific,441,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:601,interoperability,specif,specific,601,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:514,modifiability,paramet,parameter,514,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:570,reliability,doe,doesn,570,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:694,usability,custom,custom,694,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2485:779,usability,support,supported,779,"Violin plot - subset vs. all cells; FYI I made a post on the scverse discourse (https://discourse.scverse.org/t/violin-plot-subset-vs-all-cells/1399) but figured I would add it here as well. I’ve been using `sc.pl.violin()` a lot lately, but have not been able to figure out how to make a violin plot with two groups where the first is a specific subset and the second is all cells. An example use case of this is making a violin plot for a specific UMAP cluster against the rest. I am familiar with the `groupby` parameter to split based on a metadata factor, but this doesn’t allow selection of one specific metadata factor. Is there a way to do this with scanpy or do we need to build out a custom plotting function? If there is enough demand for this and it is not currently supported, I could look into making a PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2485
https://github.com/scverse/scanpy/issues/2486:1136,availability,cluster,clustering,1136,"s on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1226,availability,error,error,1226,"the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2021,availability,avail,available,2021,"atial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3228,availability,state,states,3228,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:157,deployability,version,version,157,"Tile Multiple FOVs sc.pl.spatial; - [ ✔] I have checked that this issue has not already been reported. - [✔ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1136,deployability,cluster,clustering,1136,"s on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3311,deployability,Version,Versions,3311,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:157,integrability,version,version,157,"Tile Multiple FOVs sc.pl.spatial; - [ ✔] I have checked that this issue has not already been reported. - [✔ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3228,integrability,state,states,3228,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3311,integrability,Version,Versions,3311,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1627,interoperability,share,shared,1627,"iew of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1918,interoperability,coordinat,coordinates,1918,"M', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying sing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2247,interoperability,share,shared,2247,".spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2549,interoperability,specif,specify,2549,"tial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2788,interoperability,specif,specify,2788,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2909,interoperability,specif,specifying,2909,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3193,interoperability,specif,specify,3193,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3244,interoperability,format,format,3244,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:157,modifiability,version,version,157,"Tile Multiple FOVs sc.pl.spatial; - [ ✔] I have checked that this issue has not already been reported. - [✔ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1673,modifiability,pac,packages,1673,"78 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2293,modifiability,pac,packages,2293,"=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3311,modifiability,Version,Versions,3311,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1226,performance,error,error,1226,"the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2021,reliability,availab,available,2021,"atial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1226,safety,error,error,1226,"the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2021,safety,avail,available,2021,"atial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2021,security,availab,available,2021,"atial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1446,testability,Trace,Traceback,1446,"ta.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:117,usability,confirm,confirmed,117,"Tile Multiple FOVs sc.pl.spatial; - [ ✔] I have checked that this issue has not already been reported. - [✔ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:200,usability,confirm,confirmed,200,"Tile Multiple FOVs sc.pl.spatial; - [ ✔] I have checked that this issue has not already been reported. - [✔ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get def",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:1226,usability,error,error,1226,"the master branch of scanpy. ---. I have imported NanoString CosMX data using the `sq.read.nanostring()` function and stored as `adata`. The NanoString data has multiple field of views references (FOV's) stored in the `adata.obs` dataframe as well as spatial data in `adata.uns` and `adata.obsm`. To illustrate: . ```pytp. ---------------------------------------------------------------------------. View of AnnData object with n_obs × n_vars = 52078 × 6200. obs: 'fov', ' ... 'pct_counts_is_mito', 'total_counts_is_ribo', 'pct_counts_is_ribo', 'total_counts_is_NegPrb', 'leiden', 'h_oligo', 'h_opc', 'h_tCRM', 'h_exc', 'h_IRM', 'hPIG_DE', 'h_TRM', 'h_inh', 'h_astro', 'h_CRM1', 'h_micro', 'h_DAM', 'h_CRM2', 'h_HLA', 'h_endo', 'Cell Type', 'Leiden_Cell_Type'. uns: 'spatial'. obsm: 'spatial', 'spatial_fov'. ```. However, when I try and tile the multiple FOV's together to see where cell types assigned by clustering are located spatially,. using the `sc.pl.spatial` function I get the following error:. ```python. sc.pl.spatial(. adata, . basis=""spatial_fov"",. color=[""Leiden_Cell_Type""], . spot_size=120, , . ). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[45], line 1. ----> 1 sc.pl.spatial(. 2 AD_adata,. 3 basis = 'spatial_fov',. 4 color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:2994,usability,workflow,workflow,2994,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2486:3421,usability,learn,learn,3421,"color = 'total_counts',. 5 spot_size = 120. 6 ). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:988, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 936 """"""\. 937 Scatter plot in spatial coordinates. 938 . (...). 985 Tutorial on spatial analysis. 986 """""". 987 # get default image params if available. --> 988 library_id, spatial_data = _check_spatial_data(adata.uns, library_id). 989 img, img_key = _check_img(spatial_data, img, img_key, bw=bw). 990 spot_size = _check_spot_size(spatial_data, spot_size). File /home/shared/.conda/envs/Spatial/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1291, in _check_spatial_data(uns, library_id). 1289 if library_id is _empty:. 1290 if len(spatial_mapping) > 1:. -> 1291 raise ValueError(. 1292 ""Found multiple possible libraries in `.uns['spatial']. Please specify."". 1293 f"" Options are:\n\t{list(spatial_mapping.keys())}"". 1294 ). 1295 elif len(spatial_mapping) == 1:. 1296 library_id = list(spatial_mapping.keys())[0]. ValueError: Found multiple possible libraries in `.uns['spatial']. Please specify. Options are:. 	['1', '10', '100', '101', '102', '103', '104', '105', '106'... ```. Plotting individual FOV's by specifying singular library keys generates plots. If I do an approach similar to the workflow. in this SquidPy [tutorial](https://squidpy.readthedocs.io/en/stable/external_tutorials/tutorial_nanostring.html) where I use the `sq.pl.spatial_segment()`, or `sq.pl.spatial_scatter()` and specify a list of library keys, it states that the format of the library keys argument is of an unhashable type. #### Versions. <details>. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.22.4 scipy==1.9.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.14.0rc0 python-igraph==0.10.4 pynndescent==0.5.10. </details>. I would much appreciate if anyone could advise. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2486
https://github.com/scverse/scanpy/issues/2487:682,availability,error,error,682,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:222,deployability,version,version,222,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:785,deployability,Version,Versions,785,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:834,deployability,log,logging,834,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:222,integrability,version,version,222,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:785,integrability,Version,Versions,785,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:222,modifiability,version,version,222,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:785,modifiability,Version,Versions,785,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:682,performance,error,error,682,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:682,safety,error,error,682,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:834,safety,log,logging,834,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:834,security,log,logging,834,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:834,testability,log,logging,834,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:67,usability,document,document,67,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:182,usability,confirm,confirmed,182,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:265,usability,confirm,confirmed,265,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:356,usability,guid,guide,356,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:411,usability,minim,minimal-bug-reports,411,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:517,usability,Minim,Minimal,517,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2487:682,usability,error,error,682,"No implementation of the lobpcg solver for sc.pp.pca, although the document has lobpcg as an option; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. sc.pp.pca(adata, svd_solver = 'lobpcg'). ```. ```pytb. [Paste the error output produced by the above code here]. ValueError: Unrecognized svd_solver='lobpcg'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2487
https://github.com/scverse/scanpy/issues/2488:290,availability,error,error,290,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:260,deployability,continu,continue,260,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:958,deployability,version,versions,958,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:96,energy efficiency,load,load,96,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:958,integrability,version,versions,958,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:746,modifiability,pac,packages,746,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:958,modifiability,version,versions,958,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:96,performance,load,load,96,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:290,performance,error,error,290,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:1119,performance,Time,Time,1119,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:290,safety,error,error,290,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:927,security,Session,Session,927,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:640,testability,Trace,Traceback,640,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:290,usability,error,error,290,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2488:304,usability,confirm,confirmed,304,"trouble using read_visium with visium ST data on windows ; Hello - I am trying to use scanpy to load visium ST data. The tissue_positions.csv file is located in the spatial folder - I renamed it to tissue_positions_list.csv per the expectation of scanpy but I continue to get the following error. I have confirmed that the folder structure and pathing is correct. Can you think of what else could be the issue with it not reading/finding this file? . ```py. >>> import os. >>> # p = os.path.join( ""path to outs location""). >>> print(p). ""path to outs location"". >>> print(os.path.exists(p)). True. >>> ad = sc.read_visium(p). ```. ```pytb. Traceback (most recent call last):. Cell In[6], line 1. ad = sc.read_visium(p). File ~\anaconda3\lib\site-packages\scanpy\readwrite.py:390 in read_visium. raise OSError(f""Could not find '{f}'""). OSError: Could not find 'path to outs location\spatial\tissue_positions_list.csv'. ```. ### Session/scanpy info:. Software versions. Python 3.10.9 64bit [MSC v.1916 64 bit (AMD64)]. IPython 8.10.0. OS Windows 10 10.0.22621 SP0. scanpy 1.9.3. Sun May 14 14:59:57 2023 Eastern Daylight Time",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2488
https://github.com/scverse/scanpy/issues/2489:50,availability,sli,sliced,50,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:439,availability,error,error,439,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:471,availability,sli,slice,471,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:493,availability,sli,slice,493,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:683,availability,down,download,683,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:837,deployability,version,version,837,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:853,deployability,version,version,853,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:877,deployability,version,version,877,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:27,energy efficiency,draw,drawing,27,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:452,energy efficiency,draw,drawing,452,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:670,energy efficiency,cloud,cloud,670,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:837,integrability,version,version,837,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:853,integrability,version,version,853,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:877,integrability,version,version,877,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:204,modifiability,pac,package,204,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:381,modifiability,pac,package,381,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:837,modifiability,version,version,837,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:853,modifiability,version,version,853,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:877,modifiability,version,version,877,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:439,performance,error,error,439,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:50,reliability,sli,sliced,50,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:471,reliability,sli,slice,471,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:493,reliability,sli,slice,493,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:439,safety,error,error,439,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:439,usability,error,error,439,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2489:570,usability,help,help,570,"""sc.pl.spatial()"" function drawing cannot display sliced background.; Hello, . I first obtained the NP_CP_scanpy.h5ad object using the scanpy analysis process. Then I converted the result of giotto (an R package that analyzes spatial data) into the NP_CP_giotto.h5ad object according to the structure of the NP_CP_scanpy.h5ad object. I use the ""sc.pl.spatial()"" function in scanpy package to plot the np_cp_Gioto. h5ad object. There is an error in the drawing of spatial slice + scatter plot (slice cannot be used as background, as shown in the figure below). . Can you help me check the object structure and give me some suggestions? Note：I stored in the object gofile cloud plate, download address: https://gofile.io/d/cm9gsz. ![image](https://github.com/scverse/scanpy/assets/69581197/60f5a7c4-282d-4ef1-809c-b92d829ab9bf). ```scanpy version. Scanpy version: 1.9.3. AnnData version: 0.9.1. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2489
https://github.com/scverse/scanpy/issues/2490:292,availability,cluster,clusters,292,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:0,deployability,Stack,StackedViolin,0,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:168,deployability,Stack,StackedViolin,168,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:292,deployability,cluster,clusters,292,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:113,interoperability,specif,specific,113,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:103,safety,input,inputting,103,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:322,safety,input,input,322,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:103,usability,input,inputting,103,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2490:322,usability,input,input,322,"StackedViolin as Seurat violin plot; Hi,. My issue is similar to that in #2298 . I solved the issue of inputting specific colors with the row_palette argument in sc.pl.StackedViolin(), but when using swap_axes to have the same plot as in Seurat (bottom image), it colors genes (rows) instead clusters. Is there any way to input the palette list by columns instead of by rows? ![image](https://github.com/scverse/scanpy/assets/94078098/d3be8d08-4105-42c5-aa44-37206689cfa7).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2490
https://github.com/scverse/scanpy/issues/2491:320,availability,error,error,320,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6,deployability,scale,scale,6,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:179,deployability,version,version,179,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:301,deployability,scale,scale,301,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:387,deployability,scale,scale,387,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:499,deployability,scale,scale,499,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:726,deployability,depend,dependency,726,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1880,deployability,stack,stack,1880,"nditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3068,deployability,scale,scale,3068,".array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3379,deployability,scale,scale,3379,"ray. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3966,deployability,scale,scale,3966,"g1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4490,deployability,scale,scale,4490,"wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4562,deployability,Version,Versions,4562,"requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6661,deployability,updat,updated,6661," 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]. macOS-13.3.1-arm64-arm-64bit. -----. Session information updated at 2023-05-18 14:00. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6,energy efficiency,scale,scale,6,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:301,energy efficiency,scale,scale,301,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:387,energy efficiency,scale,scale,387,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:499,energy efficiency,scale,scale,499,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3068,energy efficiency,scale,scale,3068,".array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3379,energy efficiency,scale,scale,3379,"ray. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3966,energy efficiency,scale,scale,3966,"g1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4490,energy efficiency,scale,scale,4490,"wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4792,energy efficiency,cloud,cloudpickle,4792,"center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:179,integrability,version,version,179,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:726,integrability,depend,dependency,726,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:896,integrability,wrap,wrap,896,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1131,integrability,sub,submit,1131,"have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1735,integrability,schema,schema,1735,"(https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1773,integrability,wrap,wrapped,1773,"/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3493,integrability,wrap,wrapper,3493,"ospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4298,integrability,wrap,wrapper,4298,"iable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4562,integrability,Version,Versions,4562,"requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3493,interoperability,wrapper,wrapper,3493,"ospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4298,interoperability,wrapper,wrapper,4298,"iable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:5007,interoperability,distribut,distributed,5007,"47 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seabo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:5590,interoperability,platform,platformdirs,5590,"a 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6,modifiability,scal,scale,6,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:179,modifiability,version,version,179,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:301,modifiability,scal,scale,301,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:387,modifiability,scal,scale,387,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:499,modifiability,scal,scale,499,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:726,modifiability,depend,dependency,726,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:914,modifiability,deco,decoration,914,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3068,modifiability,scal,scale,3068,".array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3379,modifiability,scal,scale,3379,"ray. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3723,modifiability,pac,packages,3723,"m_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3823,modifiability,layer,layer,3823,"k). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3892,modifiability,layer,layer,3892,"form preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3898,modifiability,layer,layer,3898,"reprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_run",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3966,modifiability,scal,scale,3966,"g1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4178,modifiability,layer,layer,4178,"---------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipyke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4184,modifiability,layer,layer,4184,"---. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4490,modifiability,scal,scale,4490,"wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4562,modifiability,Version,Versions,4562,"requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4972,modifiability,deco,decorator,4972," X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:5482,modifiability,pac,packaging,5482,r: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6531,modifiability,pac,packaged,6531," 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]. macOS-13.3.1-arm64-arm-64bit. -----. Session information updated at 2023-05-18 14:00. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6,performance,scale,scale,6,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:301,performance,scale,scale,301,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:320,performance,error,error,320,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:387,performance,scale,scale,387,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:499,performance,scale,scale,499,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1359,performance,parallel,parallelization,1359,"ause `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1557,performance,parallel,parallelize,1557,"py/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1807,performance,parallel,parallelized,1807,"871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, cal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:2892,performance,perform,perform,2892,"in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3068,performance,scale,scale,3068,".array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3379,performance,scale,scale,3379,"ray. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3966,performance,scale,scale,3966,"g1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4490,performance,scale,scale,4490,"wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:5306,performance,lock,locket,5306,"gs, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. ty",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:14,reliability,doe,doesn,14,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:394,reliability,doe,doesn,394,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:320,safety,error,error,320,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:726,safety,depend,dependency,726,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1025,safety,compl,completely,1025,"adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. impor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:2591,safety,Prevent,Preventing,2591,"-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 po",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6661,safety,updat,updated,6661," 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]. macOS-13.3.1-arm64-arm-64bit. -----. Session information updated at 2023-05-18 14:00. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1025,security,compl,completely,1025,"adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. impor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:2591,security,Preven,Preventing,2591,"-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 po",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:4720,security,certif,certifi,4720,"ackages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 if copy:. File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:5306,security,lock,locket,5306,"gs, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). TypeError: scale() got an unexpected keyword argument 'return_mean_std'. ```. #### Versions. <details>. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. appnope 0.1.3. asciitree NA. asttokens NA. attr 23.1.0. backcall 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. ty",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6110,security,soc,socks,6110," 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]. macOS-13.3.1-arm64-arm-64bit. -----. Session information updated at 2023-05-18 14:00. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6641,security,Session,Session,6641," 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]. macOS-13.3.1-arm64-arm-64bit. -----. Session information updated at 2023-05-18 14:00. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6661,security,updat,updated,6661," 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]. macOS-13.3.1-arm64-arm-64bit. -----. Session information updated at 2023-05-18 14:00. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:726,testability,depend,dependency,726,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:3202,testability,Trace,Traceback,3202,"rocessed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, layer=layer, obsm=obsm). --> 844 X, adata.var[""mean""], adata.var[""std""] = scale(. 845 X,. 846 zero_center=zero_center,. 847 max_value=max_value,. 848 copy=False, # because a copy has already been made, if it were to be made. 849 return_mean_std=True,. 850 ). 851 _set_obs_rep(adata, X, layer=layer, obsm=obsm). 852 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:22,usability,support,support,22,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:139,usability,confirm,confirmed,139,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:222,usability,confirm,confirmed,222,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:320,usability,error,error,320,"sc.pp.scale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without havi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1002,usability,support,supporting,1002,"cale() doesn't support adata.X being a dask array; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. In short `sc.pp.scale()` throws an error when `adata.X` is a dask array solely because `sc.pp._simple.scale` doesn't have the `sc.pp._simple.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1420,usability,guid,guide,1420,"le.scale_array` function registered for a `dask.array.Array` type. Adding `@scale.register(da.Array)` [here](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#LL758C7-L758C7) would fix that, but considering `dask.array` is [only an optional dependency,](https://github.com/scverse/scanpy/blob/f03c5b407412de447480733a1a1a0e33e0c871d2/scanpy/preprocessing/_simple.py#L32) there would have to be a conditional to wrap the function decoration. This brings me to the larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:1944,usability,Minim,Minimal,1944,"larger issue, is scanpy supposed to or working toward supporting dask arrays completely? I'm new to scanpy and I'm not sure if this is a bug report or an enhancement request. I could submit a pull request for this one issue but I'm curious if I'll run into many such issues as I dive in further and trying to figure out if there's existing momentum in this direction or whether I should be following some other parallelization strategy. I got here by following [AnnData's guide on using dask and zarr](https://anndata.readthedocs.io/en/latest/tutorials/notebooks/%7Bread%2Cwrite%7D_dispatched.html) to try to parallelize processing of a large scRNA-seq file. I come from a microscopy data analysis and ML background where my image data is stored in S3 hosted zarr arrays (in an OME-NGFF schema), handled by using dask arrays wrapped in xarray DataArrays, and parallelized across compute using ray. It would be nice to use a similar stack (dropping in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, targ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:2892,usability,perform,perform,2892,"in anndata for xarray) for sc-seq analyses. ### Minimal code sample (that we can copy&paste without having any data). ```python. import zarr. import anndata as ad. import dask.array as da. import scanpy as sc. # write data to zarr file. rel_zarr_path = 'data/pbmc3k_processed.zarr'. adata = sc.datasets.pbmc3k_processed(). adata.write_zarr(f'./{rel_zarr_path}', chunks=[adata.shape[0], 5]). zarr.consolidate_metadata(f'./{rel_zarr_path}'). # read data from zarr file with X as a dask array. def read_dask(store):. f = zarr.open(store, mode=""r""). def callback(func, elem_name: str, elem, iospec):. if iospec.encoding_type in (. ""dataframe"",. ""csr_matrix"",. ""csc_matrix"",. ""awkward-array"",. ):. # Preventing recursing inside of these types. return ad.experimental.read_elem(elem). elif iospec.encoding_type == ""array"":. return da.from_zarr(elem). else:. return func(elem). adata = ad.experimental.read_dispatched(f, callback=callback). return adata. adata_dask = read_dask(f'./{rel_zarr_path}'). # perform preprocessing. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pp.scale(adata_dask, max_value=10). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[1], line 39. 37 sc.pp.log1p(adata). 38 # sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). ---> 39 sc.pp.scale(adata_dask, max_value=10). File ~/miniconda3/envs/omics/lib/python3.10/functools.py:889, in singledispatch..wrapper(*args, **kw). 885 if not args:. 886 raise TypeError(f'{funcname} requires at least '. 887 '1 positional argument'). --> 889 return dispatch(args[0].__class__)(*args, **kw). File ~/miniconda3/envs/omics/lib/python3.10/site-packages/scanpy/preprocessing/_simple.py:844, in scale_anndata(adata, zero_center, max_value, copy, layer, obsm). 842 view_to_actual(adata). 843 X = _get_obs_rep(adata, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2491:6248,usability,tool,toolz,6248," 0.2.0. brotli NA. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 3.1.0. click 8.1.3. cloudpickle 2.2.1. colorama 0.4.6. colorful 0.5.5. colorful_orig 0.5.5. comm 0.1.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.5.0. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. distributed 2023.5.0. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. filelock 3.12.0. fsspec 2023.5.0. google NA. grpc 1.43.0. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. jsonschema 4.17.3. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. locket NA. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.6.3. matplotlib_inline 0.1.6. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. numba 0.57.0. numcodecs 0.11.0. numpy 1.24.3. packaging 23.1. pandas 2.0.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pyarrow 9.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pynvml NA. pyparsing 3.0.9. pyrsistent NA. pytz 2023.3. ray 2.3.0. rb_analysis NA. requests 2.29.0. scipy 1.10.1. seaborn 0.12.2. session_info 1.0.0. setproctitle 1.2.2. setuptools 67.7.2. six 1.16.0. sklearn 1.2.2. socks 1.7.1. sortedcontainers 2.4.0. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.15. wcwidth 0.2.6. yaml 6.0. zarr 2.14.2. zict 3.0.0. zipp NA. zmq 25.0.2. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. -----. Python 3.10.11 | packaged by conda-forge | (main, May 10 2023, 19:01:19) [Clang 14.0.6 ]. macOS-13.3.1-arm64-arm-64bit. -----. Session information updated at 2023-05-18 14:00. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2491
https://github.com/scverse/scanpy/issues/2492:177,modifiability,design decis,design decisions,177,"Is it possible to use color to represent the fraction?; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... coule I use the color to represent fraction and size to show the mean expression?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2492
https://github.com/scverse/scanpy/issues/2492:76,usability,help,help,76,"Is it possible to use color to represent the fraction?; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... coule I use the color to represent fraction and size to show the mean expression?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2492
https://github.com/scverse/scanpy/issues/2493:247,availability,avail,available,247,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:504,deployability,Version,Versions,504,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:4238,deployability,updat,updated,4238,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:947,energy efficiency,cloud,cloudpickle,947,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:23,integrability,batch,batch,23,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:145,integrability,batch,batch,145,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:173,integrability,sub,subset,173,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:329,integrability,batch,batch,329,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:417,integrability,batch,batch,417,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:445,integrability,sub,subset,445,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:504,integrability,Version,Versions,504,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:3843,integrability,wrap,wrapt,3843,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:2448,interoperability,platform,platformdirs,2448,2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. networkx 3.0. newick 1.0.0. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. numpyro 0.11.0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:504,modifiability,Version,Versions,504,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:1128,modifiability,deco,decorator,1128," batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:1145,modifiability,deco,decoupler,1145,""",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nbinom_ufunc NA. nc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:2313,modifiability,pac,packaging,2313,0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. networkx 3.0. newick 1.0.0. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. numpyro 0.11.0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:4085,modifiability,pac,packaged,4085,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:23,performance,batch,batch,23,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:145,performance,batch,batch,145,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:257,performance,memor,memory,257,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:329,performance,batch,batch,329,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:417,performance,batch,batch,417,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:2191,performance,network,networkx,2191,rep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. networkx 3.0. newick 1.0.0. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. numpyro 0.11.0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sk,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:247,reliability,availab,available,247,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:247,safety,avail,available,247,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:3774,safety,valid,validators,3774,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:4238,safety,updat,updated,4238,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:247,security,availab,available,247,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:876,security,certif,certifi,876,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:1560,security,iso,isoduration,1560,+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. networkx 3.0. newick 1.0.0. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. numpyro 0.11.0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pu,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:2191,security,network,networkx,2191,rep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. networkx 3.0. newick 1.0.0. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. numpyro 0.11.0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sk,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:3240,security,soc,socks,3240,"0.11.0. numpy 1.23.5. numpyro 0.11.0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:3774,security,validat,validators,3774,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:4218,security,Session,Session,4218,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:4238,security,updat,updated,4238,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:257,usability,memor,memory,257,"Kernel dies when using batch in highly_variable_genes(); When I run:. ```. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. kernel dies in about 60-90 seconds. I have plenty of available memory, so don't see why, but happens again and again. If I comment out batch:. ```pytb. sc.pp.highly_variable_genes(. adata,. flavor=""seurat_v3"",. #batch_key=""batch"",. n_top_genes=2000,. subset=False,. )```. It finished in about 10 seconds. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.10.0.dev57+g08be4e9. -----. PIL 9.4.0. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. adjustText 0.8. anyio NA. arrow 1.2.3. arviz 0.15.0. asciitree NA. asttokens NA. astunparse 1.6.3. attr 22.2.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bokeh 2.4.3. brotli NA. captum 0.6.0. cellrank 1.5.1. certifi 2023.05.07. cffi 1.15.1. charset_normalizer 2.1.1. chex 0.1.6. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.2. contextlib2 NA. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.3.0. dask_image 2022.09.0. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.6. docrep 0.3.2. dot_parser NA. entrypoints 0.4. executing 1.2.0. fasteners 0.17.3. fastjsonschema NA. flatbuffers 23.1.21. flax 0.5.0. fqdn NA. fsspec 2023.1.0. gast NA. google NA. gseapy 1.0.4. h5py 3.8.0. hypergeom_ufunc NA. idna 3.4. igraph 0.10.3. imagecodecs 2023.1.23. imageio 2.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:2468,usability,progress,progressbar,2468,.26.0. invgauss_ufunc NA. ipykernel 6.21.2. ipython_genutils 0.2.0. ipywidgets 8.0.4. isoduration NA. jax 0.4.10. jaxlib 0.4.10. jedi 0.18.2. jinja2 3.0.3. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.3.0. jupyterlab_server 2.19.0. keras 2.11.0. kiwisolver 1.4.4. leidenalg 0.9.1. lightning_fabric 1.9.3. lightning_utilities 0.7.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.7.1. matplotlib_inline 0.1.6. matplotlib_scalebar 0.8.1. ml_collections NA. ml_dtypes 0.1.0. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.1. multigrate 0.0.2. multipledispatch 0.6.0. natsort 8.3.1. nbformat 5.7.3. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. networkx 3.0. newick 1.0.0. numba 0.56.4. numcodecs 0.11.0. numpy 1.23.5. numpyro 0.11.0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2493:3491,usability,tool,toolz,3491,"0. opt_einsum v3.3.0. optax 0.1.4. packaging 23.0. pandas 1.5.3. parso 0.8.3. paste NA. patsy 0.5.3. petsc4py 3.19.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.0.0. progressbar 4.2.0. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygam 0.8.0. pygments 2.14.0. pygpcca 1.0.4. pyparsing 3.0.9. pyro 1.8.4+9ed468d. pyrsistent NA. python_utils NA. pythonjsonlogger NA. pytorch_lightning 1.9.3. pytz 2022.7.1. pywt 1.4.1. requests 2.28.2. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. scHPL NA. scarches 0.5.7. sccoda 0.1.9. scipy 1.10.1. scvelo 0.2.5. scvi 0.20.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 67.4.0. six 1.16.0. skewnorm_ufunc NA. skimage 0.19.3. sklearn 1.2.1. slepc4py 3.19.0. sniffio 1.3.0. socks 1.7.1. squidpy 1.2.2. stack_data 0.6.2. statsmodels 0.13.5. tblib 1.7.0. tcr_embedding NA. tensorboard 2.11.2. tensorflow 2.11.0. tensorflow_probability 0.19.0. termcolor NA. texttable 1.6.7. threadpoolctl 3.1.0. tifffile 2023.2.28. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. torch_cluster 1.6.0. torch_geometric 2.2.0. torch_scatter 2.1.0. torch_sparse 0.6.15. torchmetrics 0.11.3. torchvision 0.14.1. tornado 6.2. tqdm 4.64.1. traitlets 5.9.0. tree 0.1.7. typing_extensions NA. unicodedata2 NA. uri_template NA. urllib3 1.26.14. validators 0.20.0. wcwidth 0.2.6. webcolors 1.11.1. websocket 1.5.1. wrapt 1.15.0. xarray 2023.2.0. xarray_einstats 0.5.1. yaml 6.0. zarr 2.13.6. zipp NA. zmq 25.0.0. zoneinfo NA. zope NA. -----. IPython 8.11.0. jupyter_client 8.0.3. jupyter_core 5.2.0. jupyterlab 3.6.1. notebook 6.5.2. -----. Python 3.10.9 | packaged by conda-forge | (main, Feb 2 2023, 20:20:04) [GCC 11.3.0]. Linux-3.10.0-1160.83.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-05-26 01:06. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2493
https://github.com/scverse/scanpy/issues/2494:5,availability,error,error,5,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:260,availability,error,error,260,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:177,deployability,version,version,177,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:338,deployability,fail,failed,338,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:354,deployability,instal,install,354,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1096,deployability,Version,Versions,1096,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1145,deployability,log,logging,1145,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:177,integrability,version,version,177,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1096,integrability,Version,Versions,1096,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:177,modifiability,version,version,177,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:368,modifiability,pac,package,368,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:441,modifiability,pac,package,441,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1096,modifiability,Version,Versions,1096,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:5,performance,error,error,5,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:260,performance,error,error,260,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:410,performance,time,time,410,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:338,reliability,fail,failed,338,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:5,safety,error,error,5,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:260,safety,error,error,260,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1145,safety,log,logging,1145,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1145,security,log,logging,1145,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:1145,testability,log,logging,1145,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:5,usability,error,error,5,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:137,usability,confirm,confirmed,137,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:260,usability,error,error,260,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:519,usability,guid,guide,519,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:574,usability,minim,minimal-bug-reports,574,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2494:680,usability,Minim,Minimal,680,"type error in scale_factor with sc.pl.spatial function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. ---. I can't apply the sc.pl.spatial function because of a type error. The most weird thing here is that i could do this yesterday but it all failed today. I install a new package into this environment during this time, is that possible the new package would interfere the function of scanpy? . **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata_rna.obs['thing']= 'a'. plt.rcParams[""figure.figsize""] = (8, 8). sc.pl.spatial(adata_rna, color = 'thing'). ```. ```pytb. ![image](https://github.com/scverse/scanpy/assets/117483585/60431b58-cafd-4cb0-8bd9-ac7ca1810526). ![image](https://github.com/scverse/scanpy/assets/117483585/9b54d05a-b240-4ae0-adba-a4f9a25b991d). ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. ![image](https://github.com/scverse/scanpy/assets/117483585/c74bf37c-a8fc-42f3-9c44-d0de34a9bf18).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2494
https://github.com/scverse/scanpy/issues/2495:899,energy efficiency,Current,Current,899,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:1202,energy efficiency,load,load,1202,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:20,integrability,sub,subsample,20,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:564,integrability,sub,subsample,564,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:775,integrability,sub,subsampling,775,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:870,integrability,sub,subsample,870,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:1028,integrability,sub,subsample,1028,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:1372,integrability,sub,subset,1372,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:157,modifiability,paramet,parameters,157,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:434,modifiability,pac,package,434,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:761,performance,memor,memory,761,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:1202,performance,load,load,1202,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:1223,performance,memor,memory,1223,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:239,testability,simpl,simple,239,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:709,testability,simpl,simply,709,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:231,usability,tool,tool,231,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:239,usability,simpl,simple,239,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:255,usability,tool,tool,255,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:303,usability,tool,tools,303,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:403,usability,tool,tools,403,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:709,usability,simpl,simply,709,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:761,usability,memor,memory,761,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:907,usability,behavi,behavior,907,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2495:1223,usability,memor,memory,1223,"Request: Ability to subsample `AnnData` in backed mode; ## Feature type. <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? ## Request. <!-- Please describe your wishes below: -->. The `scanpy.pp.subsample` function has been really useful for iteration, experimentation, and tutorials. However, I've found that sometimes I don't want to (or simply can't) read the entire `AnnData` object into memory before subsampling. As such, it would be nice to instantiate an `AnnData` object in backed mode, then subsample that directly. ### Current behavior:. ```python. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. yields:. ```. ValueError: To copy an AnnData object in backed mode, pass a filename: `.copy(filename='myfilename.h5ad')`. To load the object into memory, use `.to_memory()`. ```. ### Workaround:. A workaround I've found is by creating a boolean array and using boolean indexing to grab a random subset of rows from the `AnnData` object:. ```python. import numpy as np. FRACTION = 0.01. np.random.seed(0). random_bool = np.random.choice(. [True, False], size=adata.shape[0], p=[FRACTION, 1 - FRACTION]. ). adata_sample = adata[random_bool, :]. adata_sample_mem = adata_sample.to_memory(). ```. It's easy enough but would be nice to have within `scanpy` itself!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2495
https://github.com/scverse/scanpy/issues/2496:206,deployability,version,version,206,"`invalid value encountered in divide` when running `pp.normalize_pearson_residuals`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html). but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`). ### Minimal code sample (that we can copy&paste without having any data). ```python. analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False). ```. ```pytb. /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide. residuals = diff / np.sqrt(mu + mu**2 / theta). ```. `analytic_pearson[""X""]` . Output:. ```py. array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,. -0.08709449, -0.16926342],. [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,. -0.09342913, -0.18157157],. [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,. 12.02085262, 6.06603257],. ...,. [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,. -0.03033674, -0.05896328],. [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,. -0.03077326, -0.05981169],. [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,. -0.03157547, -0.06137084]]). ```. ```py. adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]. adata.layers[""analytic_pearson_residual",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2496:2077,deployability,Version,Versions,2077,"rocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html). but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`). ### Minimal code sample (that we can copy&paste without having any data). ```python. analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False). ```. ```pytb. /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide. residuals = diff / np.sqrt(mu + mu**2 / theta). ```. `analytic_pearson[""X""]` . Output:. ```py. array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,. -0.08709449, -0.16926342],. [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,. -0.09342913, -0.18157157],. [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,. 12.02085262, 6.06603257],. ...,. [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,. -0.03033674, -0.05896328],. [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,. -0.03077326, -0.05981169],. [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,. -0.03157547, -0.06137084]]). ```. ```py. adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]. adata.layers[""analytic_pearson_residuals""].sum(1). ```. Output:. `array([nan, nan, nan, ..., nan, nan, nan])`. #### Versions. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.3 pynndescent==0.5.10. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2496:2281,deployability,log,logging,2281,"rocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html). but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`). ### Minimal code sample (that we can copy&paste without having any data). ```python. analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False). ```. ```pytb. /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide. residuals = diff / np.sqrt(mu + mu**2 / theta). ```. `analytic_pearson[""X""]` . Output:. ```py. array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,. -0.08709449, -0.16926342],. [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,. -0.09342913, -0.18157157],. [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,. 12.02085262, 6.06603257],. ...,. [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,. -0.03033674, -0.05896328],. [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,. -0.03077326, -0.05981169],. [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,. -0.03157547, -0.06137084]]). ```. ```py. adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]. adata.layers[""analytic_pearson_residuals""].sum(1). ```. Output:. `array([nan, nan, nan, ..., nan, nan, nan])`. #### Versions. scanpy==1.9.3 anndata==0.9.1 umap==0.5.3 numpy==1.23.5 scipy==1.10.1 pandas==2.0.1 scikit-learn==1.2.2 statsmodels==0.13.5 python-igraph==0.10.3 pynndescent==0.5.10. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
https://github.com/scverse/scanpy/issues/2496:206,integrability,version,version,206,"`invalid value encountered in divide` when running `pp.normalize_pearson_residuals`; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Hi, I'm trying to follow [Analytic Pearson residuals](https://www.sc-best-practices.org/preprocessing_visualization/normalization.html). but after getting first 2 nomalizations, I'm stucked with Pearson residuals normalization. It seems like a devided by 0 issue? I don't know. What else I can do to check if the matrix is the problem. already did gene (`min_cells=3`) and cell filtering(`min_genes=200`). ### Minimal code sample (that we can copy&paste without having any data). ```python. analytic_pearson = sc.experimental.pp.normalize_pearson_residuals(adata, inplace=False). ```. ```pytb. /home/sxykdx/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/experimental/pp/_normalization.py:59: RuntimeWarning: invalid value encountered in divide. residuals = diff / np.sqrt(mu + mu**2 / theta). ```. `analytic_pearson[""X""]` . Output:. ```py. array([[-0.08038502, -0.10195383, -0.24513291, ..., 1.47699586,. -0.08709449, -0.16926342],. [-0.08623174, -0.109369 , 3.53739781, ..., -0.54014355,. -0.09342913, -0.18157157],. [-0.07625086, -0.09671059, -0.2325321 , ..., -0.47777291,. 12.02085262, 6.06603257],. ...,. [-0.02799957, -0.03551299, -0.08540438, ..., -0.17560885,. -0.03033674, -0.05896328],. [-0.02840246, -0.03602399, -0.08663319, ..., -0.17813493,. -0.03077326, -0.05981169],. [-0.02914286, -0.03696307, -0.08889143, ..., -0.18277714,. -0.03157547, -0.06137084]]). ```. ```py. adata.layers[""analytic_pearson_residuals""] = analytic_pearson[""X""]. adata.layers[""analytic_pearson_residual",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2496
