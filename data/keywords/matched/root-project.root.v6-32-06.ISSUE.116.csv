id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/issues/16673:2086,security,model,model,2086,"814581). ### Reproducer. #include ""RooRealVar.h"". #include ""RooExponential.h"". #include ""RooGaussian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:2150,security,sign,signal,2150,"xponential.h"". #include ""RooGaussian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:2183,security,model,model,2183,"ian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. f",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:2254,security,model,model,2254,"ataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. frame4->Draw();. . c->Draw();. c->SaveAs(""RooFitMacro.png"");. . pdfadd.P",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:3555,testability,observ,observed,3555,"00);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. frame4->Draw();. . c->Draw();. c->SaveAs(""RooFitMacro.png"");. . pdfadd.Print();. status3->Print();. pdfprod.Print();. status4->Print();. . return 0;. }. [RooFitMacroA.cpp.zip](https://github.com/user-attachments/files/17362710/RooFitMacroA.cpp.zip). just unzip and run as ""root RooFitMacroA.cpp"". ### ROOT version. on lxplus. ROOT v6.26.04-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.26.08-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.28.00-x86_64-centos7-gcc11-opt - observed (different result). ROOT v6.32.02-x86_64-el9-gcc13-opt - observed (different result). ### Installation method. on lxplus, 'setupATLAS', lsetup ""root ..."" . ### Operating system. Linux centos7 and EL9. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:3623,testability,observ,observed,3623,"00);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. frame4->Draw();. . c->Draw();. c->SaveAs(""RooFitMacro.png"");. . pdfadd.Print();. status3->Print();. pdfprod.Print();. status4->Print();. . return 0;. }. [RooFitMacroA.cpp.zip](https://github.com/user-attachments/files/17362710/RooFitMacroA.cpp.zip). just unzip and run as ""root RooFitMacroA.cpp"". ### ROOT version. on lxplus. ROOT v6.26.04-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.26.08-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.28.00-x86_64-centos7-gcc11-opt - observed (different result). ROOT v6.32.02-x86_64-el9-gcc13-opt - observed (different result). ### Installation method. on lxplus, 'setupATLAS', lsetup ""root ..."" . ### Operating system. Linux centos7 and EL9. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:3688,testability,observ,observed,3688,"00);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. frame4->Draw();. . c->Draw();. c->SaveAs(""RooFitMacro.png"");. . pdfadd.Print();. status3->Print();. pdfprod.Print();. status4->Print();. . return 0;. }. [RooFitMacroA.cpp.zip](https://github.com/user-attachments/files/17362710/RooFitMacroA.cpp.zip). just unzip and run as ""root RooFitMacroA.cpp"". ### ROOT version. on lxplus. ROOT v6.26.04-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.26.08-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.28.00-x86_64-centos7-gcc11-opt - observed (different result). ROOT v6.32.02-x86_64-el9-gcc13-opt - observed (different result). ### Installation method. on lxplus, 'setupATLAS', lsetup ""root ..."" . ### Operating system. Linux centos7 and EL9. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:3754,testability,observ,observed,3754,"00);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. frame4->Draw();. . c->Draw();. c->SaveAs(""RooFitMacro.png"");. . pdfadd.Print();. status3->Print();. pdfprod.Print();. status4->Print();. . return 0;. }. [RooFitMacroA.cpp.zip](https://github.com/user-attachments/files/17362710/RooFitMacroA.cpp.zip). just unzip and run as ""root RooFitMacroA.cpp"". ### ROOT version. on lxplus. ROOT v6.26.04-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.26.08-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.28.00-x86_64-centos7-gcc11-opt - observed (different result). ROOT v6.32.02-x86_64-el9-gcc13-opt - observed (different result). ### Installation method. on lxplus, 'setupATLAS', lsetup ""root ..."" . ### Operating system. Linux centos7 and EL9. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:3913,testability,context,context,3913,"00);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. frame4->Draw();. . c->Draw();. c->SaveAs(""RooFitMacro.png"");. . pdfadd.Print();. status3->Print();. pdfprod.Print();. status4->Print();. . return 0;. }. [RooFitMacroA.cpp.zip](https://github.com/user-attachments/files/17362710/RooFitMacroA.cpp.zip). just unzip and run as ""root RooFitMacroA.cpp"". ### ROOT version. on lxplus. ROOT v6.26.04-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.26.08-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.28.00-x86_64-centos7-gcc11-opt - observed (different result). ROOT v6.32.02-x86_64-el9-gcc13-opt - observed (different result). ### Installation method. on lxplus, 'setupATLAS', lsetup ""root ..."" . ### Operating system. Linux centos7 and EL9. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:10,usability,behavi,behaviour,10,"Different behaviour of multi-range fit in RooAddPdf and RooProdPdf; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. When I use RooFit to do multi-range fit, different behaviour in RooAddPdf and RooProdPdf (with the same pdf) is got. When make workspace, people usually add some constrain pdfs to RooAddPdf to form RooProdPdf. However, the fit result is different, even if I just add the RooAddPdf into the RooProdPdf without changing the pdf form. This different behaviour exists in ROOT v6.28/00, and still exists in ROOT v6.32/02. However, in ROOT v6.26/08, the fit results of RooAddPdf and RooProdPdf are the same, which is expected. I make a reproducer script, in which RooAddpdf and RooProdPdf have the same pdf. In ROOT v6.26/08, RooAddpdf and RooProdPdf fit give the same Nbkg, which is expected. ![RooFitMacro_6_26_08_centos7_gcc11](https://github.com/user-attachments/assets/dbb6c4de-a4ad-451c-9f75-2669e9861c68). In ROOT v6.32/02, it gives different Nbkg. ![RooFitMacro_6_32_02](https://github.com/user-attachments/assets/fdff4667-d0b8-4b3e-937d-149577814581). ### Reproducer. #include ""RooRealVar.h"". #include ""RooExponential.h"". #include ""RooGaussian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:194,usability,behavi,behaviour,194,"Different behaviour of multi-range fit in RooAddPdf and RooProdPdf; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. When I use RooFit to do multi-range fit, different behaviour in RooAddPdf and RooProdPdf (with the same pdf) is got. When make workspace, people usually add some constrain pdfs to RooAddPdf to form RooProdPdf. However, the fit result is different, even if I just add the RooAddPdf into the RooProdPdf without changing the pdf form. This different behaviour exists in ROOT v6.28/00, and still exists in ROOT v6.32/02. However, in ROOT v6.26/08, the fit results of RooAddPdf and RooProdPdf are the same, which is expected. I make a reproducer script, in which RooAddpdf and RooProdPdf have the same pdf. In ROOT v6.26/08, RooAddpdf and RooProdPdf fit give the same Nbkg, which is expected. ![RooFitMacro_6_26_08_centos7_gcc11](https://github.com/user-attachments/assets/dbb6c4de-a4ad-451c-9f75-2669e9861c68). In ROOT v6.32/02, it gives different Nbkg. ![RooFitMacro_6_32_02](https://github.com/user-attachments/assets/fdff4667-d0b8-4b3e-937d-149577814581). ### Reproducer. #include ""RooRealVar.h"". #include ""RooExponential.h"". #include ""RooGaussian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:490,usability,behavi,behaviour,490,"Different behaviour of multi-range fit in RooAddPdf and RooProdPdf; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. When I use RooFit to do multi-range fit, different behaviour in RooAddPdf and RooProdPdf (with the same pdf) is got. When make workspace, people usually add some constrain pdfs to RooAddPdf to form RooProdPdf. However, the fit result is different, even if I just add the RooAddPdf into the RooProdPdf without changing the pdf form. This different behaviour exists in ROOT v6.28/00, and still exists in ROOT v6.32/02. However, in ROOT v6.26/08, the fit results of RooAddPdf and RooProdPdf are the same, which is expected. I make a reproducer script, in which RooAddpdf and RooProdPdf have the same pdf. In ROOT v6.26/08, RooAddpdf and RooProdPdf fit give the same Nbkg, which is expected. ![RooFitMacro_6_26_08_centos7_gcc11](https://github.com/user-attachments/assets/dbb6c4de-a4ad-451c-9f75-2669e9861c68). In ROOT v6.32/02, it gives different Nbkg. ![RooFitMacro_6_32_02](https://github.com/user-attachments/assets/fdff4667-d0b8-4b3e-937d-149577814581). ### Reproducer. #include ""RooRealVar.h"". #include ""RooExponential.h"". #include ""RooGaussian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:887,usability,user,user-attachments,887,"Different behaviour of multi-range fit in RooAddPdf and RooProdPdf; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. When I use RooFit to do multi-range fit, different behaviour in RooAddPdf and RooProdPdf (with the same pdf) is got. When make workspace, people usually add some constrain pdfs to RooAddPdf to form RooProdPdf. However, the fit result is different, even if I just add the RooAddPdf into the RooProdPdf without changing the pdf form. This different behaviour exists in ROOT v6.28/00, and still exists in ROOT v6.32/02. However, in ROOT v6.26/08, the fit results of RooAddPdf and RooProdPdf are the same, which is expected. I make a reproducer script, in which RooAddpdf and RooProdPdf have the same pdf. In ROOT v6.26/08, RooAddpdf and RooProdPdf fit give the same Nbkg, which is expected. ![RooFitMacro_6_26_08_centos7_gcc11](https://github.com/user-attachments/assets/dbb6c4de-a4ad-451c-9f75-2669e9861c68). In ROOT v6.32/02, it gives different Nbkg. ![RooFitMacro_6_32_02](https://github.com/user-attachments/assets/fdff4667-d0b8-4b3e-937d-149577814581). ### Reproducer. #include ""RooRealVar.h"". #include ""RooExponential.h"". #include ""RooGaussian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. Ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:1035,usability,user,user-attachments,1035,"ooAddPdf and RooProdPdf; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. When I use RooFit to do multi-range fit, different behaviour in RooAddPdf and RooProdPdf (with the same pdf) is got. When make workspace, people usually add some constrain pdfs to RooAddPdf to form RooProdPdf. However, the fit result is different, even if I just add the RooAddPdf into the RooProdPdf without changing the pdf form. This different behaviour exists in ROOT v6.28/00, and still exists in ROOT v6.32/02. However, in ROOT v6.26/08, the fit results of RooAddPdf and RooProdPdf are the same, which is expected. I make a reproducer script, in which RooAddpdf and RooProdPdf have the same pdf. In ROOT v6.26/08, RooAddpdf and RooProdPdf fit give the same Nbkg, which is expected. ![RooFitMacro_6_26_08_centos7_gcc11](https://github.com/user-attachments/assets/dbb6c4de-a4ad-451c-9f75-2669e9861c68). In ROOT v6.32/02, it gives different Nbkg. ![RooFitMacro_6_32_02](https://github.com/user-attachments/assets/fdff4667-d0b8-4b3e-937d-149577814581). ### Reproducer. #include ""RooRealVar.h"". #include ""RooExponential.h"". #include ""RooGaussian.h"". #include ""RooAddPdf.h"". #include ""RooProdPdf.h"". #include ""RooDataSet.h"". #include ""RooPlot.h"". #include ""RooExtendPdf.h"". #include ""RooFitResult.h"". . #include ""TCanvas.h"". . int RooFitMacroA(). {. using namespace RooFit;. . RooRealVar x(""x"", ""x"", 0, 100);. RooRealVar alpha(""alpha"", ""alpha"", -0.04, -0.1, -0.0);. RooExponential model(""model"", ""Exponential model"", x, alpha);. . // Define side band regions and full range. . x.setRange(""LEFT"", 0, 20);. x.setRange(""RIGHT"", 60, 100);. x.setRange(""BLIND"",20,60);. x.setRange(""FULL"", 0, 100);. std::unique_ptr<RooDataSet> data{model.generate(x, 10000)};. . RooRealVar Nsig(""Nsig"", ""Number of signal events"", 1000, 0, 2000);. RooRealVar Nbkg(""Nbkg"", ""Number of background events"", 10000, 0, 20000);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal mo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/issues/16673:3380,usability,user,user-attachments,3380,"00);. . RooRealVar mean(""mean"", ""Mean of signal model"", 40.);. RooRealVar width(""width"", ""Width of signal model"", 5.);. RooGaussian sig(""sig"", ""Signal model"", x, mean, width);. . // RooAddPdf pdfadd(""pdfadd"", ""NSig*signal + NBkg*background"", {sig, model}, {Nsig, Nbkg});. RooAddPdf pdfadd(""pdfadd"", ""NBkg*background"", {model}, {Nbkg});. RooProdPdf pdfprod(""pdfprod"", ""pdfprod"", RooArgSet(pdfadd));. . pdfadd.Print();. pdfprod.Print();. . TCanvas* c = new TCanvas(""c"", ""c"", 1400, 1000);. c->Divide(2,2);. . c->cd(1);. RooPlot* frame1 = x.frame();. pdfadd.plotOn(frame1);. pdfadd.paramOn(frame1,Label(""RooAddPdf""));. frame1->Draw();. . c->cd(2);. RooPlot* frame2 = x.frame();. pdfprod.plotOn(frame2);. pdfprod.paramOn(frame2,Label(""RooProdPdf""));. frame2->Draw();. . c->cd(3);. RooPlot* frame3 = x.frame();. RooFitResult* status3 = pdfadd.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status3->Print();. data->plotOn(frame3);. pdfadd.plotOn(frame3);. pdfadd.paramOn(frame3,Label(""RooAddPdf_fitted""));. frame3->Draw();. . c->cd(4);. RooPlot* frame4 = x.frame();. RooFitResult* status4 = pdfprod.fitTo(*data,Range(""LEFT,RIGHT""),Save());. status4->Print();. data->plotOn(frame4);. pdfprod.plotOn(frame4);. pdfprod.paramOn(frame4,Label(""RooProdPdf_fitted""));. frame4->Draw();. . c->Draw();. c->SaveAs(""RooFitMacro.png"");. . pdfadd.Print();. status3->Print();. pdfprod.Print();. status4->Print();. . return 0;. }. [RooFitMacroA.cpp.zip](https://github.com/user-attachments/files/17362710/RooFitMacroA.cpp.zip). just unzip and run as ""root RooFitMacroA.cpp"". ### ROOT version. on lxplus. ROOT v6.26.04-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.26.08-x86_64-centos7-gcc11-opt - no observed (same result). ROOT v6.28.00-x86_64-centos7-gcc11-opt - observed (different result). ROOT v6.32.02-x86_64-el9-gcc13-opt - observed (different result). ### Installation method. on lxplus, 'setupATLAS', lsetup ""root ..."" . ### Operating system. Linux centos7 and EL9. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16673
https://github.com/root-project/root/pull/16674:17,energy efficiency,gpu,gpu,17,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:35,energy efficiency,GPU,GPU,35,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:59,energy efficiency,gpu,gpu,59,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:63,integrability,compon,components,63,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:63,interoperability,compon,components,63,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:63,modifiability,compon,components,63,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:17,performance,gpu,gpu,17,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:35,performance,GPU,GPU,35,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16674:59,performance,gpu,gpu,59,[CI] Enable tmva-gpu and cudnn for GPU runner; Enable more gpu components.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16674
https://github.com/root-project/root/pull/16675:226,integrability,discover,discovered,226,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:66,interoperability,XML,XML,66,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:75,interoperability,xml,xml,75,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:226,interoperability,discover,discovered,226,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:33,safety,test,tests,33,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:89,safety,test,test,89,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:33,testability,test,tests,33,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:89,testability,test,test,89,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:142,testability,coverag,coverage,142,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16675:226,usability,discov,discovered,226,"[RF] Disable `stressHistFactroy` tests if ROOT was not built with XML; If `xml=OFF`, the test can still be compiled, which is always good for coverage. But it can't be run: the `hist2workspace` executable is missing. This was discovered in this PR:. * https://github.com/root-project/root/pull/16674",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16675
https://github.com/root-project/root/pull/16677:20,modifiability,variab,variables,20,"[ntuple] Initialize variables to silence compiler warnings; Clang warns that ""variable 'px' may be uninitialized when used here"" because it does not understand the interplay with `RNTupleView`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16677
https://github.com/root-project/root/pull/16677:78,modifiability,variab,variable,78,"[ntuple] Initialize variables to silence compiler warnings; Clang warns that ""variable 'px' may be uninitialized when used here"" because it does not understand the interplay with `RNTupleView`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16677
https://github.com/root-project/root/pull/16677:140,reliability,doe,does,140,"[ntuple] Initialize variables to silence compiler warnings; Clang warns that ""variable 'px' may be uninitialized when used here"" because it does not understand the interplay with `RNTupleView`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16677
https://github.com/root-project/root/pull/16677:149,testability,understand,understand,149,"[ntuple] Initialize variables to silence compiler warnings; Clang warns that ""variable 'px' may be uninitialized when used here"" because it does not understand the interplay with `RNTupleView`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16677
https://github.com/root-project/root/pull/16678:211,deployability,updat,updated,211,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:7,energy efficiency,model,model,7,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:129,energy efficiency,model,model,129,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:181,safety,test,tested,181,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:211,safety,updat,updated,211,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:7,security,model,model,7,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:129,security,model,model,129,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:211,security,updat,updated,211,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16678:181,testability,test,tested,181,Ntuple model create bare; # This Pull request:. adds a `fCreateBare` option to `RCreateModelOptions that allows reconstructing a model without a default entry. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary). This PR fixes #16324.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16678
https://github.com/root-project/root/pull/16679:350,availability,cluster,cluster,350,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:22,deployability,build,building,22,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:135,deployability,build,building,135,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:195,deployability,manag,manages,195,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:350,deployability,cluster,cluster,350,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:195,energy efficiency,manag,manages,195,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:319,energy efficiency,current,currently,319,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:444,energy efficiency,optim,optimal,444,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:254,integrability,sub,sub-indices,254,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:195,safety,manag,manages,195,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/pull/16679:78,usability,support,support,78,"[ntuple] Add MT index building; This PR introduces the first steps towards MT support for the `RNTupleIndex`, by enabling mulithreaded building of the index. To enable this, the index itself now manages multiple _index partitions_, which are essentially sub-indices for a particular entry range. These entry ranges are currently set according to the cluster boundaries, but further benchmarking and evaluation will be required to determine the optimal partitioning scheme.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16679
https://github.com/root-project/root/issues/16680:261,availability,failur,failures,261,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:364,availability,error,error,364,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2593,availability,Operat,Operating,2593,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:261,deployability,fail,failures,261,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:589,deployability,modul,module,589,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1107,deployability,fail,failed,1107,"- [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1828,deployability,fail,failed,1828,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2520,deployability,version,version,2520,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2541,deployability,Instal,Installation,2541,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2573,deployability,instal,install,2573,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2309,integrability,repositor,repository,2309,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2520,integrability,version,version,2520,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2309,interoperability,repositor,repository,2309,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:589,modifiability,modul,module,589,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2520,modifiability,version,version,2520,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:71,performance,parallel,parallel,71,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:261,performance,failur,failures,261,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:364,performance,error,error,364,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2367,performance,parallel,parallel,2367,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:261,reliability,fail,failures,261,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1107,reliability,fail,failed,1107,"- [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1828,reliability,fail,failed,1828,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:364,safety,error,error,364,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:589,safety,modul,module,589,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2242,safety,test,test,2242,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:770,security,Session,Session,770,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:851,security,Session,Session,851,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:860,security,Session,Session,860,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:888,security,Session,Session,888,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:952,security,Session,Session,952,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:961,security,Session,Session,961,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:995,security,Session,Session,995,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1058,security,Session,Session,1058,"e run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1067,security,Session,Session,1067,"parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_A",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1350,security,Session,Session,1350,"10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allow",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1405,security,Session,Session,1405," ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. #",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1463,security,Session,Session,1463,"ost recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1565,security,Session,Session,1565,".py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both lo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1621,security,Session,Session,1621,"me/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Add",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1727,security,Session,Session,1727,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:1787,security,Session,Session,1787,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:455,testability,Trace,Traceback,455,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2242,testability,test,test,2242,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:2633,testability,context,context,2633,"ick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. I also see from grepping:. ```. ./src/./tutorials/tmva/TMVA_SOFIE_GNN_Application.C. 10:#include ""encoder.hxx"". ./src/./tutorials/tmva/TMVA_SOFIE_GNN.py. 127:ROOT.gInterpreter.Declare('#include ""encoder.hxx""'). ```. So at least both of those test are uses the same generated file name (I can't find it in the repository) `encoder.hxx` and are still allowed to run in parallel ... leading to unstable result. ### Reproducer. Rerun https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971. ### ROOT version. master. ### Installation method. both local install and CI. ### Operating system. linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/issues/16680:364,usability,error,error,364,"TMVA/Sofie tutorials used same name for generated files bur are run in parallel.; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I see (for example in https://github.com/root-project/root/pull/16664/checks?check_run_id=31435842971): failures like:. ```. /github/home/ROOT-CI/src/tutorials/tmva/TMVA_SOFIE_GNN_Application.C:10:10: fatal error: 'encoder.hxx' file not found. #include ""encoder.hxx"". ^~~~~~~~~~~~~. ```. or . ```. Traceback (most recent call last):. File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 226, in <module>. gnn = SofieGNN(). File ""/home/pcanal/root_working/code/quick-devel/tutorials/tmva/TMVA_SOFIE_GNN.py"", line 150, in __init__. self.encoder_session = ROOT.TMVA_SOFIE_encoder.Session(). TypeError: none of the 4 overloaded methods succeeded. Full details:. Session::Session(TMVA_SOFIE_encoder::Session&&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session(const TMVA_SOFIE_encoder::Session&) =>. TypeError: takes at least 1 arguments (0 given). Session::Session() =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. void __cppyy_internal::init_TMVA_SOFIE_encoder__Session(TMVA_SOFIE_encoder::Session*& self, const TMVA_SOFIE_encoder::Edge_Update::Session& edge_update = TMVA_SOFIE_encoder::Edge. _Update::Session{}, const vector<float>& fEdgeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Node_Update::Session& node_update = TMVA_SOFIE_encoder::Node_Update::Session{}, co. nst vector<float>& fNodeInputs = vector<float>{}, const TMVA_SOFIE_encoder::Global_Update::Session& global_update = TMVA_SOFIE_encoder::Global_Update::Session{}) =>. runtime_error: TMVA-SOFIE failed to read the correct tensor name; expected name is tensor_EncodeProcessDecodeMLPGraphIndependentgraph_independentedge_modelmlplinear_3w0 , read . 0.00669210032. ```. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16680
https://github.com/root-project/root/pull/16681:33,deployability,API,API,33,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:114,deployability,API,API,114,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:346,deployability,depend,depending,346,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:408,deployability,modul,module,408,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:498,deployability,API,API,498,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:119,energy efficiency,Current,Currently,119,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:33,integrability,API,API,33,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:114,integrability,API,API,114,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:346,integrability,depend,depending,346,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:498,integrability,API,API,498,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:21,interoperability,distribut,distributed,21,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:33,interoperability,API,API,33,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:91,interoperability,distribut,distributed,91,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:114,interoperability,API,API,114,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:396,interoperability,distribut,distributed,396,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:498,interoperability,API,API,498,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:346,modifiability,depend,depending,346,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:408,modifiability,modul,module,408,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:346,safety,depend,depending,346,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:408,safety,modul,module,408,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:346,testability,depend,depending,346,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16681:505,usability,prefer,preferrable,505,"[df] Unify local and distributed API; Unify the main common entry points between local and distributed RDataFrame API. Currently these changes:. - The ROOT.RDataFrame constructor. - ROOT.RDF.RunGraphs. - ROOT.RDF.Experimental.VariationsFor. Anytime one of the above is called, a pythonization will dispatch to the appropriate RDataFrame flavour, depending on the arguments. Previous usage of the distributed module with fully qualified names of functions still works, although usage of the unified API is preferrable and advisable.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16681
https://github.com/root-project/root/pull/16682:8,deployability,Build,Build,8,[cmake] Build clad with one core only; fixes #16654. See also https://github.com/root-project/root/pull/16667 that on top of these changes adds a Ubuntu 24.10 build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16682
https://github.com/root-project/root/pull/16682:159,deployability,build,build,159,[cmake] Build clad with one core only; fixes #16654. See also https://github.com/root-project/root/pull/16667 that on top of these changes adds a Ubuntu 24.10 build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16682
https://github.com/root-project/root/pull/16682:28,energy efficiency,core,core,28,[cmake] Build clad with one core only; fixes #16654. See also https://github.com/root-project/root/pull/16667 that on top of these changes adds a Ubuntu 24.10 build.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16682
https://github.com/root-project/root/pull/16684:50,availability,failur,failures,50,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:184,availability,failur,failure,184,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:50,deployability,fail,failures,50,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:144,deployability,build,builds,144,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:155,deployability,fail,failing,155,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:184,deployability,fail,failure,184,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:50,performance,failur,failures,50,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:184,performance,failur,failure,184,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:50,reliability,fail,failures,50,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:155,reliability,fail,failing,155,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:184,reliability,fail,failure,184,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:16,safety,test,test-stressgraphics-chrome,16,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:179,safety,test,test,179,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:16,testability,test,test-stressgraphics-chrome,16,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16684:179,testability,test,test,179,[cmake] Disable test-stressgraphics-chrome; Until failures on Linux Fedora 39 are understood. This PR is marked as emergency since all fedora39 builds are failing because of this test failure.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16684
https://github.com/root-project/root/pull/16685:225,integrability,batch,batch,225,"[webgui] support Safari, improve headless modes, disable `stressgraphics-chrome`; 1. Support Safari, only can be used in interactive mode. 2. Always run `firefox` via `runfirefox.sh` script (Linux/Mac), let stop `firefox` in batch mode on Mac. 3. Enable webgpu usage for chrome, requires on Mac to support 3d graphics. 4. Adjust `stressGraphics_web.ref` file to match Mac/Chrome, Mac/Firefox, Windows/Firefox.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16685
https://github.com/root-project/root/pull/16685:225,performance,batch,batch,225,"[webgui] support Safari, improve headless modes, disable `stressgraphics-chrome`; 1. Support Safari, only can be used in interactive mode. 2. Always run `firefox` via `runfirefox.sh` script (Linux/Mac), let stop `firefox` in batch mode on Mac. 3. Enable webgpu usage for chrome, requires on Mac to support 3d graphics. 4. Adjust `stressGraphics_web.ref` file to match Mac/Chrome, Mac/Firefox, Windows/Firefox.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16685
https://github.com/root-project/root/pull/16685:9,usability,support,support,9,"[webgui] support Safari, improve headless modes, disable `stressgraphics-chrome`; 1. Support Safari, only can be used in interactive mode. 2. Always run `firefox` via `runfirefox.sh` script (Linux/Mac), let stop `firefox` in batch mode on Mac. 3. Enable webgpu usage for chrome, requires on Mac to support 3d graphics. 4. Adjust `stressGraphics_web.ref` file to match Mac/Chrome, Mac/Firefox, Windows/Firefox.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16685
https://github.com/root-project/root/pull/16685:85,usability,Support,Support,85,"[webgui] support Safari, improve headless modes, disable `stressgraphics-chrome`; 1. Support Safari, only can be used in interactive mode. 2. Always run `firefox` via `runfirefox.sh` script (Linux/Mac), let stop `firefox` in batch mode on Mac. 3. Enable webgpu usage for chrome, requires on Mac to support 3d graphics. 4. Adjust `stressGraphics_web.ref` file to match Mac/Chrome, Mac/Firefox, Windows/Firefox.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16685
https://github.com/root-project/root/pull/16685:121,usability,interact,interactive,121,"[webgui] support Safari, improve headless modes, disable `stressgraphics-chrome`; 1. Support Safari, only can be used in interactive mode. 2. Always run `firefox` via `runfirefox.sh` script (Linux/Mac), let stop `firefox` in batch mode on Mac. 3. Enable webgpu usage for chrome, requires on Mac to support 3d graphics. 4. Adjust `stressGraphics_web.ref` file to match Mac/Chrome, Mac/Firefox, Windows/Firefox.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16685
https://github.com/root-project/root/pull/16685:207,usability,stop,stop,207,"[webgui] support Safari, improve headless modes, disable `stressgraphics-chrome`; 1. Support Safari, only can be used in interactive mode. 2. Always run `firefox` via `runfirefox.sh` script (Linux/Mac), let stop `firefox` in batch mode on Mac. 3. Enable webgpu usage for chrome, requires on Mac to support 3d graphics. 4. Adjust `stressGraphics_web.ref` file to match Mac/Chrome, Mac/Firefox, Windows/Firefox.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16685
https://github.com/root-project/root/pull/16685:298,usability,support,support,298,"[webgui] support Safari, improve headless modes, disable `stressgraphics-chrome`; 1. Support Safari, only can be used in interactive mode. 2. Always run `firefox` via `runfirefox.sh` script (Linux/Mac), let stop `firefox` in batch mode on Mac. 3. Enable webgpu usage for chrome, requires on Mac to support 3d graphics. 4. Adjust `stressGraphics_web.ref` file to match Mac/Chrome, Mac/Firefox, Windows/Firefox.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16685
https://github.com/root-project/root/issues/16687:798,availability,error,error,798,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:851,availability,Error,Error,851,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:980,availability,Error,Error,980,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1128,availability,Error,Error,1128,"escription. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. as",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1257,availability,Error,Error,1257," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1897,availability,Operat,Operating,1897," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1410,deployability,version,version,1410," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1867,deployability,Instal,Installation,1867," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:571,energy efficiency,Draw,Draw,571,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1410,integrability,version,version,1410," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:892,interoperability,coordinat,coordinates,892,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1024,interoperability,coordinat,coordinates,1024,"on when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large a",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1169,interoperability,coordinat,coordinates,1169," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1301,interoperability,coordinat,coordinates,1301," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1410,modifiability,version,version,1410," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:798,performance,error,error,798,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:851,performance,Error,Error,851,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:980,performance,Error,Error,980,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1128,performance,Error,Error,1128,"escription. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. as",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1257,performance,Error,Error,1257," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1991,performance,time,timeseries,1991," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:2064,performance,time,time,2064," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:2118,performance,time,time,2118," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:798,safety,error,error,798,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:851,safety,Error,Error,851,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:980,safety,Error,Error,980,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1128,safety,Error,Error,1128,"escription. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. as",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1257,safety,Error,Error,1257," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:0,security,Loss,Loss,0,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1565,security,Team,Team,1565," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1945,testability,context,context,1945," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:798,usability,error,error,798,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:851,usability,Error,Error,851,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:980,usability,Error,Error,980,"Loss of floating point precision when saving TCanvas as ROOT macro; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeserie",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1128,usability,Error,Error,1128,"escription. Floating point precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. as",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1257,usability,Error,Error,1257," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16687:1729,usability,help,help,1729," precision should be preserved when saving plots as ROOT macros with `TCanvas::SaveAs()`. This can probably be achieved with not too much effort using `std::setprecision`:. https://en.cppreference.com/w/cpp/io/manip/setprecision. ### Reproducer. Run this code, which works fine:. ```c++. TCanvas *c = new TCanvas(""c"", ""c"");. TH1D *histo = new TH1D(""histo"", ""histo"", 1, 595780500.110732, 595780531.878908);. histo->Draw();. c->SaveAs(""plot.C"");. ```. The resulting macro will not preserve the precision on the floating point numbers:. ```c++. TH1D *histo__1 = new TH1D(""histo__1"",""histo"",1,5.957805e+08,5.957805e+08);. ```. And you'll get an error when running it:. ```txt. Processing plot.C... Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. root [1] Error in <TCanvas::Range>: illegal world coordinates range: x1=595780500.000000, y1=-0.131250, x2=595780500.000000, y2=1.181250. Error in <TCanvas::RangeAxis>: illegal axis coordinates range: xmin=595780500.000000, ymin=0.000000, xmax=595780500.000000, ymax=1.050000. ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 18:21:53 |. | From tags/6-32-06@6-32-06 |. | With g++ (GCC) 13.3.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. Nix. ### Operating system. NixOS (Linux). ### Additional context. Can easily happen in the analysis of timeseries, where one often has large axis values because they represent time with respect to some reference point far back in time (e.g. astrophysics, finance, ...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16687
https://github.com/root-project/root/issues/16689:329,availability,FAILUR,FAILURES,329,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3506,availability,Operat,Operating,3506,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:329,deployability,FAIL,FAILURES,329,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:508,deployability,build,build,508,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2803,deployability,build,build,2803,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3447,deployability,version,version,3447,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3468,deployability,Instal,Installation,3468,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:140,energy efficiency,GPU,GPU-PR,140,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:222,energy efficiency,GPU,GPU-related,222,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2280,energy efficiency,cpu,cpu,2280," ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2296,energy efficiency,gpu,gpu,2296,"-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3025,energy efficiency,Draw,Draw,3025,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3245,energy efficiency,Draw,Draw,3245,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:191,integrability,compon,components,191,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3447,integrability,version,version,3447,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:191,interoperability,compon,components,191,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3524,interoperability,registr,registry,3524,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:191,modifiability,compon,components,191,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3447,modifiability,version,version,3447,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:21,performance,time,times,21,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:140,performance,GPU,GPU-PR,140,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:222,performance,GPU,GPU-related,222,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:308,performance,time,time,308,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:329,performance,FAILUR,FAILURES,329,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2280,performance,cpu,cpu,2280," ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2296,performance,gpu,gpu,2296,"-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3082,performance,content,content,3082,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3175,performance,content,content,3175,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:329,reliability,FAIL,FAILURES,329,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2771,reliability,doe,does,2771,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:16,safety,test,test,16,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:283,safety,test,test,283,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:324,safety,TEST,TEST,324,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2766,safety,test,test,2766,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:0,testability,Simpl,Simple,0,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:16,testability,test,test,16,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:283,testability,test,test,283,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:324,testability,TEST,TEST,324,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2766,testability,test,test,2766,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3581,testability,context,context,3581,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:0,usability,Simpl,Simple,0,"Simple notebook test times out when root7=on, webgui=Off; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. In the GPU-PR #16580, @dpiparo suggested to disable a few components to speed up the non-GPU-related parts. After disabling the webgui, the following test started to hang and time out:. ```. TEST FAILURES:. 1521:roottest-python-JupyROOT-Cpp_IMT_Canvas_notebook. ```. ### Reproducer. This is the full config:. ```. cmake -S '/github/home/ROOT-CI/src' -B '/github/home/ROOT-CI/build' -DCMAKE_BUILD_TYPE=RelWithDebInfo ""-DCMAKE_BUILD_TYPE=RelWithDebInfo"" ""-Dalien=off"" ""-Dall=off"" ""-Darrow=off"" ""-Dasan=off"" ""-Dasimage=on"" ""-Dasserts=off"" ""-Dbuiltin_cfitsio=off"" ""-Dbuiltin_clang=on"" ""-Dbuiltin_cling=on"" ""-Dbuiltin_cppzmq=on"" ""-Dbuiltin_davix=off"" ""-Dbuiltin_fftw3=off"" ""-Dbuiltin_freetype=off"" ""-Dbuiltin_ftgl=off"" ""-Dbuiltin_gl2ps=off"" ""-Dbuiltin_glew=off"" ""-Dbuiltin_gsl=off"" ""-Dbuiltin_llvm=on"" ""-Dbuiltin_lz4=off"" ""-Dbuiltin_lzma=off"" ""-Dbuiltin_nlohmannjson=off"" ""-Dbuiltin_openssl=off"" ""-Dbuiltin_openui5=on"" ""-Dbuiltin_pcre=off"" ""-Dbuiltin_tbb=off"" ""-Dbuiltin_unuran=on"" ""-Dbuiltin_vc=off"" ""-Dbuiltin_vdt=off"" ""-Dbuiltin_veccore=off"" ""-Dbuiltin_xrootd=off"" ""-Dbuiltin_xxhash=off"" ""-Dbuiltin_zeromq=on"" ""-Dbuiltin_zlib=off"" ""-Dbuiltin_zstd=off"" ""-Dccache=on"" ""-Dcefweb=off"" ""-Dclad=on"" ""-Dclingtest=off"" ""-Dcocoa=off"" ""-Dcoverage=off"" ""-Dcuda=on"" ""-Dcudnn=off"" ""-Dcxxmodules=off"" ""-Ddaos=off"" ""-Ddataframe=on"" ""-Ddavix=on"" ""-Ddcache=off"" ""-Ddev=off"" ""-Ddistcc=off"" ""-Dfail-on-missing=on"" ""-Dfcgi=off"" ""-Dfftw3=on"" ""-Dfitsio=on"" ""-Dfortran=off"" ""-Dgdml=off"" ""-Dgminimal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:2714,usability,minim,minimal,2714,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/issues/16689:3059,usability,statu,status,3059,"mal=off"" ""-Dgnuinstall=off"" ""-Dgsl_shared=off"" ""-Dgviz=off"" ""-Dhttp=on"" ""-Dimt=on"" ""-Djemalloc=off"" ""-Dlibcxx=off"" ""-Dmacos_native=off"" ""-Dmathmore=on"" ""-Dmemory_termination=off"" ""-Dminimal=off"" ""-Dmpi=off"" ""-Dmysql=off"" ""-Dodbc=off"" ""-Dopengl=on"" ""-Dpgsql=on"" ""-Dpyroot=on"" ""-Dpythia8=off"" ""-Dqt5web=off"" ""-Dqt6web=off"" ""-Dr=off"" ""-Droofit=on"" ""-Droofit_multiprocess=on"" ""-Droot7=on"" ""-Drootbench=off"" ""-Droottest=on"" ""-Droottest_force_checkout=off"" ""-Drpath=on"" ""-Druntime_cxxmodules=on"" ""-Dshadowpw=off"" ""-Dshared=on"" ""-Dsoversion=off"" ""-Dspectrum=off"" ""-Dsqlite=off"" ""-Dssl=on"" ""-Dtcmalloc=off"" ""-Dtest_distrdf_dask=off"" ""-Dtest_distrdf_pyspark=off"" ""-Dtesting=on"" ""-Dtmva-cpu=on"" ""-Dtmva-gpu=off"" ""-Dtmva-pymva=on"" ""-Dtmva-rmva=off"" ""-Dtmva-sofie=off"" ""-Dtmva=on"" ""-Dunfold=off"" ""-Dunuran=on"" ""-During=off"" ""-Dvc=off"" ""-Dvdt=on"" ""-Dveccore=off"" ""-Dvecgeom=off"" ""-Dwebgui=off"" ""-Dwin_broken_tests=off"" ""-Dwinrtdebug=off"" ""-Dx11=on"" ""-Dxml=on"" ""-Dxrootd=on"". ```. This is the notebook it tries to run:. https://github.com/root-project/roottest/blob/master/python/JupyROOT/Cpp_IMT_Canvas.ipynb. And this is a minimal reproducer if you reverse engineer what the test does:. ```. root@bbb56c35bcff:~/build# jupyter nbconvert --debug --to notebook --ExecutePreprocessor.enabled=True ../roottest/python/JupyROOT/Cpp_IMT_Canvas.ipynb. [...]. [NbConvertApp] Executing cell:. ROOT::EnableImplicitMT();. TCanvas c(""c"", ""c"");. c.Draw();. [NbConvertApp] msg_type: status. [NbConvertApp] content: {'execution_state': 'busy'}. [NbConvertApp] msg_type: execute_input. [NbConvertApp] content: {'code': 'ROOT::EnableImplicitMT();\nTCanvas c(""c"", ""c"");\nc.Draw();', 'execution_count': 1}. ```. You can make it pass by:. - Enabling webgui (it seems to create an image based on the output). - Or by running with `--ExecutePreprocessor.enabled=False`. ### ROOT version. Master. ### Installation method. From source. ### Operating system. registry.cern.ch/root-ci/ubuntu2404-cuda. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16689
https://github.com/root-project/root/pull/16691:113,safety,Test,Testing,113,"[webgui] improve chrome handling, enable `stressgraphics-chrome` again; It is adjusting chrome on top of #16685. Testing chrome and firefox stressgraphics.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16691
https://github.com/root-project/root/pull/16691:113,testability,Test,Testing,113,"[webgui] improve chrome handling, enable `stressgraphics-chrome` again; It is adjusting chrome on top of #16685. Testing chrome and firefox stressgraphics.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16691
https://github.com/root-project/root/pull/16692:171,availability,consist,consistent,171,"[RF] Update SBI tutorials with improved plot styling and labels; This is because these plots are also going to be shown at CHEP, and it would be nice if the tutorials are consistent by then.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16692
https://github.com/root-project/root/pull/16692:5,deployability,Updat,Update,5,"[RF] Update SBI tutorials with improved plot styling and labels; This is because these plots are also going to be shown at CHEP, and it would be nice if the tutorials are consistent by then.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16692
https://github.com/root-project/root/pull/16692:5,safety,Updat,Update,5,"[RF] Update SBI tutorials with improved plot styling and labels; This is because these plots are also going to be shown at CHEP, and it would be nice if the tutorials are consistent by then.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16692
https://github.com/root-project/root/pull/16692:5,security,Updat,Update,5,"[RF] Update SBI tutorials with improved plot styling and labels; This is because these plots are also going to be shown at CHEP, and it would be nice if the tutorials are consistent by then.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16692
https://github.com/root-project/root/pull/16692:171,usability,consist,consistent,171,"[RF] Update SBI tutorials with improved plot styling and labels; This is because these plots are also going to be shown at CHEP, and it would be nice if the tutorials are consistent by then.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16692
https://github.com/root-project/root/pull/16693:110,energy efficiency,model,model,110,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:192,energy efficiency,model,model,192,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:16,integrability,sub,subfield,16,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:86,integrability,sub,subfields,86,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:212,integrability,sub,subfields,212,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:25,security,access,access,25,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:110,security,model,model,110,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:127,security,access,access,127,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16693:192,security,model,model,192,"[ntuple] Enable subfield access in `REntry`; This PR adds the possibility to register subfields to an RNTuple model for direct access to the values of these fields in entries belonging to the model. Registerging subfields in a collection is not permitted as of this PR, but will be added at a later point, borrowing from the implementation of `RNTupleDS`. This functionality will be used in the `RNTupleProcessor`, which provides an iterator over an `REntry`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16693
https://github.com/root-project/root/pull/16694:129,deployability,version,version,129,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:215,deployability,fail,failing,215,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:428,deployability,updat,updated,428,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:129,integrability,version,version,129,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:129,modifiability,version,version,129,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:215,reliability,fail,failing,215,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:61,safety,test,test,61,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:206,safety,test,test,206,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:398,safety,test,tested,398,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:428,safety,updat,updated,428,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:428,security,updat,updated,428,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:61,testability,test,test,61,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:206,testability,test,test,206,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16694:398,testability,test,tested,398,[cling] Windows: Fix declaration for C99 and re-enable Gnu.C test; # This Pull request:. ## Changes or fixes:. This is a rebased version of https://github.com/root-project/cling/pull/174 by @marsupial. The test was failing for a reason that likely shouldn't be ignored. This reverts commit https://github.com/root-project/cling/commit/5947e13cb99052b6f7a5b501244ee2be9be9d080. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16694
https://github.com/root-project/root/pull/16695:240,deployability,updat,updated,240,[ntuple] return const char* instead of std::string from RColumnElemen…; …t::GetTypeName. This doesn't impose a potential allocation (or the use of std::string) on the caller unnecessarily. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16695
https://github.com/root-project/root/pull/16695:121,energy efficiency,alloc,allocation,121,[ntuple] return const char* instead of std::string from RColumnElemen…; …t::GetTypeName. This doesn't impose a potential allocation (or the use of std::string) on the caller unnecessarily. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16695
https://github.com/root-project/root/pull/16695:94,reliability,doe,doesn,94,[ntuple] return const char* instead of std::string from RColumnElemen…; …t::GetTypeName. This doesn't impose a potential allocation (or the use of std::string) on the caller unnecessarily. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16695
https://github.com/root-project/root/pull/16695:210,safety,test,tested,210,[ntuple] return const char* instead of std::string from RColumnElemen…; …t::GetTypeName. This doesn't impose a potential allocation (or the use of std::string) on the caller unnecessarily. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16695
https://github.com/root-project/root/pull/16695:240,safety,updat,updated,240,[ntuple] return const char* instead of std::string from RColumnElemen…; …t::GetTypeName. This doesn't impose a potential allocation (or the use of std::string) on the caller unnecessarily. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16695
https://github.com/root-project/root/pull/16695:240,security,updat,updated,240,[ntuple] return const char* instead of std::string from RColumnElemen…; …t::GetTypeName. This doesn't impose a potential allocation (or the use of std::string) on the caller unnecessarily. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16695
https://github.com/root-project/root/pull/16695:210,testability,test,tested,210,[ntuple] return const char* instead of std::string from RColumnElemen…; …t::GetTypeName. This doesn't impose a potential allocation (or the use of std::string) on the caller unnecessarily. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16695
https://github.com/root-project/root/pull/16697:11,deployability,Scale,Scale,11,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:92,deployability,scale,scale,92,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:11,energy efficiency,Scale,Scale,11,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:92,energy efficiency,scale,scale,92,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:11,modifiability,Scal,Scale,11,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:92,modifiability,scal,scale,92,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:11,performance,Scale,Scale,11,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:92,performance,scale,scale,92,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:29,testability,context,context,29,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16697:37,usability,menu,menu,37,[hist] add Scale function to context menu; So that you can right click on the histogram and scale it. sibling PR is in https://github.com/root-project/roottest/pull/1203,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16697
https://github.com/root-project/root/pull/16698:130,availability,avail,available,130,[ntuple] Allow casting with RNTupleViews; This conveniently also allows looking at columns through a `typedef` that might only be available with a dictionary.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16698
https://github.com/root-project/root/pull/16698:130,reliability,availab,available,130,[ntuple] Allow casting with RNTupleViews; This conveniently also allows looking at columns through a `typedef` that might only be available with a dictionary.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16698
https://github.com/root-project/root/pull/16698:130,safety,avail,available,130,[ntuple] Allow casting with RNTupleViews; This conveniently also allows looking at columns through a `typedef` that might only be available with a dictionary.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16698
https://github.com/root-project/root/pull/16698:130,security,availab,available,130,[ntuple] Allow casting with RNTupleViews; This conveniently also allows looking at columns through a `typedef` that might only be available with a dictionary.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16698
https://github.com/root-project/root/pull/16699:203,reliability,doe,does,203,[webgui] do not use `--no-sandbox` in interactive session; Chrome requires this option in headless mode - when run as superuser in CI. But for normal interactive mode newest chrome complains that option does not exists.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16699
https://github.com/root-project/root/pull/16699:181,safety,compl,complains,181,[webgui] do not use `--no-sandbox` in interactive session; Chrome requires this option in headless mode - when run as superuser in CI. But for normal interactive mode newest chrome complains that option does not exists.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16699
https://github.com/root-project/root/pull/16699:26,security,sandbox,sandbox,26,[webgui] do not use `--no-sandbox` in interactive session; Chrome requires this option in headless mode - when run as superuser in CI. But for normal interactive mode newest chrome complains that option does not exists.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16699
https://github.com/root-project/root/pull/16699:50,security,session,session,50,[webgui] do not use `--no-sandbox` in interactive session; Chrome requires this option in headless mode - when run as superuser in CI. But for normal interactive mode newest chrome complains that option does not exists.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16699
https://github.com/root-project/root/pull/16699:181,security,compl,complains,181,[webgui] do not use `--no-sandbox` in interactive session; Chrome requires this option in headless mode - when run as superuser in CI. But for normal interactive mode newest chrome complains that option does not exists.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16699
https://github.com/root-project/root/pull/16699:38,usability,interact,interactive,38,[webgui] do not use `--no-sandbox` in interactive session; Chrome requires this option in headless mode - when run as superuser in CI. But for normal interactive mode newest chrome complains that option does not exists.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16699
https://github.com/root-project/root/pull/16699:150,usability,interact,interactive,150,[webgui] do not use `--no-sandbox` in interactive session; Chrome requires this option in headless mode - when run as superuser in CI. But for normal interactive mode newest chrome complains that option does not exists.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16699
https://github.com/root-project/root/pull/16700:315,deployability,updat,updated,315,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16700:190,safety,test,tests,190,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16700:285,safety,test,tested,285,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16700:315,safety,updat,updated,315,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16700:315,security,updat,updated,315,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16700:185,testability,unit,unit,185,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16700:190,testability,test,tests,190,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16700:285,testability,test,tested,285,[ntuple] fix RNTuple::Merge not passing mergeOpts to RNTupleMerger; This is causing `hadd` to ignore the compression options when merging RNTuples. We didn't catch this bug because the unit tests were bypassing TFileMerger and calling directly into RNTupleMerger. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16700
https://github.com/root-project/root/pull/16701:158,deployability,log,logical,158,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:126,interoperability,plug,plugins,126,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:232,interoperability,plug,plugins,232,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:328,interoperability,plug,plugins,328,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:158,safety,log,logical,158,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:158,security,log,logical,158,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:158,testability,log,logical,158,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:120,usability,tool,tools,120,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:226,usability,tool,tools,226,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:269,usability,close,closes,269,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16701:322,usability,tool,tools,322,[CMake] Fix warning in clad CMakeLists.txt; Fixes the following warning:. ```. CMake Warning (dev) in interpreter/cling/tools/plugins/clad/CMakeLists.txt:. A logical block opening on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:17 (if). closes on the line. /root/root_src/interpreter/cling/tools/plugins/clad/CMakeLists.txt:27 (endif). with mis-matching arguments. This warning is for project developers. Use -Wno-dev to suppress it. ```. @bellenot,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16701
https://github.com/root-project/root/pull/16702:1,energy efficiency,core,core,1,[core] add utility functions for compression; - R__getCompressionAlgorithm(): inspects the compression algorithm used by a given buffer;. - AlgorithmFromCompressionSettings(): convert a compression settings int to a EAlgorithm.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16702
https://github.com/root-project/root/pull/16702:129,integrability,buffer,buffer,129,[core] add utility functions for compression; - R__getCompressionAlgorithm(): inspects the compression algorithm used by a given buffer;. - AlgorithmFromCompressionSettings(): convert a compression settings int to a EAlgorithm.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16702
https://github.com/root-project/root/pull/16703:168,deployability,depend,dependency,168,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:49,integrability,compon,components,49,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:74,integrability,compon,components,74,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:168,integrability,depend,dependency,168,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:348,integrability,compon,component,348,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:49,interoperability,compon,components,49,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:60,interoperability,specif,specified,60,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:74,interoperability,compon,components,74,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:93,interoperability,specif,specified,93,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:348,interoperability,compon,component,348,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:49,modifiability,compon,components,49,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:74,modifiability,compon,components,74,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:168,modifiability,depend,dependency,168,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:348,modifiability,compon,component,348,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:168,safety,depend,dependency,168,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:168,testability,depend,dependency,168,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16703:303,usability,user,users,303,"[CMake] Don't require `json` in ROOTConfig if no components specified; If components are not specified, we should assume nlohmann_json is not required. Propagating the dependency on nlohmann_json just for the sake of one ROOT feature (ROOTEve) that might be used is unreasonable. We can expect from the users that link against ROOTEve to list this component explicitly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16703
https://github.com/root-project/root/pull/16705:76,availability,error,errors,76,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:273,availability,error,error,273,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:65,interoperability,format,formatting,65,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:76,performance,error,errors,76,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:273,performance,error,error,273,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:76,safety,error,errors,76,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:83,safety,prevent,preventing,83,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:273,safety,error,error,273,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:83,security,preven,preventing,83,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:27,usability,minim,minimal,27,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:76,usability,error,errors,76,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:265,usability,minim,minimal,265,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16705:273,usability,error,error,273,"[webgui] adjust tutorials, minimal jsroot fix; 1. Fixing several formatting errors preventing doxygen generation. 2. Rename files in `tutorials\webgui` to let correctly create doxygen. 3. Fix jsroot_importmap generation for `jsroot/geom` and `jsroot/three`. 4. Fix minimal error in JSROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16705
https://github.com/root-project/root/pull/16706:34,integrability,interfac,interfacing,34,"[graf3d] use the proper type when interfacing with FT_Outline and FTContour; Fixes a compiler warning. Freetype 2.13.3 changed the type of a data member from char* to. unsigned char*, so we need to pass the correct type to FTContour to. avoid compiler warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16706
https://github.com/root-project/root/pull/16706:34,interoperability,interfac,interfacing,34,"[graf3d] use the proper type when interfacing with FT_Outline and FTContour; Fixes a compiler warning. Freetype 2.13.3 changed the type of a data member from char* to. unsigned char*, so we need to pass the correct type to FTContour to. avoid compiler warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16706
https://github.com/root-project/root/pull/16706:34,modifiability,interfac,interfacing,34,"[graf3d] use the proper type when interfacing with FT_Outline and FTContour; Fixes a compiler warning. Freetype 2.13.3 changed the type of a data member from char* to. unsigned char*, so we need to pass the correct type to FTContour to. avoid compiler warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16706
https://github.com/root-project/root/pull/16706:237,safety,avoid,avoid,237,"[graf3d] use the proper type when interfacing with FT_Outline and FTContour; Fixes a compiler warning. Freetype 2.13.3 changed the type of a data member from char* to. unsigned char*, so we need to pass the correct type to FTContour to. avoid compiler warnings",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16706
https://github.com/root-project/root/pull/16707:181,availability,robust,robustness,181,[RF] Implement style and color command argument Pythonizations in C++; This is done to reduce the feature divergence between PyROOT and C++ ROOT. Also improves code performance and robustness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16707
https://github.com/root-project/root/pull/16707:87,energy efficiency,reduc,reduce,87,[RF] Implement style and color command argument Pythonizations in C++; This is done to reduce the feature divergence between PyROOT and C++ ROOT. Also improves code performance and robustness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16707
https://github.com/root-project/root/pull/16707:165,performance,perform,performance,165,[RF] Implement style and color command argument Pythonizations in C++; This is done to reduce the feature divergence between PyROOT and C++ ROOT. Also improves code performance and robustness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16707
https://github.com/root-project/root/pull/16707:181,reliability,robust,robustness,181,[RF] Implement style and color command argument Pythonizations in C++; This is done to reduce the feature divergence between PyROOT and C++ ROOT. Also improves code performance and robustness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16707
https://github.com/root-project/root/pull/16707:181,safety,robust,robustness,181,[RF] Implement style and color command argument Pythonizations in C++; This is done to reduce the feature divergence between PyROOT and C++ ROOT. Also improves code performance and robustness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16707
https://github.com/root-project/root/pull/16707:31,usability,command,command,31,[RF] Implement style and color command argument Pythonizations in C++; This is done to reduce the feature divergence between PyROOT and C++ ROOT. Also improves code performance and robustness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16707
https://github.com/root-project/root/pull/16707:165,usability,perform,performance,165,[RF] Implement style and color command argument Pythonizations in C++; This is done to reduce the feature divergence between PyROOT and C++ ROOT. Also improves code performance and robustness.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16707
https://github.com/root-project/root/pull/16709:140,deployability,updat,updated,140,[ntuple] rearrange code to avoid a compiler warning; Fix a warning in RNTupleSerializer. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16709
https://github.com/root-project/root/pull/16709:27,safety,avoid,avoid,27,[ntuple] rearrange code to avoid a compiler warning; Fix a warning in RNTupleSerializer. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16709
https://github.com/root-project/root/pull/16709:110,safety,test,tested,110,[ntuple] rearrange code to avoid a compiler warning; Fix a warning in RNTupleSerializer. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16709
https://github.com/root-project/root/pull/16709:140,safety,updat,updated,140,[ntuple] rearrange code to avoid a compiler warning; Fix a warning in RNTupleSerializer. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16709
https://github.com/root-project/root/pull/16709:140,security,updat,updated,140,[ntuple] rearrange code to avoid a compiler warning; Fix a warning in RNTupleSerializer. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16709
https://github.com/root-project/root/pull/16709:110,testability,test,tested,110,[ntuple] rearrange code to avoid a compiler warning; Fix a warning in RNTupleSerializer. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16709
https://github.com/root-project/root/pull/16711:27,deployability,depend,dependencies,27,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:105,energy efficiency,model,model,105,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:27,integrability,depend,dependencies,27,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:27,modifiability,depend,dependencies,27,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:22,safety,test,test,22,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:27,safety,depend,dependencies,27,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:41,safety,avoid,avoid,41,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:80,safety,avoid,avoid,80,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:105,security,model,model,105,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:22,testability,test,test,22,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16711:27,testability,depend,dependencies,27,"[tmva] Impose correct test dependencies, avoid multiple invocations of Declare, avoid races when writing model files; This PR fixes #16680.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16711
https://github.com/root-project/root/pull/16712:103,deployability,contain,contains,103,"[ntuple] Fixes to model/field cloning; As a user-visible effect, fixes buffered writing when the model contains a class field or a TObject field and the column representation of (nested) members inside those fields were changed. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16712
https://github.com/root-project/root/pull/16712:18,energy efficiency,model,model,18,"[ntuple] Fixes to model/field cloning; As a user-visible effect, fixes buffered writing when the model contains a class field or a TObject field and the column representation of (nested) members inside those fields were changed. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16712
https://github.com/root-project/root/pull/16712:97,energy efficiency,model,model,97,"[ntuple] Fixes to model/field cloning; As a user-visible effect, fixes buffered writing when the model contains a class field or a TObject field and the column representation of (nested) members inside those fields were changed. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16712
https://github.com/root-project/root/pull/16712:71,integrability,buffer,buffered,71,"[ntuple] Fixes to model/field cloning; As a user-visible effect, fixes buffered writing when the model contains a class field or a TObject field and the column representation of (nested) members inside those fields were changed. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16712
https://github.com/root-project/root/pull/16712:18,security,model,model,18,"[ntuple] Fixes to model/field cloning; As a user-visible effect, fixes buffered writing when the model contains a class field or a TObject field and the column representation of (nested) members inside those fields were changed. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16712
https://github.com/root-project/root/pull/16712:97,security,model,model,97,"[ntuple] Fixes to model/field cloning; As a user-visible effect, fixes buffered writing when the model contains a class field or a TObject field and the column representation of (nested) members inside those fields were changed. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16712
https://github.com/root-project/root/pull/16712:44,usability,user,user-visible,44,"[ntuple] Fixes to model/field cloning; As a user-visible effect, fixes buffered writing when the model contains a class field or a TObject field and the column representation of (nested) members inside those fields were changed. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16712
https://github.com/root-project/root/pull/16714:41,energy efficiency,model,model,41,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:448,energy efficiency,model,model,448,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:617,energy efficiency,model,models,617,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:9,safety,Prevent,Prevent,9,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:9,security,Preven,Prevent,9,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:17,security,modif,modifications,17,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:41,security,model,model,41,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:297,security,access,accessed,297,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:448,security,model,model,448,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/pull/16714:617,security,model,models,617,"[ntuple] Prevent modifications of frozen model; A number of changes, split into multiple commits:. * `RProjectedFields` moves to `Internal` and `GetFieldZero()` is not `const` (plus one fix to take references instead of pointers to `RNTupleModel`). The projected fields of a `RNTupleModel` can be accessed via `Internal::GetProjectedFieldsFromModel()`. * A new `Internal::GetFieldZeroFromModel()` is used to get the `RFieldZero` also from a frozen model. * `RNTupleModel::GetFieldZero()` is split into `GetConstFieldZero()`, which can always be called, and `GetMutableFieldZero()`, which is only allowed for unfrozen models.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16714
https://github.com/root-project/root/issues/16715:148,availability,state,state,148,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2228,availability,Operat,Operating,2228,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:5,deployability,fail,fails,5,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:280,deployability,build,build,280,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1364,deployability,modul,modules,1364,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1490,deployability,fail,fails,1490,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1754,deployability,build,build,1754,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1960,deployability,instal,installed,1960,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2032,deployability,instal,installed,2032,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2042,deployability,upgrad,upgradable,2042,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2122,deployability,instal,installed,2122,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2132,deployability,upgrad,upgradable,2132,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2174,deployability,version,version,2174,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2195,deployability,Instal,Installation,2195,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1774,energy efficiency,gpu,gpu,1774,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:126,integrability,configur,configure,126,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:148,integrability,state,state,148,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1543,integrability,discover,discovered,1543,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2174,integrability,version,version,2174,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:234,interoperability,share,shared,234,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:535,interoperability,Architectur,Architectures,535,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:821,interoperability,Architectur,Architectures,821,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1543,interoperability,discover,discovered,1543,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:126,modifiability,configur,configure,126,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1364,modifiability,modul,modules,1364,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2042,modifiability,upgrad,upgradable,2042,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2132,modifiability,upgrad,upgradable,2132,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2174,modifiability,version,version,2174,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1774,performance,gpu,gpu,1774,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:5,reliability,fail,fails,5,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1468,reliability,doe,doesn,1468,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1490,reliability,fail,fails,1490,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1364,safety,modul,modules,1364,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:126,security,configur,configure,126,"TMVA fails to link to cudnn; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. It seems that one can configure tmva into a state that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1949,security,apt,apt,1949,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:2284,testability,context,context,2284,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1149,usability,user,users,1149,"e that cudnn is disabled, but it's still trying to link:. ```. [ 78%] Linking CXX shared library ../../lib/libTMVA.so. cd /root/build/tmva/tmva && /usr/bin/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/issues/16715:1543,usability,discov,discovered,1543,"n/cmake -E cmake_link_script CMakeFiles/TMVA.dir/link.txt --verbose=1. /usr/bin/c++ -fPIC -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual. [...]. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.1]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x1b): undefined reference to `cudnnGetErrorString'. /usr/bin/ld: CMakeFiles/TMVA.dir/src/DNN/Architectures/Cudnn.cu.o: in function `TMVA::DNN::cudnnError(cudnnStatus_t, char const*, int, bool) [clone .part.0] [clone .constprop.2]':. tmpxft_0001274b_00000000-6_Cudnn.cudafe1.cpp:(.text+0x5b): undefined reference to `cudnnGetErrorString'. [...]. ```. I believe the way to trick it is to set `tmva-cudnn=ON`. It looks like users were not supposed to touch it, instead they should have set `-Dcudnn=On`. Setting the latter, the following code runs:. https://github.com/root-project/root/blob/45f13f0c6e145b0ddef82bf049a43fbe4870381b/cmake/modules/SearchInstalledSoftware.cmake#L1638-L1654. Instead, I set `tmva-cudnn` directly, the code above doesn't run, and tmva fails to link because the location of cudnn is never discovered. Maybe, one of `cudnn` or `tmva-cudnn` should be removed, and only a single flag should enable or disable it. ### Reproducer. On ubuntu with cuda and cudnn, I did:. ```. (ROOT-CI) root@102b09e3cf56:~/build# cmake -Dtmva-gpu=On -Dtesting=On -Dtmva-cudnn=On -Dbuiltin_openui5=Off -Dclad=Off -Dgdml=Off -Dgeom=Off -Dopengl=Off -Droot7=Off -Dspectrum=Off -Droofit=Off -Dvdt=Off ../root. ```. ```. $ apt list --installed | grep cudnn. libcudnn9-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. libcudnn9-dev-cuda-12/unknown,now 9.3.0.75-1 amd64 [installed,upgradable to: 9.5.0.50-1]. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. Ubuntu with cuda-12-6. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16715
https://github.com/root-project/root/pull/16717:228,deployability,stack,stackoverflow,228,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16717:104,integrability,event,eventual,104,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16717:655,integrability,wrap,wrapped,655,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16717:148,modifiability,variab,variables,148,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16717:357,safety,avoid,avoid,357,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16717:432,testability,simul,simulation,432,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16717:543,usability,user,users,543,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16717:710,usability,help,helper,710,"Limit number of threads used by NumPy in tutorials; Set the environment for the tutorials, which is the eventual ROOT_environ plus some environment variables related to limiting the number of threads used by NumPy. See: https://stackoverflow.com/questions/30791550/limit-number-of-threads-in-numpy. Possibly related to #16552, but the main motivation is to avoid an excessive number of threads when running the RooFit tutorials for simulation based inference. So far, the environment was set inside these tutorials, but this is distracting to users who look at these tutorials. Also, make sure that the same environment is used for all tutorials that are wrapped in `ROOT_ADD_TEST`. Furthermore, remove unused helper function.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16717
https://github.com/root-project/root/pull/16718:45,availability,error,error,45,[TMVA] Require torch<2.5 otherwise on ARM an error is prompted; See https://github.com/pytorch/pytorch/issues/138333.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16718
https://github.com/root-project/root/pull/16718:45,performance,error,error,45,[TMVA] Require torch<2.5 otherwise on ARM an error is prompted; See https://github.com/pytorch/pytorch/issues/138333.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16718
https://github.com/root-project/root/pull/16718:45,safety,error,error,45,[TMVA] Require torch<2.5 otherwise on ARM an error is prompted; See https://github.com/pytorch/pytorch/issues/138333.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16718
https://github.com/root-project/root/pull/16718:45,usability,error,error,45,[TMVA] Require torch<2.5 otherwise on ARM an error is prompted; See https://github.com/pytorch/pytorch/issues/138333.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16718
https://github.com/root-project/root/issues/16719:369,availability,failur,failure,369,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:448,availability,avail,available,448,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:166,deployability,fail,fail,166,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:356,deployability,fail,failing,356,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:369,deployability,fail,failure,369,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:524,deployability,fail,fails,524,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:644,deployability,Fail,Failed,644,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:697,deployability,Fail,Failed,697,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:752,deployability,Fail,Failed,752,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:51,energy efficiency,model,model,51,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:369,performance,failur,failure,369,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:166,reliability,fail,fail,166,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:356,reliability,fail,failing,356,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:369,reliability,fail,failure,369,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:448,reliability,availab,available,448,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:524,reliability,fail,fails,524,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:644,reliability,Fail,Failed,644,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:697,reliability,Fail,Failed,697,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:752,reliability,Fail,Failed,752,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:8,safety,test,test,8,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:199,safety,Test,TestRModelParserKeras,199,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:239,safety,Test,TestRModelParserPyTorch,239,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:292,safety,test,tests,292,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:448,safety,avail,available,448,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:519,safety,test,test,519,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:51,security,model,model,51,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:448,security,availab,available,448,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:8,testability,test,test,8,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:199,testability,Test,TestRModelParserKeras,199,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:239,testability,Test,TestRModelParserPyTorch,239,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:292,testability,test,tests,292,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:519,testability,test,test,519,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16719:387,usability,indicat,indicate,387,"PyTorch test/tutorials are (likely) using the same model files.; . Doing:. ```. ctest -R tmva -j 32. ```. will result in an arbitrary result (sometimes pass sometime fail) for. ```. gtest-tmva-pymva-TestRModelParserKeras. gtest-tmva-pymva-TestRModelParserPyTorch . ```. re-running just those tests (whether they succeeded or not) will lead to both of them failing. The failure report is indicate that they 'now' need the BLAS library (which is not available on the system). As a possible clue (or not), the following 3 test fails systemically on the system due to the missing BLAS library:. ```. 996 - tutorial-tmva-TMVA_SOFIE_GNN_Application (Failed). 1000 - tutorial-tmva-TMVA_SOFIE_RDataFrame (Failed). 1002 - tutorial-tmva-TMVA_SOFIE_RSofieReader (Failed). ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16719
https://github.com/root-project/root/issues/16720:154,availability,consist,consistently,154,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:148,deployability,fail,fails,148,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:148,reliability,fail,fails,148,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:7,safety,test,test,7,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:142,safety,test,tests,142,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:350,safety,Test,TestRModelParserKeras,350,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:7,testability,test,test,7,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:142,testability,test,tests,142,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:350,testability,Test,TestRModelParserKeras,350,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/issues/16720:154,usability,consist,consistently,154,4 TMVA test requires BLAS library but run even when it was not found.; See https://github.com/root-project/root/issues/16553. The following 3 tests fails consistently with missing BLAS symbols. ```. 984:tutorial-tmva-TMVA_SOFIE_GNN_Application. 988:tutorial-tmva-TMVA_SOFIE_RDataFrame. 990:tutorial-tmva-TMVA_SOFIE_RSofieReader. 353-gtest-tmva-pymva-TestRModelParserKeras. ```.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16720
https://github.com/root-project/root/pull/16721:582,energy efficiency,model,model,582,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:620,energy efficiency,model,model,620,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:446,performance,time,time,446,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:593,performance,disk,disk,593,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:646,performance,perform,performant,646,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:725,performance,perform,performance,725,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:782,performance,cach,cache,782,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:136,safety,except,exception,136,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:310,safety,except,exception,310,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:690,safety,compl,completeness,690,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:778,safety,hot,hot,778,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:582,security,model,model,582,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:620,security,model,model,620,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:690,security,compl,completeness,690,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:646,usability,perform,performant,646,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16721:725,usability,perform,performance,725,"[ntuple] Mark RField methods as final and remove duplicate implementations; * Mark (most) `RField` specializations as `final`; the only exception is `RField<std::array<ItemT, N>>` which is the base class of `RField<ItemT[N]>`. * Mark (most) overriden functions in the `RFieldBase` hierarchy as final; the only exception is `RSimpleField::GenerateColumns` which is overriden by `RRealField`. * Remove many duplicate implementations in the compile-time specialized classes: The reasoning is that we use the type-erased implementations with `RFieldBase::Create`, when reconstructing a model from disk, or when `Clone`ing a model. So if they are not performant, we have to fix them anyway. For completeness, there seems to be no performance change in the `iotools` benchmarks (with hot cache, to put emphasis on the RNTuple implementation).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16721
https://github.com/root-project/root/pull/16723:123,deployability,fail,fails,123,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:153,interoperability,platform,platforms,153,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:81,performance,time,time,81,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:123,reliability,fail,fails,123,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:30,safety,test,test,30,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:40,safety,test,testLikelihoodJob,40,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:59,safety,test,test,59,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:30,testability,test,test,30,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:40,testability,test,testLikelihoodJob,40,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:59,testability,test,test,59,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16723:164,usability,hint,hinting,164,"[RF] Disable `rf615` tutorial test and `testLikelihoodJob` test that is prone to time out; The rf615 tutorial occasionally fails on cleanup on different platforms, hinting to a PyROOT issue. We disable the rf617 tutorial for now. as the covered RooFit functionality is also covered by rf617 (the multidimensional case).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16723
https://github.com/root-project/root/pull/16724:95,deployability,Continu,Continue,95,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:291,deployability,build,building,291,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:341,deployability,build,builds,341,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:446,deployability,artifact,artifact,446,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:489,deployability,build,build,489,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:547,deployability,Instal,Install,547,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:562,deployability,version,version,562,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:754,deployability,releas,releases,754,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:788,deployability,build,build,788,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:808,deployability,build,build,808,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:835,deployability,build,building,835,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:930,deployability,build,builds,930,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:1014,deployability,depend,dependencies,1014,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:315,energy efficiency,core,core,315,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:770,energy efficiency,OPTIM,OPTIMIZATION,770,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:562,integrability,version,version,562,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:1014,integrability,depend,dependencies,1014,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:562,modifiability,version,version,562,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:620,modifiability,pac,packages,620,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:1014,modifiability,depend,dependencies,1014,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:770,performance,OPTIMIZ,OPTIMIZATION,770,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:137,safety,test,testing,137,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:363,safety,test,tests,363,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:479,safety,Test,Test,479,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:1014,safety,depend,dependencies,1014,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:137,testability,test,testing,137,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:363,testability,test,tests,363,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:479,testability,Test,Test,479,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:1014,testability,depend,dependencies,1014,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:268,usability,Statu,Status,268,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:326,usability,workflow,workflow,326,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:396,usability,document,documentation,396,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:516,usability,document,documentation,516,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:814,usability,workflow,workflows,814,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:858,usability,workflow,workflow,858,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:937,usability,document,documentation,937,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:997,usability,support,support,997,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/pull/16724:1103,usability,workflow,workflow,1103,"[skip-ci] [docu] Generate Doxygen docs with Makefile + GitHub Actions 3; # This Pull request:. Continue Adrian's work: This draft PR for testing the doxygen generation GitHub action with our self-hosted runners. Uses our existing Makefile setup. Initial PR #16046. ## Status. Succeeded with building only docs for `core`. The workflow first builds `root` without tests and then makes the Doxygen documentation. It also uploads it to GitHub as an artifact. ## Checklist:. - [x] **Test with build from scratch and all documentation folders**. - [x] Install latest version of `doxygen`, `qhelpgenerator` and other required packages in image at https://github.com/root-project/root-ci-images. - [ ] Upload result to website/S3. - [ ] Nightlies for different releases. - [ ] OPTIMIZATION: use build from existing build workflows instead of building again in this workflow. We could for example add a job in `root-master.yml` that only builds documentation after the `run_nightlies` job. Github actions support defining dependencies between jobs: https://docs.github.com/en/actions/using-jobs/using-jobs-in-a-workflow#defining-prerequisite-jobs. This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16724
https://github.com/root-project/root/issues/16725:2241,availability,Operat,Operating,2241,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:176,deployability,contain,containing,176,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:195,deployability,contain,containing,195,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1401,deployability,continu,continue,1401,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:2121,deployability,version,version,2121,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:2144,deployability,Instal,Installation,2144,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:918,energy efficiency,Load,Load,918,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1147,energy efficiency,Charg,Charged,1147,"hes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Install",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1309,energy efficiency,Load,LoadTree,1309,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1455,energy efficiency,Charg,Charge,1455,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1482,energy efficiency,charg,charge,1482,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1502,energy efficiency,Charg,Charge,1502,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:666,integrability,event,events,666,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:2121,integrability,version,version,2121,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:2121,modifiability,version,version,2121,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:253,performance,time,time,253,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:918,performance,Load,Load,918,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1309,performance,Load,LoadTree,1309,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:698,safety,input,inputfile,698,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1022,safety,input,inputfile,1022,"nesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:261,security,access,accesses,261,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:423,security,access,accessing,423,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1610,testability,trace,traceback,1610,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:2289,testability,context,context,2289,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:698,usability,input,inputfile,698,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:773,usability,help,help,773,"Pyroot crashes reading TClonesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1022,usability,input,inputfile,1022,"nesArray in a TTree; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. A pyroot python program crashes when reading a TFile containing a TTree containing a TClonesArray. It appears to crash the second time it accesses the TClonesArray. This has started happening since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/issues/16725:1586,usability,Close,Close,1586,"ing since moving to ROOT 6.32 on AlmaLinux 9.4. It worked fine with 6.20.04 running on Centos7. The library for accessing the TTree information was created using MakeProject. . ### Reproducer. This is the python code that crashes. ```. #!/usr/bin/env python3. import os. import ROOT. import argparse. parser = argparse.ArgumentParser(description='Analyse events.'). parser.add_argument(""inputfile""). parser.add_argument(""-o"",""--outputfile"",default=""Output.root"",help=""Name of output file""). args = parser.parse_args(). READEVENTANALYSISLIBRARY=ROOT.gSystem.Getenv(""READEVENTANALYSISLIBRARY"");. ROOT.gSystem.Load(READEVENTANALYSISLIBRARY);. globalRecon = ROOT.TChain(""ReconDir/Global""). globalRecon.AddFile(args.inputfile). OutputFile = ROOT.TFile(args.outputfile,""RECREATE"",""ND280 Analysis""). hTrackMomenta = ROOT.TH1F(""TrackMomenta"", ""Charged Track Momentum"", 100, 0, 1000.0). entries = globalRecon.GetEntries(). for entry in range(entries):. 	print("" entry = ""+str(entry)). 	ientry = globalRecon.LoadTree(entry). 	if ientry < 0:. 		break. 	nb = globalRecon.GetEntry(entry). 	if nb<=0:. 		continue. 	. 	for	pid in globalRecon.PIDs :. 		if(pid.Charge != 0) :. 			print("" charge is ""+str(pid.Charge)). 		#	hTrackMomenta.Fill(pid.FrontMomentum). OutputFile.Write(). OutputFile.Close(). ```. The crash traceback suggest this as the line causing the crash:. #7 0x00007fe963a68e9a in TBranchElement::ReadLeavesClones(TBuffer&) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #8 0x00007fe963a60899 in TBranch::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #9 0x00007fe963a7326b in TBranchElement::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. #10 0x00007fe963ad7300 in TTree::GetEntry(long long, int) () from /home/aleph/ajf/t2k/root/lib/libTree.so. ### ROOT version. 6.32.00 . ### Installation method. prebuilt binary root_v6.32.00.Linux-almalinux9.4-x86_64-gcc11.4.tar.gz. ### Operating system. AlmaLinux 9.4. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16725
https://github.com/root-project/root/pull/16726:19,availability,Operat,Operator,19,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:124,availability,operat,operator,124,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:181,availability,Operat,Operator,181,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:307,deployability,updat,updated,307,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:235,energy efficiency,model,models,235,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:51,safety,test,tests,51,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:220,safety,test,tests,220,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:277,safety,test,tested,277,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:307,safety,updat,updated,307,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:235,security,model,models,235,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:307,security,updat,updated,307,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:51,testability,test,tests,51,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:220,testability,test,tests,220,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:277,testability,test,tested,277,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/pull/16726:107,usability,support,support,107,[tmva][sofie] Clip Operator implemented along with tests; # This Pull request:. This Pull request adds the support for Clip operator in SOFIE. ## Changes or fixes:. Implemented the Operator Class files and also included tests and onnx models for the same. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16726
https://github.com/root-project/root/issues/16730:932,availability,ERROR,ERROR,932,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:983,availability,ERROR,ERROR,983,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1034,availability,ERROR,ERROR,1034,"memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ******",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1085,availability,ERROR,ERROR,1085,"or duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:2325,availability,Operat,Operating,2325,"e""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. </tr>. </table>. ### ROOT version. see in table. ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:2254,deployability,version,version,2254,"e""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. </tr>. </table>. ### ROOT version. see in table. ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:2281,deployability,Instal,Installation,2281,"e""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. </tr>. </table>. ### ROOT version. see in table. ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:2302,deployability,build,build,2302,"e""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. </tr>. </table>. ### ROOT version. see in table. ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1189,energy efficiency,Draw,Draw,1189,"er. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break ***",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1215,energy efficiency,draw,draws,1215,"can.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ``",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:2254,integrability,version,version,2254,"e""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. </tr>. </table>. ### ROOT version. see in table. ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:2254,modifiability,version,version,2254,"e""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. </tr>. </table>. ### ROOT version. see in table. ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:37,performance,memor,memory,37,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:398,performance,memor,memory,398,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:932,performance,ERROR,ERROR,932,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:983,performance,ERROR,ERROR,983,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1034,performance,ERROR,ERROR,1034,"memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ******",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1085,performance,ERROR,ERROR,1085,"or duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:932,safety,ERROR,ERROR,932,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:983,safety,ERROR,ERROR,983,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1034,safety,ERROR,ERROR,1034,"memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ******",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1085,safety,ERROR,ERROR,1085,"or duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:2365,testability,context,context,2365,"e""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. </tr>. </table>. ### ROOT version. see in table. ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:37,usability,memor,memory,37,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:398,usability,memor,memory,398,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:932,usability,ERROR,ERROR,932,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:983,usability,ERROR,ERROR,983,"Issue with Cling and TTree object in memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ***********",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1034,usability,ERROR,ERROR,1034,"memory; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ******",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/issues/16730:1085,usability,ERROR,ERROR,1085,"or duplicates. ### Description. Strange issue with Cling and TTree:Scan(), please see table in Reproducer. ### Reproducer. file `scan.C`. ```C++. #include ""TTree.h"". #include ""TRandom.h"". TTree *t = nullptr;. void scan() {. const Int_t kMax = 10;. Int_t n;. Float_t a[kMax];. t = new TTree(""t"", ""tree""); // in memory. t->Branch(""n"", &n, ""n/I"");. t->Branch(""a"", a, ""a[n]/F"");. for (Int_t i = 0; i < 5; i++) {. n = gRandom->Rndm()*(kMax-1);. for (Int_t j = 0; j < n; j++). a[j] = gRandom->Gaus(0, 1);. t->Fill();. }. // t->Scan(""a[0]"");. }. ```. <table>. <tr>. <td> Fedora 40, root master (2024-10-22)</td> <td> lxplus.cern.ch (RHEL 9.4), root v6.32.06 </td>. </tr>. <tr>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * 1.255e-41 *. ERROR leaf:a, len=22 and max=8. * 1 * 1.3911939 *. ERROR leaf:a, len=22 and max=8. * 2 * 1.1125664 *. ERROR leaf:a, len=22 and max=8. * 3 * 2.0609021 *. ERROR leaf:a, len=22 and max=8. * 4 * -0.182436 *. ************************. (long long) 5. root [2] t->Draw(""a[0]""). root [3] // draws correct all 5 values. ```. </td>. <td>. ```C++. $ root scan.C. root [0]. Processing scan.C... root [1] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. (long long) 5. root [2]. ```. </td>. </tr>. <tr>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911939 *. * 2 * 1.1125664 *. * 3 * 2.0609021 *. * 4 * -0.182436 *. ************************. *** Break *** segmentation violation. ```. </td>. <td>. ```C++. $ root. root [0] .L scan.C. root [1] scan(). root [2] t->Scan(""a[0]""). ************************. * Row * a[0] *. ************************. * 0 * -0.434764 *. * 1 * 1.3911",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16730
https://github.com/root-project/root/pull/16731:57,availability,failur,failures,57,Adjust stressGraphics_web.ref for fedora40; Should solve failures on fedora40 in #16729,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16731
https://github.com/root-project/root/pull/16731:57,deployability,fail,failures,57,Adjust stressGraphics_web.ref for fedora40; Should solve failures on fedora40 in #16729,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16731
https://github.com/root-project/root/pull/16731:57,performance,failur,failures,57,Adjust stressGraphics_web.ref for fedora40; Should solve failures on fedora40 in #16729,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16731
https://github.com/root-project/root/pull/16731:57,reliability,fail,failures,57,Adjust stressGraphics_web.ref for fedora40; Should solve failures on fedora40 in #16729,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16731
https://github.com/root-project/root/issues/16733:284,availability,error,error,284,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:469,availability,Error,Error,469,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:545,availability,Error,Error,545,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:589,availability,Error,Error,589,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1170,availability,Operat,Operating,1170,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:5,deployability,fail,fails,5,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:14,deployability,build,build,14,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:65,deployability,build,building,65,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:181,deployability,version,versions,181,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:260,deployability,fail,fail,260,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:622,deployability,fail,failed,622,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:655,deployability,version,version,655,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:684,deployability,fail,failing,684,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1020,deployability,build,build,1020,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1030,deployability,build,build,1030,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1089,deployability,version,version,1089,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1126,deployability,Instal,Installation,1126,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1147,deployability,build,build,1147,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:181,integrability,version,versions,181,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:655,integrability,version,version,655,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1089,integrability,version,version,1089,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:181,modifiability,version,versions,181,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:655,modifiability,version,version,655,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1089,modifiability,version,version,1089,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:77,performance,parallel,parallel,77,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:284,performance,error,error,284,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:469,performance,Error,Error,469,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:545,performance,Error,Error,545,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:589,performance,Error,Error,589,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:5,reliability,fail,fails,5,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:260,reliability,fail,fail,260,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:622,reliability,fail,failed,622,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:684,reliability,fail,failing,684,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:284,safety,error,error,284,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:469,safety,Error,Error,469,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:545,safety,Error,Error,545,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:589,safety,Error,Error,589,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:1210,testability,context,context,1210,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:284,usability,error,error,284,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:352,usability,Stop,Stop,352,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:469,usability,Error,Error,469,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:545,usability,Error,Error,545,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16733:589,usability,Error,Error,589,"ROOT fails to build many builtins with CMake 3.30 (>=3.28) (when building in parallel (-j N)); ### Check duplicate issues. - [X] Checked for duplicates. ### Description. With newer versions of cmake like 3.30.5 at least some of ExternalProject_Add'ed builtins fail to compile with an error like. ```. gmake[6]: *** read jobs pipe: Bad file descriptor. Stop. gmake[6]: *** Waiting for unfinished jobs.... gmake[5]: *** [CMakeFiles/Makefile2:97: CMakeFiles/pcre.dir/all] Error 2. gmake[4]: *** [CMakeFiles/Makefile2:104: CMakeFiles/pcre.dir/rule] Error 2. gmake[3]: *** [Makefile:179: pcre] Error 2. ```. (here builtin PCRE failed). I don't know with which version of cmake this starts failing, but we (SPI/LCG) moved from 3.26.2 to 3.30. Unless one limits oneself to a small number of `--jobs`? ### Reproducer. On lxplus or equivalent machines with CVMFS for example. ```. export PATH=/cvmfs/sft.cern.ch/lcg/contrib/CMake/3.30.5/Linux-x86_64/bin/:$PATH. git clone https://github.com/root-project/root.git. cd root. mkdir build. cd build. cmake -D builtin_pcre=ON .. make -j8. ```. ### ROOT version. any? (definitely HEAD). ### Installation method. build from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16733
https://github.com/root-project/root/issues/16736:1336,availability,Operat,Operating,1336,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:1278,deployability,version,version,1278,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:1299,deployability,Instal,Installation,1299,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:133,energy efficiency,Current,Currently,133,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:1255,energy efficiency,current,current,1255,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:1278,integrability,version,version,1278,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:1278,modifiability,version,version,1278,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:623,safety,avoid,avoid,623,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:1381,testability,context,context,1381,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:15,usability,document,documentation,15,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/issues/16736:1180,usability,behavi,behaviour,1180,"Please improve documentation and/or argument names for TH1::GetQuantiles(); ### Explain what you would like to see improved and how. Currently there is:. ```cpp. TH1::GetQuantiles(int nprobSum, double* q, const double* probSum);. ```. where `q` is the quantile, while `probSum` is the probability associated with the given quantile. In the description, however, we have:. ```. F(x_q) = q with 0 <= q <= 1. ```. where `x_q` is the quantile (i.e. argument `q` of `GetQuantiles`), while `q` is the probability (i.e. argument `probSum`). I propose to change the argument names to `int n`, `double* xq` and `const double* q` to avoid confusion and be in agreement with both the description in ROOT and e.g. Wikipedia. Next, in the description we have. ```. [in] probSum - array of positions where quantiles will be computed. ```. but this is confusing and, I think, wrong. It should rather be ""array of probabilities associated with calculated quantiles"". If the argument names were changed as I propose, then this text would not even be necessary, because the thing would be obvious from the equation above. The only thing about the arguments needing description would be `n` and the behaviour in case of `q == nullptr` (note that I mean the new `q`, not the current one). ### ROOT version. master. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16736
https://github.com/root-project/root/pull/16737:20,energy efficiency,alloc,allocation,20,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:56,energy efficiency,Alloc,Allocate,56,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:13,performance,memor,memory,13,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:183,safety,test,tests,183,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:271,safety,test,tests,271,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:178,testability,unit,unit,178,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:183,testability,test,tests,183,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:266,testability,unit,unit,266,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:271,testability,test,tests,271,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16737:13,usability,memor,memory,13,"[ntuple] fix memory allocation in unique pointer field; Allocate unique pointer pointees with `new`, so that it matches the default deleter. This appears actually already in our unit tests when ran under valgrind. In general, it would be useful to regularly run the unit tests under valgrind. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16737
https://github.com/root-project/root/pull/16738:53,availability,consist,consistently,53,"[ntuple] replace malloc() by new where possible; Use consistently new/delete instead of malloc/free. Except for the RVec handling, because RVec itself uses malloc/free.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16738
https://github.com/root-project/root/pull/16738:101,safety,Except,Except,101,"[ntuple] replace malloc() by new where possible; Use consistently new/delete instead of malloc/free. Except for the RVec handling, because RVec itself uses malloc/free.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16738
https://github.com/root-project/root/pull/16738:53,usability,consist,consistently,53,"[ntuple] replace malloc() by new where possible; Use consistently new/delete instead of malloc/free. Except for the RVec handling, because RVec itself uses malloc/free.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16738
https://github.com/root-project/root/issues/16739:38,integrability,batch,batches,38,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:264,integrability,batch,batches,264,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:536,integrability,Batch,BatchProcess,536,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:698,integrability,batch,batchSize,698,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:202,interoperability,format,format,202,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:38,performance,batch,batches,38,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:264,performance,batch,batches,264,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:536,performance,Batch,BatchProcess,536,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:698,performance,batch,batchSize,698,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:549,safety,input,inputCols,549,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:820,testability,context,context,820,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:300,usability,support,supported,300,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16739:549,usability,input,inputCols,549,"Feed back numpy data to RDF graph, in batches; ### Feature description. As discussed during CHEP24, it would be very useful to have the option. to not only extract data from RDF graph in numpy/torch/tf format but. also to be able to feed back into RDF the data in batches (e.g. for NN. inference not supported in SOPHIE). When exporting/importing it would be useful to have the option to. explode/flatten vecops of same length. Pseudo code example:. ```. def processBatch(nparray). #do something with pyTorch. ... return outTensor. rdf.BatchProcess(inputCols={""Jet_pt"",""Jet_eta"",""Jet_mass"",""MET_pt""},. outputVectorCols={""Jet_regressedPt"", ""Jet_regressedMass""},. outputScalarCols={}, processBatch,. batchSize=100000,flattenRVec=True,broadCastScalars=True). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16739
https://github.com/root-project/root/issues/16740:292,availability,error,error,292,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:204,integrability,event,events,204,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:246,integrability,sub,subevents,246,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:717,integrability,event,events,717,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:754,integrability,event,events,754,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:822,modifiability,maintain,maintaining,822,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:292,performance,error,error,292,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:339,performance,memor,memory,339,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:292,safety,error,error,292,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:589,safety,input,inputdataset,589,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:822,safety,maintain,maintaining,822,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:838,safety,input,input,838,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:911,testability,context,context,911,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:0,usability,Support,Support,0,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:292,usability,error,error,292,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:339,usability,memor,memory,339,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:347,usability,efficien,efficient,347,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:563,usability,progress,progressive,563,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:589,usability,input,inputdataset,589,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16740:838,usability,input,input,838,"Support for histogram filling in oversampled dataset; ### Feature description. As discussed in CHEP24 for CMS FlashSim samples produced with. oversampling a dedicated histo filling scheme is needed where events. are first accumulated on same-gen subevents then used to fill a TH. with proper error handling. In order to achieve this in a (memory) efficient way the following. features would be needed:. - know the number of threads actively used and/or which threads will. not be used at all or any longer in the processing. - define a global_rdfentry_ that is a progressive number on the inputdataset. - know what global_rdfentry_ a given thread is processing. An additional useful feature, for handling oversampled events is the. option to have output events in Snapshots sorted according to the. global_rdfentry_ (i.e. maintaining the input order). ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16740
https://github.com/root-project/root/issues/16741:205,availability,avail,available,205,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:327,availability,slo,slowRegression,327,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:157,modifiability,variab,variables,157,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:182,modifiability,variab,variables,182,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:8,performance,cach,caching,8,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:109,performance,Cach,Caching,109,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:127,performance,Cach,Cache,127,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:361,performance,Cach,Cache,361,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:205,reliability,availab,available,205,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:327,reliability,slo,slowRegression,327,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:205,safety,avail,available,205,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:205,security,availab,available,205,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:574,testability,context,context,574,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/issues/16741:101,usability,support,support,101,"Partial caching in RDF graph; ### Feature description. As discussed in CHEP24, it would be useful to support Caching (e.g. RDF.Cache) of a limited number of variables with the other variables. being still available in a lazy way. Example usage. ```. #suppose rdf has columns Jet_pt, Jet_eta. rdf=rdf.Define(""Jet_regressedPt"", ""slowRegression(Jet_pt)""). rdf=rdf.Cache([""Jet_regressedPt""]). rdf=rdf.Define(""Jet_discriminator"",""computeDiscriminator(Jet_regressedPt,. Jet_eta""). rdf=rdf.TH1F(""Jet_discriminator""). ```. ### Alternatives considered. _No response_. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16741
https://github.com/root-project/root/pull/16742:15,availability,failur,failures,15,[CI] S3 upload failures should not cancel the build; Try splitting the build and the S3 upload step. These might not need to be intertwined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16742
https://github.com/root-project/root/pull/16742:15,deployability,fail,failures,15,[CI] S3 upload failures should not cancel the build; Try splitting the build and the S3 upload step. These might not need to be intertwined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16742
https://github.com/root-project/root/pull/16742:46,deployability,build,build,46,[CI] S3 upload failures should not cancel the build; Try splitting the build and the S3 upload step. These might not need to be intertwined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16742
https://github.com/root-project/root/pull/16742:71,deployability,build,build,71,[CI] S3 upload failures should not cancel the build; Try splitting the build and the S3 upload step. These might not need to be intertwined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16742
https://github.com/root-project/root/pull/16742:15,performance,failur,failures,15,[CI] S3 upload failures should not cancel the build; Try splitting the build and the S3 upload step. These might not need to be intertwined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16742
https://github.com/root-project/root/pull/16742:15,reliability,fail,failures,15,[CI] S3 upload failures should not cancel the build; Try splitting the build and the S3 upload step. These might not need to be intertwined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16742
https://github.com/root-project/root/pull/16742:35,usability,cancel,cancel,35,[CI] S3 upload failures should not cancel the build; Try splitting the build and the S3 upload step. These might not need to be intertwined.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16742
https://github.com/root-project/root/pull/16743:191,deployability,version,version,191,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:253,deployability,build,building,253,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:191,integrability,version,version,191,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:56,modifiability,pac,packages,56,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:191,modifiability,version,version,191,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:90,safety,test,tests,90,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:287,safety,Test,Tested,287,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:85,testability,unit,unit,85,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:90,testability,test,tests,90,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:287,testability,Test,Tested,287,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16743:116,usability,support,support,116,Make `requirements.txt` resolvable in Python 3.13; Some packages that we use in some unit tests and tutorials don't support Python 3.13 yet. They should be listed conditionally on the Python version to make the environment resolve. This is required for building the Fedora 41 CI images. Tested with Python 3.13 on Arch Linux.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16743
https://github.com/root-project/root/pull/16744:140,deployability,build,building,140,[cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16744
https://github.com/root-project/root/pull/16744:52,modifiability,variab,variable,52,[cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16744
https://github.com/root-project/root/pull/16744:206,modifiability,variab,variable,206,[cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16744
https://github.com/root-project/root/pull/16744:153,safety,test,tests,153,[cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16744
https://github.com/root-project/root/pull/16744:153,testability,test,tests,153,[cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16744
https://github.com/root-project/root/pull/16744:194,usability,help,help,194,[cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16744
https://github.com/root-project/root/pull/16745:212,deployability,updat,updated,212,[skip-ci][NFC][ntuple] document default RNTupleWriteOptions; # This Pull request:. document the default values in `RNTupleWriteOptions` next to the `Limits` section for reader's convenience. ## Checklist:. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16745
https://github.com/root-project/root/pull/16745:212,safety,updat,updated,212,[skip-ci][NFC][ntuple] document default RNTupleWriteOptions; # This Pull request:. document the default values in `RNTupleWriteOptions` next to the `Limits` section for reader's convenience. ## Checklist:. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16745
https://github.com/root-project/root/pull/16745:212,security,updat,updated,212,[skip-ci][NFC][ntuple] document default RNTupleWriteOptions; # This Pull request:. document the default values in `RNTupleWriteOptions` next to the `Limits` section for reader's convenience. ## Checklist:. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16745
https://github.com/root-project/root/pull/16745:23,usability,document,document,23,[skip-ci][NFC][ntuple] document default RNTupleWriteOptions; # This Pull request:. document the default values in `RNTupleWriteOptions` next to the `Limits` section for reader's convenience. ## Checklist:. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16745
https://github.com/root-project/root/pull/16745:83,usability,document,document,83,[skip-ci][NFC][ntuple] document default RNTupleWriteOptions; # This Pull request:. document the default values in `RNTupleWriteOptions` next to the `Limits` section for reader's convenience. ## Checklist:. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16745
https://github.com/root-project/root/pull/16747:217,integrability,pub,public,217,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:224,integrability,interfac,interface,224,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:241,integrability,wrap,wraps,241,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:224,interoperability,interfac,interface,224,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:224,modifiability,interfac,interface,224,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:450,reliability,Poisson,Poisson,450,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:76,safety,avoid,avoid,76,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:7,usability,Support,Support,7,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16747:158,usability,user,user,158,"[math] Support AD for `TMath::LnGamma` using functions from GSL; This is to avoid any num-diff fallback in RooFit, which results in annoying warnings for the user. A new function `ROOT::Math::digamma` is added to the public interface, which wraps `gsl_sf_psi`. The digamma function is the derivative of `lgamma`, so it is used in `CladDerivator.h` to define the derivatives of `TMath::LnGamma` and the related gamma functions that are used to define Poisson cdfs.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16747
https://github.com/root-project/root/pull/16749:70,deployability,configurat,configuration,70,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:132,deployability,version,versions,132,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:70,integrability,configur,configuration,70,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:132,integrability,version,versions,132,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:267,interoperability,platform,platforms,267,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:70,modifiability,configur,configuration,70,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:132,modifiability,version,versions,132,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:250,safety,test,tested,250,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:70,security,configur,configuration,70,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16749:250,testability,test,tested,250,"[civetweb] Don't include `<openssl/engine.h>`; We don't use it in our configuration of civetweb, and it will be removed in upcoming versions of Fedora and RHEL:. https://github.com/dotnet/runtime/issues/104775#issuecomment-2229857943. This change is tested by all CI platforms, because globally we set `http=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16749
https://github.com/root-project/root/pull/16750:1250,availability,robust,robust,1250,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1362,availability,state,state,1362,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1191,deployability,manag,management,1191,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1292,deployability,integr,integrate,1292,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1727,deployability,observ,observable,1727,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1191,energy efficiency,manag,management,1191,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1315,energy efficiency,profil,profiling,1315,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:511,integrability,filter,filter,511,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:705,integrability,filter,filtering,705,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:989,integrability,filter,filtering,989,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1292,integrability,integr,integrate,1292,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1362,integrability,state,state,1362,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1372,integrability,filter,filtering,1372,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1292,interoperability,integr,integrate,1292,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:44,modifiability,paramet,parameter,44,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:145,modifiability,paramet,parameters,145,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:304,modifiability,paramet,parameters,304,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:490,modifiability,paramet,parameters,490,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:766,modifiability,paramet,parameters,766,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:847,modifiability,paramet,parameters,847,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1002,modifiability,paramet,parameters,1002,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1068,modifiability,paramet,parameters,1068,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1181,modifiability,paramet,parameter,1181,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1292,modifiability,integr,integrate,1292,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1398,modifiability,paramet,parameters,1398,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1602,modifiability,paramet,parameters,1602,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1680,modifiability,paramet,parameter,1680,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:190,performance,overhead,overhead,190,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:340,performance,time,time,340,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:416,performance,overhead,overhead,416,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1315,performance,profil,profiling,1315,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1522,performance,perform,performance,1522,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1632,performance,time,times,1632,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1250,reliability,robust,robust,1250,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1292,reliability,integr,integrate,1292,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1105,safety,avoid,avoid,1105,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1191,safety,manag,management,1191,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1206,safety,compl,completely,1206,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1250,safety,robust,robust,1250,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1434,safety,valid,validated,1434,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1206,security,compl,completely,1206,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1292,security,integr,integrate,1292,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1434,security,validat,validated,1434,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:449,testability,simpl,simply,449,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1292,testability,integr,integrate,1292,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1534,testability,regress,regression,1534,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1727,testability,observ,observable,1727,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:5,usability,Support,Support,5,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:108,usability,user,users,108,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:449,usability,simpl,simply,449,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1273,usability,help,help,1273,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1385,usability,minim,minimization,1385,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16750:1522,usability,perform,performance,1522,"[RF] Support changing constant vs. floating parameter flag for fits with gradients from codegen AD; For our users, it's important to fix certain parameters in the likelihood easily with any overhead. So far, this didn't work when using gradients from AD, because the gradients were only produced for the parameters that are floating at the time where the likelihood is created. However, it has no additional runtime overhead in backwards AD mode to simply generate the gradient for **all** parameters, and then filter out the right elements in the the RooMinimizer-related code. This is what is implemented in the second commit of this PR. Some changes in the RooAbsMinimizerFcn were necessary to do this filtering: so far it didn't store any information on all the parameters in order. It only stored two separate lists for floating and constant parameters. The first commit in this PR adds the necessary data members (`_allParams` and `_allParamsInit`) to the RooAbsMinimizerFcn for the filtering of parameters. Furthermore, the previous datamembers that stored the parameters separately are removed to avoid duplication and possible desync of information. On this occasion, the parameter management was completely rewritten to be more concise and robust. This will also help later when we integrate the discrete profiling from CMS combine, where changing the state and filtering of minimization parameters is also relevant. It was validated with the ATLAS and CMS likelihoods from ICHEP 2024 that this PR results in no performance regression, even though we are now generating the gradient for more parameters (roughly up to two times more, because for every floating nuisance parameter there is usually one constant global observable that constrains it).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16750
https://github.com/root-project/root/pull/16751:163,deployability,build,build,163,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:270,deployability,updat,updated,270,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:127,integrability,compon,components,127,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:169,integrability,compon,components,169,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:205,integrability,compon,components,205,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:127,interoperability,compon,components,127,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:169,interoperability,compon,components,169,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:205,interoperability,compon,components,205,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:127,modifiability,compon,components,127,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:169,modifiability,compon,components,169,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:205,modifiability,compon,components,205,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:240,safety,test,tested,240,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:270,safety,updat,updated,270,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:270,security,updat,updated,270,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:240,testability,test,tested,240,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/pull/16751:106,usability,minim,minimum,106,"Superbuilds; # This Pull request:. ## Changes or fixes:. This PR allows ROOT is possible to be built as a minimum set of basic components. Also, it is possible to build components using already built ROOT components. ## Checklist:. - [ X ] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16751
https://github.com/root-project/root/issues/16752:527,deployability,depend,depending,527,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:88,energy efficiency,current,currently,88,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:98,energy efficiency,alloc,allocates,98,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:483,energy efficiency,alloc,allocation,483,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:122,integrability,buffer,buffer,122,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:366,integrability,buffer,buffer,366,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:527,integrability,depend,depending,527,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:527,modifiability,depend,depending,527,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:432,performance,content,contents,432,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:520,performance,memor,memory,520,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:527,safety,depend,depending,527,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:507,security,sign,significant,507,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:527,testability,depend,depending,527,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16752:520,usability,memor,memory,520,"[ntuple] Copy sealed page in RPageSinkBuf after compression; `RPageSinkBuf::CommitPage` currently allocates a sealed page buffer with the same size as the uncompressed page:. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L148. Instead the code should seal / compress the page into a temporary buffer, at which point the exact compressed size is known and the contents can be copied into an appropriately sized allocation. This saves (significant) memory depending on the compression factor, while the extra `memcpy` should not be visible compared to the compression itself.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16752
https://github.com/root-project/root/issues/16753:345,deployability,releas,released,345,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:516,deployability,releas,released,516,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:78,energy efficiency,schedul,scheduler,78,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:604,energy efficiency,alloc,allocator,604,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:32,integrability,buffer,buffers,32,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:280,integrability,asynchron,asynchronous,280,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:502,integrability,buffer,buffer,502,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:78,performance,schedul,scheduler,78,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:280,performance,asynch,asynchronous,280,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:403,performance,memor,memory,403,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:410,performance,overhead,overhead,410,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:627,safety,safe,safe,627,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:391,security,sign,significant,391,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16753:403,usability,memor,memory,403,"[ntuple] Free uncompressed page buffers in RPageSinkBuf with IMT; With a task scheduler, `RPageSinkBuf::CommitPage` copies the uncompressed page. https://github.com/root-project/root/blob/226e4c00e5dc4b7aaf881bad810a0c78c8a14185/tree/ntuple/v7/src/RPageSinkBuf.cxx#L167-L170. for asynchronous compression. However, the uncompressed page is only released in `FlushClusterImpl` which leads to significant memory overhead for high compression factors (such as CMS miniAOD). In principle, the uncompressed buffer can be released directly after compression, which is only a bit tricky because it requires the allocator to be thread-safe.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16753
https://github.com/root-project/root/issues/16754:48,deployability,contain,containers,48,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1145,deployability,contain,containers,1145,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:90,energy efficiency,current,currently,90,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:155,energy efficiency,alloc,allocator,155,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:307,energy efficiency,model,model,307,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:364,energy efficiency,model,model,364,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:433,energy efficiency,alloc,allocator,433,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:646,energy efficiency,alloc,allocator,646,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:850,energy efficiency,core,core,850,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:968,energy efficiency,Alloc,Allocator,968,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1411,energy efficiency,model,model,1411,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1468,energy efficiency,model,model,1468,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1720,energy efficiency,alloc,allocator,1720,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1922,energy efficiency,core,core,1922,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1343,integrability,pub,public,1343,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:30,modifiability,paramet,parameters,30,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1200,modifiability,paramet,parameters,1200,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:307,security,model,model,307,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:364,security,model,model,364,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1225,security,Hash,Hash,1225,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1355,security,hash,hash,1355,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1411,security,model,model,1411,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1468,security,model,model,1468,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:9,usability,Support,Support,9,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:672,usability,support,supported,672,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/issues/16754:1744,usability,support,supported,1744,"[ntuple] Support all template parameters of STL containers; As pointed out by ATLAS, it's currently not possible to use a `std::vector` with a non-default allocator in RNTuple:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <scoped_allocator>. #include <vector>. void ntuple_vector_allocator() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::vector<int, std::scoped_allocator_adaptor<std::allocator<int>>>>(""v"");. }. ```. leads to. ```. Processing ntuple_vector_allocator.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): vector<int,scoped_allocator_adaptor<allocator<int> > > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```. This is because `RField` is only partially specialized for `std::vector<ItemT>`, so a non-default `Allocator` falls back to the default `RField` declaration (which assumes it's a class and checks that it's not in `std` namespace). Note that in principle, this affects all STL containers. For many of them, there are other template parameters, for example `Hash` for `std::unordered_set`:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <unordered_set>. struct IntHash : public std::hash<int> {};. void ntuple_unordered_set_hash() {. auto model = ROOT::Experimental::RNTupleModel::CreateBare();. model->MakeField<std::unordered_set<int, IntHash>>(""s"");. }. ```. leads to. ```. Processing ntuple_unordered_set_hash.C... terminate called after throwing an instance of 'ROOT::Experimental::RException'. what(): unordered_set<int,IntHash,equal_to<int>,allocator<int> > is not supported. At:. ROOT::Experimental::RClassField::RClassField(std::string_view, std::string_view, TClass *) [/home/jhahnfel/ROOT/src/tree/ntuple/v7/src/RField.cxx:1807]. Aborted (core dumped). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16754
https://github.com/root-project/root/pull/16755:147,deployability,build,building,147,[v6.32][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16755
https://github.com/root-project/root/pull/16755:59,modifiability,variab,variable,59,[v6.32][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16755
https://github.com/root-project/root/pull/16755:213,modifiability,variab,variable,213,[v6.32][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16755
https://github.com/root-project/root/pull/16755:160,safety,test,tests,160,[v6.32][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16755
https://github.com/root-project/root/pull/16755:160,testability,test,tests,160,[v6.32][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16755
https://github.com/root-project/root/pull/16755:201,usability,help,help,201,[v6.32][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16755
https://github.com/root-project/root/pull/16756:147,deployability,build,building,147,[v6-30][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16756
https://github.com/root-project/root/pull/16756:59,modifiability,variab,variable,59,[v6-30][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16756
https://github.com/root-project/root/pull/16756:213,modifiability,variab,variable,213,[v6-30][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16756
https://github.com/root-project/root/pull/16756:160,safety,test,tests,160,[v6-30][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16756
https://github.com/root-project/root/pull/16756:160,testability,test,tests,160,[v6-30][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16756
https://github.com/root-project/root/pull/16756:201,usability,help,help,201,[v6-30][cmake][win] Set the CMAKE_SKIP_TEST_ALL_DEPENDENCY variable; This should partially solve the issue with the rebuild (linking) of ROOT when building the tests. See also: https://cmake.org/cmake/help/latest/variable/CMAKE_SKIP_TEST_ALL_DEPENDENCY.html. Requires CMake v3.29.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16756
https://github.com/root-project/root/issues/16757:515,energy efficiency,model,model,515,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:608,energy efficiency,model,model,608,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:661,energy efficiency,model,model,661,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:917,energy efficiency,model,model,917,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:1116,energy efficiency,Load,LoadEntry,1116,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:1258,energy efficiency,optim,optimizing,1258,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:456,performance,Cach,CacheLine,456,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:595,performance,Cach,CacheLine,595,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:1116,performance,Load,LoadEntry,1116,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:1258,performance,optimiz,optimizing,1258,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:1232,safety,prevent,prevent,1232,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:515,security,model,model,515,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:608,security,model,model,608,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:661,security,model,model,661,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:917,security,model,model,917,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/issues/16757:1232,security,preven,prevent,1232,"[ntuple] Handling of over-aligned types; ### Description. In some type-punned fields, we make assumptions that the alignment is smaller than `alignof(std::max_align_t)`. ### Reproducer. This breaks in certain combinations of types, for example a `std::vector` of an over-aligned type:. ```c++. #include <ROOT/RNTupleModel.hxx>. #include <ROOT/RNTupleReader.hxx>. #include <ROOT/RNTupleWriter.hxx>. #include <sstream>. #include <vector>. struct alignas(64) CacheLine {. int i = 0;. };. void ntuple_aligned() {. auto model = ROOT::Experimental::RNTupleModel::Create();. using Vector = std::vector<CacheLine>;. model->MakeField<Vector>(""v"");. {. auto writeModel = model->Clone();. auto vPtr = writeModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto writer = ROOT::Experimental::RNTupleWriter::Recreate(std::move(writeModel), ""ntuple"", ""ntuple_aligned.root"");. vPtr->push_back({});. writer->Fill();. }. auto readModel = model->Clone();. auto vPtr = readModel->GetDefaultEntry().GetPtr<Vector>(""v"");. auto reader = ROOT::Experimental::RNTupleReader::Open(std::move(readModel), ""ntuple"", ""ntuple_aligned.root"");. reader->LoadEntry(0);. auto ptr = &vPtr->at(0);. auto uptr = reinterpret_cast<std::uintptr_t>(ptr);. // Do a small dance to prevent the compiler from optimizing the alignment check... std::stringstream ss;. ss << uptr;. ss >> uptr;. std::cout << ptr << "" ("" << uptr << "") % 64 = "" << (uptr % 64) << std::endl;. }. ```. possible output:. ```. 0x48c9230 (76321328) % 64 = 48. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16757
https://github.com/root-project/root/pull/16758:198,safety,test,tested,198,[doxygen] Let run tutorials with ACLiC when generating doxygen [skip-ci]; Required for tutorials like `triangle.cxx` where dictionary must be generated for the class. `skip-ci` while doxygen is not tested by CI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16758
https://github.com/root-project/root/pull/16758:198,testability,test,tested,198,[doxygen] Let run tutorials with ACLiC when generating doxygen [skip-ci]; Required for tutorials like `triangle.cxx` where dictionary must be generated for the class. `skip-ci` while doxygen is not tested by CI.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16758
https://github.com/root-project/root/pull/16759:204,availability,state,state,204,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16759:27,deployability,build,build,27,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16759:179,integrability,configur,configured,179,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16759:204,integrability,state,state,204,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16759:179,modifiability,configur,configured,179,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16759:313,modifiability,variab,variables,313,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16759:240,reliability,doe,doesn,240,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16759:179,security,configur,configured,179,"[CMake] Remove the 'cudnn' build option in favour of 'tmva-cudnn' and modernise cmake.; - Replace the duo of `cudnn` and `tmva-cudnn` by just `tmva-cudnn`. Otherwise, ROOT can be configured to an invalid state where everything compiles but doesn't link. - Modernise the CMake code that links to cuDNN, going from variables to an imported target. Fix #16715.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16759
https://github.com/root-project/root/pull/16760:110,deployability,contain,containing,110,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:160,deployability,fail,failing,160,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:257,deployability,contain,containing,257,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:409,deployability,updat,updated,409,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:92,energy efficiency,load,loading,92,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:245,energy efficiency,load,load,245,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:324,energy efficiency,model,model,324,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:92,performance,load,loading,92,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:245,performance,load,load,245,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:160,reliability,fail,failing,160,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:211,safety,except,exception,211,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:379,safety,test,tested,379,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:409,safety,updat,updated,409,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:324,security,model,model,324,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:409,security,updat,updated,409,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16760:379,testability,test,tested,379,"[ntuple] allow reading a RNTuple with an unknown locator type; # This Pull request:. allows loading a RNTuple containing locators of unknown types. Rather than failing upon reading the RNTuple, we will throw an exception only when attempting to load a page containing an unknown locator type. This allows reconstructing the model and reading the descriptor. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16760
https://github.com/root-project/root/pull/16761:63,availability,operat,operators,63,[tmva][sofie] Update documentation with list of supported ONNX operators; Remove also a duplication in registering operator in RModelParser_ONNX.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16761
https://github.com/root-project/root/pull/16761:115,availability,operat,operator,115,[tmva][sofie] Update documentation with list of supported ONNX operators; Remove also a duplication in registering operator in RModelParser_ONNX.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16761
https://github.com/root-project/root/pull/16761:14,deployability,Updat,Update,14,[tmva][sofie] Update documentation with list of supported ONNX operators; Remove also a duplication in registering operator in RModelParser_ONNX.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16761
https://github.com/root-project/root/pull/16761:14,safety,Updat,Update,14,[tmva][sofie] Update documentation with list of supported ONNX operators; Remove also a duplication in registering operator in RModelParser_ONNX.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16761
https://github.com/root-project/root/pull/16761:14,security,Updat,Update,14,[tmva][sofie] Update documentation with list of supported ONNX operators; Remove also a duplication in registering operator in RModelParser_ONNX.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16761
https://github.com/root-project/root/pull/16761:21,usability,document,documentation,21,[tmva][sofie] Update documentation with list of supported ONNX operators; Remove also a duplication in registering operator in RModelParser_ONNX.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16761
https://github.com/root-project/root/pull/16761:48,usability,support,supported,48,[tmva][sofie] Update documentation with list of supported ONNX operators; Remove also a duplication in registering operator in RModelParser_ONNX.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16761
https://github.com/root-project/root/pull/16762:15,deployability,Updat,Update,15,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:105,deployability,upgrad,upgraded,105,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:243,deployability,updat,updated,243,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:105,modifiability,upgrad,upgraded,105,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:15,safety,Updat,Update,15,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:213,safety,test,tested,213,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:243,safety,updat,updated,243,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:15,security,Updat,Update,15,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:243,security,updat,updated,243,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16762:213,testability,test,tested,213,[DO NOT MERGE] Update to LLVM18.1.8; # This Pull request:. Checks if there are any breaking changes when upgraded to LLVM18.1.8. Conda can only use LLVM18.1.8 as a base. ## Changes or fixes:. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16762
https://github.com/root-project/root/pull/16763:30,safety,test,tests,30,[cmake] Re-add python stl_set tests; This PR adds a test for #14710 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16763
https://github.com/root-project/root/pull/16763:52,safety,test,test,52,[cmake] Re-add python stl_set tests; This PR adds a test for #14710 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16763
https://github.com/root-project/root/pull/16763:30,testability,test,tests,30,[cmake] Re-add python stl_set tests; This PR adds a test for #14710 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16763
https://github.com/root-project/root/pull/16763:52,testability,test,test,52,[cmake] Re-add python stl_set tests; This PR adds a test for #14710 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16763
https://github.com/root-project/root/pull/16764:348,deployability,contain,container,348,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:503,deployability,log,logic,503,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:51,integrability,sub,subclasses,51,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:131,integrability,sub,subfields,131,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:234,safety,Avoid,Avoid,234,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:503,safety,log,logic,503,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:389,security,sign,signal,389,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:503,security,log,logic,503,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:503,testability,log,logic,503,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16764:115,usability,user,user,115,"[ntuple] Fixes and cleanups for `RRecordField` and subclasses; * Remove dangerous `RField` constructors, where the user could pass subfields into typed `RField<std::pair<T1, T2>>` and `RField<std::tuple<ItemTs...>>` without checks. * Avoid UB in `RRecordField` construction, related to unspecified order of evaluation of function arguments. * Take container of `unique_ptr`'s by value, to signal ownership handover. * Fix `fSize` calculation in `RRecordField::AttachItemFields`, to have less (critical) logic in the typed `RField` constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16764
https://github.com/root-project/root/pull/16766:15,safety,Test,Test,15,[DO NOT MERGE] Test the test for #11707; This PR fixes #11707 by providing a test in roottest (sister PR https://github.com/root-project/roottest/pull/1210).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16766
https://github.com/root-project/root/pull/16766:24,safety,test,test,24,[DO NOT MERGE] Test the test for #11707; This PR fixes #11707 by providing a test in roottest (sister PR https://github.com/root-project/roottest/pull/1210).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16766
https://github.com/root-project/root/pull/16766:77,safety,test,test,77,[DO NOT MERGE] Test the test for #11707; This PR fixes #11707 by providing a test in roottest (sister PR https://github.com/root-project/roottest/pull/1210).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16766
https://github.com/root-project/root/pull/16766:15,testability,Test,Test,15,[DO NOT MERGE] Test the test for #11707; This PR fixes #11707 by providing a test in roottest (sister PR https://github.com/root-project/roottest/pull/1210).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16766
https://github.com/root-project/root/pull/16766:24,testability,test,test,24,[DO NOT MERGE] Test the test for #11707; This PR fixes #11707 by providing a test in roottest (sister PR https://github.com/root-project/roottest/pull/1210).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16766
https://github.com/root-project/root/pull/16766:77,testability,test,test,77,[DO NOT MERGE] Test the test for #11707; This PR fixes #11707 by providing a test in roottest (sister PR https://github.com/root-project/roottest/pull/1210).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16766
https://github.com/root-project/root/issues/16767:1010,availability,Operat,Operating,1010,"Unordered container as first tuple member confuses Meta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. With `std::tuple<std::unordered*`, there are missing data members. ### Reproducer. ```. root [0] TClass::GetClass(""std::tuple<int, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [1] TClass::GetClass(""std::tuple<std::set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [2] TClass::GetClass(""std::tuple<std::unordered_set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=1. OBJ: TDataMember _0. ```. Same with `std::unordered_map<int, int>`, while `std::set<int>` and `std::map<int, int>` seem to be fine. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16767
https://github.com/root-project/root/issues/16767:10,deployability,contain,container,10,"Unordered container as first tuple member confuses Meta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. With `std::tuple<std::unordered*`, there are missing data members. ### Reproducer. ```. root [0] TClass::GetClass(""std::tuple<int, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [1] TClass::GetClass(""std::tuple<std::set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [2] TClass::GetClass(""std::tuple<std::unordered_set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=1. OBJ: TDataMember _0. ```. Same with `std::unordered_map<int, int>`, while `std::set<int>` and `std::map<int, int>` seem to be fine. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16767
https://github.com/root-project/root/issues/16767:949,deployability,version,version,949,"Unordered container as first tuple member confuses Meta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. With `std::tuple<std::unordered*`, there are missing data members. ### Reproducer. ```. root [0] TClass::GetClass(""std::tuple<int, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [1] TClass::GetClass(""std::tuple<std::set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [2] TClass::GetClass(""std::tuple<std::unordered_set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=1. OBJ: TDataMember _0. ```. Same with `std::unordered_map<int, int>`, while `std::set<int>` and `std::map<int, int>` seem to be fine. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16767
https://github.com/root-project/root/issues/16767:972,deployability,Instal,Installation,972,"Unordered container as first tuple member confuses Meta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. With `std::tuple<std::unordered*`, there are missing data members. ### Reproducer. ```. root [0] TClass::GetClass(""std::tuple<int, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [1] TClass::GetClass(""std::tuple<std::set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [2] TClass::GetClass(""std::tuple<std::unordered_set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=1. OBJ: TDataMember _0. ```. Same with `std::unordered_map<int, int>`, while `std::set<int>` and `std::map<int, int>` seem to be fine. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16767
https://github.com/root-project/root/issues/16767:949,integrability,version,version,949,"Unordered container as first tuple member confuses Meta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. With `std::tuple<std::unordered*`, there are missing data members. ### Reproducer. ```. root [0] TClass::GetClass(""std::tuple<int, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [1] TClass::GetClass(""std::tuple<std::set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [2] TClass::GetClass(""std::tuple<std::unordered_set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=1. OBJ: TDataMember _0. ```. Same with `std::unordered_map<int, int>`, while `std::set<int>` and `std::map<int, int>` seem to be fine. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16767
https://github.com/root-project/root/issues/16767:949,modifiability,version,version,949,"Unordered container as first tuple member confuses Meta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. With `std::tuple<std::unordered*`, there are missing data members. ### Reproducer. ```. root [0] TClass::GetClass(""std::tuple<int, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [1] TClass::GetClass(""std::tuple<std::set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [2] TClass::GetClass(""std::tuple<std::unordered_set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=1. OBJ: TDataMember _0. ```. Same with `std::unordered_map<int, int>`, while `std::set<int>` and `std::map<int, int>` seem to be fine. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16767
https://github.com/root-project/root/issues/16767:1050,testability,context,context,1050,"Unordered container as first tuple member confuses Meta; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. With `std::tuple<std::unordered*`, there are missing data members. ### Reproducer. ```. root [0] TClass::GetClass(""std::tuple<int, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [1] TClass::GetClass(""std::tuple<std::set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=2. OBJ: TDataMember _1. OBJ: TDataMember _0. root [2] TClass::GetClass(""std::tuple<std::unordered_set<int>, int>"")->GetListOfDataMembers()->Print(). Collection name='TListOfDataMembers', class='TListOfDataMembers', size=1. OBJ: TDataMember _0. ```. Same with `std::unordered_map<int, int>`, while `std::set<int>` and `std::map<int, int>` seem to be fine. ### ROOT version. `master`. ### Installation method. from source. ### Operating system. Linux. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16767
https://github.com/root-project/root/pull/16768:216,integrability,sub,sub,216,"[ntuple] Remove RFieldBase::GetNElements(); There is not a well-defined good way to determine the number of things in a field without any further input. This has been used by the views, to iterate all the data of a (sub)field, independent of entry boundaries. This field range is now determined directly by the view from the descriptor. Fixes #16588",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16768
https://github.com/root-project/root/pull/16768:146,safety,input,input,146,"[ntuple] Remove RFieldBase::GetNElements(); There is not a well-defined good way to determine the number of things in a field without any further input. This has been used by the views, to iterate all the data of a (sub)field, independent of entry boundaries. This field range is now determined directly by the view from the descriptor. Fixes #16588",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16768
https://github.com/root-project/root/pull/16768:146,usability,input,input,146,"[ntuple] Remove RFieldBase::GetNElements(); There is not a well-defined good way to determine the number of things in a field without any further input. This has been used by the views, to iterate all the data of a (sub)field, independent of entry boundaries. This field range is now determined directly by the view from the descriptor. Fixes #16588",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16768
https://github.com/root-project/root/pull/16769:23,deployability,version,version,23,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:40,deployability,Depend,Depends,40,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:23,integrability,version,version,23,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:40,integrability,Depend,Depends,40,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:16,interoperability,format,format,16,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:23,modifiability,version,version,23,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:40,modifiability,Depend,Depends,40,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:40,safety,Depend,Depends,40,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16769:40,testability,Depend,Depends,40,[ntuple] Binary format version 1.0.0.0; Depends on #16645,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16769
https://github.com/root-project/root/pull/16770:74,reliability,doe,does,74,"[webgui] do not use Edge browser for headless by default; While Microsoft does not allow to use headless mode by default, . do not try to use it without explicit argument `--web=edge`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16770
https://github.com/root-project/root/issues/16771:144,availability,error,errors,144,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:40,deployability,fail,fails,40,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:191,deployability,stack,stack,191,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:691,deployability,contain,contained,691,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:144,performance,error,errors,144,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:40,reliability,fail,fails,40,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:144,safety,error,errors,144,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:197,testability,trace,trace,197,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/issues/16771:144,usability,error,errors,144,"copying a default constructed `TH2Poly` fails.; . See https://github.com/cms-sw/cmssw/pull/41932#issuecomment-2440492881. ```. // This produces errors. TH2Poly p1;. TH2Poly p2(p1);. ```. The stack trace is:. ```. * frame #0: 0x000000010515b3d4 libHist.so`TH2Poly::Copy(this=0x00000001000100a8, newobj=0x00000001000180a8) const at TH2Poly.cxx:235:49. frame #1: 0x000000010515add8 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:185:9. frame #2: 0x000000010515ae34 libHist.so`TH2Poly::TH2Poly(this=0x00000001000180a8, rhs=0x00000001000100a8) at TH2Poly.cxx:184:47. ```. with a missing `if not nullptr` at:. ```. 234 // need to use Clone to copy the contained bin list. -> 235 newth2p.fBins = dynamic_cast<TList *>(fBins->Clone());. ```. As a side note:. ```. // This works fine (initialized case). TH2Poly p1;. Double_t x[] = {0,0,1,1};. Double_t y[] = {0,1,1,0};. p1.AddBin(4, x, y);. TH2Poly p2(p1);. ```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16771
https://github.com/root-project/root/pull/16772:15,modifiability,refact,refactoring,15,"[RF] RooFit AD refactoring; 1. Avoid referencing RooFuncWrapper inside code generation context. 2. Take out RooFit code generation context outside of Detail namespace. 3. Get rid of the `Experimental::RooFuncWrapper` class and make the code generation and AD with Clad accessible with the `RooFit::Evaluator`. The goal is to have one entry point for the user to do any kind of evaluation of RooFit computation graphs. Point number 3 still has to be done, which is why this is a draft PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16772
https://github.com/root-project/root/pull/16772:15,performance,refactor,refactoring,15,"[RF] RooFit AD refactoring; 1. Avoid referencing RooFuncWrapper inside code generation context. 2. Take out RooFit code generation context outside of Detail namespace. 3. Get rid of the `Experimental::RooFuncWrapper` class and make the code generation and AD with Clad accessible with the `RooFit::Evaluator`. The goal is to have one entry point for the user to do any kind of evaluation of RooFit computation graphs. Point number 3 still has to be done, which is why this is a draft PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16772
https://github.com/root-project/root/pull/16772:31,safety,Avoid,Avoid,31,"[RF] RooFit AD refactoring; 1. Avoid referencing RooFuncWrapper inside code generation context. 2. Take out RooFit code generation context outside of Detail namespace. 3. Get rid of the `Experimental::RooFuncWrapper` class and make the code generation and AD with Clad accessible with the `RooFit::Evaluator`. The goal is to have one entry point for the user to do any kind of evaluation of RooFit computation graphs. Point number 3 still has to be done, which is why this is a draft PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16772
https://github.com/root-project/root/pull/16772:269,security,access,accessible,269,"[RF] RooFit AD refactoring; 1. Avoid referencing RooFuncWrapper inside code generation context. 2. Take out RooFit code generation context outside of Detail namespace. 3. Get rid of the `Experimental::RooFuncWrapper` class and make the code generation and AD with Clad accessible with the `RooFit::Evaluator`. The goal is to have one entry point for the user to do any kind of evaluation of RooFit computation graphs. Point number 3 still has to be done, which is why this is a draft PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16772
https://github.com/root-project/root/pull/16772:87,testability,context,context,87,"[RF] RooFit AD refactoring; 1. Avoid referencing RooFuncWrapper inside code generation context. 2. Take out RooFit code generation context outside of Detail namespace. 3. Get rid of the `Experimental::RooFuncWrapper` class and make the code generation and AD with Clad accessible with the `RooFit::Evaluator`. The goal is to have one entry point for the user to do any kind of evaluation of RooFit computation graphs. Point number 3 still has to be done, which is why this is a draft PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16772
https://github.com/root-project/root/pull/16772:131,testability,context,context,131,"[RF] RooFit AD refactoring; 1. Avoid referencing RooFuncWrapper inside code generation context. 2. Take out RooFit code generation context outside of Detail namespace. 3. Get rid of the `Experimental::RooFuncWrapper` class and make the code generation and AD with Clad accessible with the `RooFit::Evaluator`. The goal is to have one entry point for the user to do any kind of evaluation of RooFit computation graphs. Point number 3 still has to be done, which is why this is a draft PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16772
https://github.com/root-project/root/pull/16772:354,usability,user,user,354,"[RF] RooFit AD refactoring; 1. Avoid referencing RooFuncWrapper inside code generation context. 2. Take out RooFit code generation context outside of Detail namespace. 3. Get rid of the `Experimental::RooFuncWrapper` class and make the code generation and AD with Clad accessible with the `RooFit::Evaluator`. The goal is to have one entry point for the user to do any kind of evaluation of RooFit computation graphs. Point number 3 still has to be done, which is why this is a draft PR.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16772
https://github.com/root-project/root/pull/16773:7,safety,prevent,prevent,7,[hist] prevent nullptr access with copy from default constructor; Fixes https://github.com/root-project/root/issues/16771,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16773
https://github.com/root-project/root/pull/16773:7,security,preven,prevent,7,[hist] prevent nullptr access with copy from default constructor; Fixes https://github.com/root-project/root/issues/16771,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16773
https://github.com/root-project/root/pull/16773:23,security,access,access,23,[hist] prevent nullptr access with copy from default constructor; Fixes https://github.com/root-project/root/issues/16771,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16773
https://github.com/root-project/root/issues/16774:410,availability,error,error,410,"Missing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No respon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1149,availability,down,download,1149,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1920,availability,Operat,Operating,1920,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1057,deployability,build,build,1057,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1396,deployability,version,version,1396,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1875,deployability,Instal,Installation,1875,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1396,integrability,version,version,1396,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1396,modifiability,version,version,1396,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:410,performance,error,error,410,"Missing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No respon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:410,safety,error,error,410,"Missing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No respon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1551,security,Team,Team,1551,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1981,testability,context,context,1981,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:410,usability,error,error,410,"Missing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No respon",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/issues/16774:1737,usability,help,help,1737,"sing TMVA::Experimental::SOFIE::RModelParser_ONNX class in some 6.32/XX pre-compiled binaries; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. It seems that in several 6.32/XX pre-compiled binaries the class `TMVA::Experimental::SOFIE::RModelParser_ONNX` is missing. With 6.32/06 on Ubuntu 24.04:. ```. root [0] TMVA::Experimental::SOFIE::RModelParser_ONNX(). ROOT_prompt_0:1:28: error: no member named 'RModelParser_ONNX' in namespace 'TMVA::Experimental::SOFIE'. TMVA::Experimental::SOFIE::RModelParser_ONNX(). ~~~~~~~~~~~~~~~~~~~~~~~~~~~^. ```. while it works perfectly fine on Ubuntu 20.04. I quickly checked that the header file `RModelParser_ONNX.hxx` is missing in the folder `include/TMVA` in 6.32/XX pre-compiled binaries for both Ubuntu 22.04 and Ubuntu 24.04, while it is present in the pre-compiled binaries for Ubuntu 20.04, Almalinux 8.9 and Almalinux 9.4. Unless there are good reasons why `RModel_ONNX` class should be missing in Ubuntu 22.04 and Ubuntu 24.04 binaries, I assume there is something fishy in the build system. ### Reproducer. On an Ubuntu 24.04 machine:. ```. wget wget https://root.cern/download/root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. tar -xzf root_v6.32.06.Linux-ubuntu24.04-x86_64-gcc13.2.tar.gz. source root/bin/thisroot.sh. root. (from the ROOT shell) TMVA::Experimental::SOFIE::RModelParser_ONNX(). ```. ### ROOT version. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.32.06 https://root.cern |. | (c) 1995-2024, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Sep 21 2024, 19:19:59 |. | From tags/v6-32-06@v6-32-06 |. | With c++ (Ubuntu 13.2.0-23ubuntu4) 13.2.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Installation method. pre-built binaries. ### Operating system. Ubuntu 22.04, Ubuntu 24.04. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16774
https://github.com/root-project/root/pull/16775:32,deployability,version,versions,32,[ci] Enable Sofie on all Ubuntu versions; This is an attempt to fix https://github.com/root-project/root/issues/16774 once the next release is created.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16775
https://github.com/root-project/root/pull/16775:132,deployability,releas,release,132,[ci] Enable Sofie on all Ubuntu versions; This is an attempt to fix https://github.com/root-project/root/issues/16774 once the next release is created.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16775
https://github.com/root-project/root/pull/16775:32,integrability,version,versions,32,[ci] Enable Sofie on all Ubuntu versions; This is an attempt to fix https://github.com/root-project/root/issues/16774 once the next release is created.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16775
https://github.com/root-project/root/pull/16775:32,modifiability,version,versions,32,[ci] Enable Sofie on all Ubuntu versions; This is an attempt to fix https://github.com/root-project/root/issues/16774 once the next release is created.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16775
https://github.com/root-project/root/pull/16777:189,deployability,contain,contain,189,"[RF] Avoid using variable-length arrays in RooFit multiprocessing tests; These VLAs are not part of the C++ standard and cause compiler warnings. In this case, the arrays were only used to contain reference values, which can absolutely be done with `std::vector` on the heap.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16777
https://github.com/root-project/root/pull/16777:108,interoperability,standard,standard,108,"[RF] Avoid using variable-length arrays in RooFit multiprocessing tests; These VLAs are not part of the C++ standard and cause compiler warnings. In this case, the arrays were only used to contain reference values, which can absolutely be done with `std::vector` on the heap.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16777
https://github.com/root-project/root/pull/16777:17,modifiability,variab,variable-length,17,"[RF] Avoid using variable-length arrays in RooFit multiprocessing tests; These VLAs are not part of the C++ standard and cause compiler warnings. In this case, the arrays were only used to contain reference values, which can absolutely be done with `std::vector` on the heap.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16777
https://github.com/root-project/root/pull/16777:5,safety,Avoid,Avoid,5,"[RF] Avoid using variable-length arrays in RooFit multiprocessing tests; These VLAs are not part of the C++ standard and cause compiler warnings. In this case, the arrays were only used to contain reference values, which can absolutely be done with `std::vector` on the heap.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16777
https://github.com/root-project/root/pull/16777:66,safety,test,tests,66,"[RF] Avoid using variable-length arrays in RooFit multiprocessing tests; These VLAs are not part of the C++ standard and cause compiler warnings. In this case, the arrays were only used to contain reference values, which can absolutely be done with `std::vector` on the heap.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16777
https://github.com/root-project/root/pull/16777:66,testability,test,tests,66,"[RF] Avoid using variable-length arrays in RooFit multiprocessing tests; These VLAs are not part of the C++ standard and cause compiler warnings. In this case, the arrays were only used to contain reference values, which can absolutely be done with `std::vector` on the heap.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16777
https://github.com/root-project/root/pull/16778:24,availability,cluster,cluster,24,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:111,availability,cluster,cluster,111,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:175,availability,cluster,cluster,175,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:24,deployability,cluster,cluster,24,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:111,deployability,cluster,cluster,111,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:175,deployability,cluster,cluster,175,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:72,safety,test,testing,72,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:72,testability,test,testing,72,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16778:52,usability,experien,experience,52,"[ntuple] Adjust default cluster size; Following the experience with AGC testing, double the default compressed cluster size to 100 MB and also double the maximum uncompressed cluster size to 1 GiB.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16778
https://github.com/root-project/root/pull/16779:139,interoperability,semant,semantics,139,"[ntuple] Construct RVariantField with vector of unique_ptr; This clearly signals ownership transfer and avoids circumventing smart pointer semantics. For more details on passing the vector by value, see also commit c7dac7370d.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16779
https://github.com/root-project/root/pull/16779:104,safety,avoid,avoids,104,"[ntuple] Construct RVariantField with vector of unique_ptr; This clearly signals ownership transfer and avoids circumventing smart pointer semantics. For more details on passing the vector by value, see also commit c7dac7370d.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16779
https://github.com/root-project/root/pull/16779:73,security,sign,signals,73,"[ntuple] Construct RVariantField with vector of unique_ptr; This clearly signals ownership transfer and avoids circumventing smart pointer semantics. For more details on passing the vector by value, see also commit c7dac7370d.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16779
https://github.com/root-project/root/pull/16779:65,usability,clear,clearly,65,"[ntuple] Construct RVariantField with vector of unique_ptr; This clearly signals ownership transfer and avoids circumventing smart pointer semantics. For more details on passing the vector by value, see also commit c7dac7370d.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16779
https://github.com/root-project/root/pull/16780:84,safety,avoid,avoid,84,"[CPyCppyy] Initialize new PyTypeObject fields introduced in Python 3.13; This is to avoid compilier warnings, as usual. Commit will also be ported to `wlav/CPyCppyy`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16780
https://github.com/root-project/root/pull/16781:356,availability,cluster,cluster,356,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:555,availability,slo,slower,555,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:356,deployability,cluster,cluster,356,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:9,energy efficiency,Reduc,Reduce,9,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:252,energy efficiency,alloc,allocation,252,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:327,energy efficiency,reduc,reduced,327,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:245,integrability,buffer,buffer,245,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:441,integrability,buffer,buffered,441,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:729,integrability,buffer,buffer,729,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:16,performance,memor,memory,16,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:308,performance,memor,memory,308,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:315,performance,overhead,overhead,315,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:375,performance,parallel,parallel,375,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:468,performance,memor,memory,468,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:475,performance,overhead,overhead,475,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:672,performance,concurren,concurrently,672,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:555,reliability,slo,slower,555,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:16,usability,memor,memory,16,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:308,usability,memor,memory,308,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:468,usability,memor,memory,468,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:738,usability,Close,Closes,738,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16781:753,usability,close,closes,753,"[ntuple] Reduce memory usage of `RPageSinkBuf`; 1. Shrink sealed page in `RPageSinkBuf`, https://github.com/root-project/root/issues/16752. 2. Free uncompressed page after compression, https://github.com/root-project/root/issues/16753. 3. Delay buffer allocation in `RPageSinkBuf`. For the non-IMT case, the memory overhead is reduced to around the zipped cluster size. With parallel compression using IMT, all uncompressed pages need to be buffered first. The actual memory overhead is a function of how quickly these are consumed in the background (the slower, the later they are freed after compression) on the one hand and on the other hand how many tasks are running concurrently (each of them needs a temporary compression buffer). Closes #16752, closes #16753",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16781
https://github.com/root-project/root/pull/16782:12,availability,consist,consistent,12,[hist] more consistent notation of GetQuantile function; Fixes https://github.com/root-project/root/issues/16736. following suggestions by @AntoniMarcinek. original code is from @eoffermann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16782
https://github.com/root-project/root/pull/16782:12,usability,consist,consistent,12,[hist] more consistent notation of GetQuantile function; Fixes https://github.com/root-project/root/issues/16736. following suggestions by @AntoniMarcinek. original code is from @eoffermann,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16782
https://github.com/root-project/root/pull/16783:282,availability,robust,robust,282,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:396,deployability,modul,modules,396,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:554,deployability,Updat,Update,554,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:14,integrability,batch,batch,14,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:154,integrability,batch,batch,154,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:345,integrability,batch,batch,345,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:470,integrability,configur,configure,470,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:396,modifiability,modul,modules,396,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:470,modifiability,configur,configure,470,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:14,performance,batch,batch,14,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:154,performance,batch,batch,154,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:328,performance,perform,performed,328,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:345,performance,batch,batch,345,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:282,reliability,robust,robust,282,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:282,safety,robust,robust,282,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:396,safety,modul,modules,396,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:554,safety,Updat,Update,554,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:470,security,configur,configure,470,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:554,security,Updat,Update,554,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/pull/16783:328,usability,perform,performed,328,"[webcanv] use batch mode for stored JSON; When created JSON should be used outside ROOT application and without running THttpServer,. it is better to use batch mode for generation of JSON files. Places are:. 1. jupyter. 2. doxygen. 3. c1->SaveAs(""file.json""). Produced JSON is more robust and can be processed as is - how it is performed by the batch image production. Main difference - extra JS modules directly embed into JSON. And `TF1` always store its values. Also configure `source_dir` of JSROOT when producing images. This let use local mathjax. Update JSROOT with Android/TGeo fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16783
https://github.com/root-project/root/issues/16784:692,availability,Operat,Operating,692,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:265,deployability,Depend,Depending,265,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:588,deployability,version,version,588,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:655,deployability,Instal,Installation,655,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:265,integrability,Depend,Depending,265,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:588,integrability,version,version,588,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:265,modifiability,Depend,Depending,265,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:480,modifiability,paramet,parameter,480,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:588,modifiability,version,version,588,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:340,reliability,doe,does,340,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:265,safety,Depend,Depending,265,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:265,testability,Depend,Depending,265,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/issues/16784:737,testability,context,context,737,"Remove default value of p from TH1::GetQuantiles() as is the case with TF1::GetQuantiles; ### Explain what you would like to see improved and how. This is a follow-up to #16736, see https://github.com/root-project/root/pull/16782#discussion_r1820807153. <details>. Depending on whether `p` argument is `nullptr` or not, the method actually does 2 different things. It either calculates `xp` given `p` or it calculates `p`. So it is either F^-1(p) or F(x). </details>. The default parameter of p = nullptr brings the method to return just the bin edges, so it is not very useful. ### ROOT version. master, although notation matches what #16782 brings. ### Installation method. irrelevant. ### Operating system. irrelevant. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16784
https://github.com/root-project/root/pull/16785:100,deployability,API,API,100,"[CPyCppyy] Don't use deprecated Py_GetProgramName; The `Py_GetProgramName` function in the Python C API was deprecated in Python 3.13 and will be removed in Python 3.15. However, it seems behavior is unchanged by just passing an empty string instead. This avoids a warning when building CPyCppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785
https://github.com/root-project/root/pull/16785:278,deployability,build,building,278,"[CPyCppyy] Don't use deprecated Py_GetProgramName; The `Py_GetProgramName` function in the Python C API was deprecated in Python 3.13 and will be removed in Python 3.15. However, it seems behavior is unchanged by just passing an empty string instead. This avoids a warning when building CPyCppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785
https://github.com/root-project/root/pull/16785:100,integrability,API,API,100,"[CPyCppyy] Don't use deprecated Py_GetProgramName; The `Py_GetProgramName` function in the Python C API was deprecated in Python 3.13 and will be removed in Python 3.15. However, it seems behavior is unchanged by just passing an empty string instead. This avoids a warning when building CPyCppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785
https://github.com/root-project/root/pull/16785:100,interoperability,API,API,100,"[CPyCppyy] Don't use deprecated Py_GetProgramName; The `Py_GetProgramName` function in the Python C API was deprecated in Python 3.13 and will be removed in Python 3.15. However, it seems behavior is unchanged by just passing an empty string instead. This avoids a warning when building CPyCppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785
https://github.com/root-project/root/pull/16785:256,safety,avoid,avoids,256,"[CPyCppyy] Don't use deprecated Py_GetProgramName; The `Py_GetProgramName` function in the Python C API was deprecated in Python 3.13 and will be removed in Python 3.15. However, it seems behavior is unchanged by just passing an empty string instead. This avoids a warning when building CPyCppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785
https://github.com/root-project/root/pull/16785:188,usability,behavi,behavior,188,"[CPyCppyy] Don't use deprecated Py_GetProgramName; The `Py_GetProgramName` function in the Python C API was deprecated in Python 3.13 and will be removed in Python 3.15. However, it seems behavior is unchanged by just passing an empty string instead. This avoids a warning when building CPyCppyy.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16785
https://github.com/root-project/root/pull/16786:29,integrability,pub,public,29,"[ntuple] make CreateAnchor a public internal free function; This allows programs (such as 3rd party readers) to create a RNTuple anchor while keeping it clear that ""regular"" users are not meant to do that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16786
https://github.com/root-project/root/pull/16786:153,usability,clear,clear,153,"[ntuple] make CreateAnchor a public internal free function; This allows programs (such as 3rd party readers) to create a RNTuple anchor while keeping it clear that ""regular"" users are not meant to do that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16786
https://github.com/root-project/root/pull/16786:174,usability,user,users,174,"[ntuple] make CreateAnchor a public internal free function; This allows programs (such as 3rd party readers) to create a RNTuple anchor while keeping it clear that ""regular"" users are not meant to do that.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16786
https://github.com/root-project/root/pull/16787:50,availability,consist,consistency,50,[ntuple] rename iterators' count() -> size(); for consistency with C++20 ranges.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16787
https://github.com/root-project/root/pull/16787:50,usability,consist,consistency,50,[ntuple] rename iterators' count() -> size(); for consistency with C++20 ranges.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16787
https://github.com/root-project/root/pull/16788:5,deployability,updat,update,5,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:90,deployability,Updat,Updates,90,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:198,deployability,updat,updates,198,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:260,deployability,updat,updated,260,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:5,safety,updat,update,5,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:25,safety,Test,TestStatistics,25,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:90,safety,Updat,Updates,90,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:139,safety,Test,TestStatistics,139,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:198,safety,updat,updates,198,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:229,safety,test,tested,229,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:260,safety,updat,updated,260,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:5,security,updat,update,5,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:90,security,Updat,Updates,90,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:198,security,updat,updates,198,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:260,security,updat,updated,260,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:25,testability,Test,TestStatistics,25,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:139,testability,Test,TestStatistics,139,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16788:229,testability,test,tested,229,[RF] update MultiProcess/TestStatistics docs; # This Pull request:. ## Changes or fixes:. Updates the RooFit::MultiProcess-enabled RooFit::TestStatistics classes docs to include all the most recent updates. ## Checklist:. - [x] ~tested changes locally~. - [x] updated the docs (if necessary). This PR fixes #10967,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16788
https://github.com/root-project/root/pull/16789:15,safety,test,test,15,"[ntuple] add a test for accessing a RNTupleView out of bounds; I realized we were missing a test for accessing a view out of bounds, so I added one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16789
https://github.com/root-project/root/pull/16789:92,safety,test,test,92,"[ntuple] add a test for accessing a RNTupleView out of bounds; I realized we were missing a test for accessing a view out of bounds, so I added one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16789
https://github.com/root-project/root/pull/16789:24,security,access,accessing,24,"[ntuple] add a test for accessing a RNTupleView out of bounds; I realized we were missing a test for accessing a view out of bounds, so I added one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16789
https://github.com/root-project/root/pull/16789:101,security,access,accessing,101,"[ntuple] add a test for accessing a RNTupleView out of bounds; I realized we were missing a test for accessing a view out of bounds, so I added one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16789
https://github.com/root-project/root/pull/16789:15,testability,test,test,15,"[ntuple] add a test for accessing a RNTupleView out of bounds; I realized we were missing a test for accessing a view out of bounds, so I added one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16789
https://github.com/root-project/root/pull/16789:92,testability,test,test,92,"[ntuple] add a test for accessing a RNTupleView out of bounds; I realized we were missing a test for accessing a view out of bounds, so I added one.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16789
https://github.com/root-project/root/issues/16790:1757,availability,Operat,Operating,1757,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:39,deployability,fail,fails,39,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:257,deployability,stack,stack,257,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1154,deployability,build,build,1154,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1569,deployability,instal,installation,1569,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1703,deployability,version,version,1703,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1724,deployability,Instal,Installation,1724,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1791,deployability,contain,container,1791,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1094,energy efficiency,alloc,allocator,1094,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1448,energy efficiency,GPU,GPU,1448,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1617,energy efficiency,gpu,gpu,1617,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1703,integrability,version,version,1703,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1219,interoperability,Specif,Specifically,1219,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1703,modifiability,version,version,1703,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1448,performance,GPU,GPU,1448,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1617,performance,gpu,gpu,1617,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:39,reliability,fail,fails,39,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:34,safety,test,test,34,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:151,safety,test,test,151,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:922,safety,test,testLSTMBackpropagation,922,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1170,safety,test,test,1170,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1184,safety,test,testLSTMBackpropagationCudnn,1184,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1361,safety,test,test,1361,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1375,safety,Test,TestLSTMBackpropagation,1375,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1514,safety,test,tests,1514,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:34,testability,test,test,34,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:151,testability,test,test,151,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:263,testability,trace,trace,263,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:922,testability,test,testLSTMBackpropagation,922,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1170,testability,test,test,1170,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1184,testability,test,testLSTMBackpropagationCudnn,1184,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1361,testability,test,test,1361,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1375,testability,Test,TestLSTMBackpropagation,1375,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1514,testability,test,tests,1514,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/issues/16790:1834,testability,context,context,1834,"[TMVA] cuDNN LSTM backpropagation test fails on ubuntu2404 cuda 12.6.1; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. The test `TMVA-DNN-LSTM-BackpropagationCudnn` crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Specifically, it's the assignment in this loop:. https://github.com/root-project/root/blob/9d876cd7faafcb6f0249b1185831a1be53865cac/tmva/tmva/test/DNN/LSTM/TestLSTMBackpropagation.h#L149-L159. Which triggers a cuda_memcpy to the GPU. The crash happens somewhere in the cuda library. Other cudnn tests work, so the problem is not necessarily a broken installation. ### Reproducer. ```. cmake -Dtmva-gpu=On -Dtesting=On <src>. ctest -R TMVA-DNN-LSTM-BackpropagationCudnn. ```. ### ROOT version. Master. ### Installation method. Source. ### Operating system. ubuntu24 docker container with cuda 12.6.1. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16790
https://github.com/root-project/root/pull/16791:147,deployability,stack,stack,147,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:1044,deployability,build,build,1044,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:984,energy efficiency,alloc,allocator,984,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:32,safety,test,test,32,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:43,safety,test,test,43,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:812,safety,test,testLSTMBackpropagation,812,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:1060,safety,test,test,1060,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:1074,safety,test,testLSTMBackpropagationCudnn,1074,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:32,testability,test,test,32,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:43,testability,test,test,43,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:153,testability,trace,trace,153,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:812,testability,test,testLSTMBackpropagation,812,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:1060,testability,test,test,1060,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:1074,testability,test,testLSTMBackpropagationCudnn,1074,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16791:1150,usability,progress,progress,1150,"[TMVA] Disable a crashing cuDNN test.; The test TMVA-DNN-LSTM-BackpropagationCudnn crashes on ubuntu2404 cuda-12.6.1 with cudnn with the following stack trace:. ```. 0x00007fda7f0b5540 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed1491e in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7f08f040 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7ed0ef22 in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fda7eed2bae in <unknown> from /usr/lib64/libcuda.so.1. 0x00007fdaaa248b01 in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa218baa in <unknown> from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x00007fdaaa270721 in cudaMemcpy + 0x211 from /usr/local/cuda-12.6/targets/x86_64-linux/lib/libcudart.so.12. 0x000055d25af29e37 in bool testLSTMBackpropagation<TMVA::DNN::TCudnn<double> >(unsigned long, unsigned long, unsigned long, unsigned long, TMVA::DNN::TCudnn<double>::Scalar_t, std::vector<bool, std::allocator<bool> >, bool) + 0x4d37 from /github/home/ROOT-CI/build/tmva/tmva/test/DNN/LSTM/testLSTMBackpropagationCudnn. ```. Disabling it now, #16790 opened to track progress.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16791
https://github.com/root-project/root/pull/16792:313,integrability,inject,injection,313,[jsroot] dev 30/10/2024; 1. Fix - handle reordering of fragments in multipart reply https://github.com/root-project/jsroot/issues/319. 2. Fix - properly show non-zero entries https://github.com/root-project/jsroot/issues/320. 3. Fix - display empty hist bin if fSumw2 not zero. 4. Fix - let use batch_mode script injection in interactive session.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16792
https://github.com/root-project/root/pull/16792:313,security,inject,injection,313,[jsroot] dev 30/10/2024; 1. Fix - handle reordering of fragments in multipart reply https://github.com/root-project/jsroot/issues/319. 2. Fix - properly show non-zero entries https://github.com/root-project/jsroot/issues/320. 3. Fix - display empty hist bin if fSumw2 not zero. 4. Fix - let use batch_mode script injection in interactive session.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16792
https://github.com/root-project/root/pull/16792:338,security,session,session,338,[jsroot] dev 30/10/2024; 1. Fix - handle reordering of fragments in multipart reply https://github.com/root-project/jsroot/issues/319. 2. Fix - properly show non-zero entries https://github.com/root-project/jsroot/issues/320. 3. Fix - display empty hist bin if fSumw2 not zero. 4. Fix - let use batch_mode script injection in interactive session.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16792
https://github.com/root-project/root/pull/16792:326,usability,interact,interactive,326,[jsroot] dev 30/10/2024; 1. Fix - handle reordering of fragments in multipart reply https://github.com/root-project/jsroot/issues/319. 2. Fix - properly show non-zero entries https://github.com/root-project/jsroot/issues/320. 3. Fix - display empty hist bin if fSumw2 not zero. 4. Fix - let use batch_mode script injection in interactive session.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16792
https://github.com/root-project/root/pull/16793:154,energy efficiency,current,currently,154,"[hist] remove default parameter in TH1::GetQuantiles, as is the case with TF1::GetQuantiles; Fixes https://github.com/root-project/root/issues/16784. The currently default parameter of p = nullptr is a very weird use case, which calculates F-1(F(bin_edges)), ie it just returns the bin edges. So force user to really decide if he wants to pass that nullptr as argument. Warning: this PR might break some preexisting scripts though relying on this weird feature.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16793
https://github.com/root-project/root/pull/16793:22,modifiability,paramet,parameter,22,"[hist] remove default parameter in TH1::GetQuantiles, as is the case with TF1::GetQuantiles; Fixes https://github.com/root-project/root/issues/16784. The currently default parameter of p = nullptr is a very weird use case, which calculates F-1(F(bin_edges)), ie it just returns the bin edges. So force user to really decide if he wants to pass that nullptr as argument. Warning: this PR might break some preexisting scripts though relying on this weird feature.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16793
https://github.com/root-project/root/pull/16793:172,modifiability,paramet,parameter,172,"[hist] remove default parameter in TH1::GetQuantiles, as is the case with TF1::GetQuantiles; Fixes https://github.com/root-project/root/issues/16784. The currently default parameter of p = nullptr is a very weird use case, which calculates F-1(F(bin_edges)), ie it just returns the bin edges. So force user to really decide if he wants to pass that nullptr as argument. Warning: this PR might break some preexisting scripts though relying on this weird feature.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16793
https://github.com/root-project/root/pull/16793:302,usability,user,user,302,"[hist] remove default parameter in TH1::GetQuantiles, as is the case with TF1::GetQuantiles; Fixes https://github.com/root-project/root/issues/16784. The currently default parameter of p = nullptr is a very weird use case, which calculates F-1(F(bin_edges)), ie it just returns the bin edges. So force user to really decide if he wants to pass that nullptr as argument. Warning: this PR might break some preexisting scripts though relying on this weird feature.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16793
https://github.com/root-project/root/issues/16794:281,availability,error,error,281,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:678,availability,Operat,Operating,678,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:596,deployability,version,version,596,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:616,deployability,version,versions,616,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:648,deployability,Instal,Installation,648,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:596,integrability,version,version,596,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:616,integrability,version,versions,616,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:38,modifiability,variab,variable,38,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:195,modifiability,variab,variable,195,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:596,modifiability,version,version,596,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:616,modifiability,version,versions,616,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:281,performance,error,error,281,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:281,safety,error,error,281,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:716,testability,context,context,716,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/issues/16794:281,usability,error,error,281,"TFormula: Pol functions do not accept variable name as arguments ; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. In TFormula the polynomial functions do not accept a variable name (such as x) as argument. . ### Reproducer. Example of code producing an error in parsing the formula expression. ```. TF1 f1(""f1"",""pol1(x,0)"");. TF1 f2(""f2"",""pol1(x,[A],[B])"");. ```. In the case of other predefined functions, for example, gaus, works as expected:. ```. TF1 f1(""f1"",""gaus(x,0)"");. f1.Print(""V"");. TF1 f2(""f2"",""gaus(x,[A],[mean],[sigma])"");. f2.Print(""V"");. ```. ### ROOT version. All ROOT 6 versions with new TFormula. ### Installation method. All. ### Operating system. All. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16794
https://github.com/root-project/root/pull/16795:29,deployability,contain,container,29,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:171,deployability,contain,container-local,171,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:113,performance,time,times,113,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:187,performance,network,network,187,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:14,security,dns,dns,14,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:82,security,dns,dns,82,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:87,security,dns,dns,87,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:133,security,dns,dns,133,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/pull/16795:187,security,network,network,187,"[CI] Add cern dns servers to container config.; Due to a bug in podman + aardvark-dns, dns resolution frequently times out. The CERN dns servers are added to sidestep the container-local network.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16795
https://github.com/root-project/root/issues/16796:1004,availability,ERROR,ERROR,1004,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1226,availability,Operat,Operating,1226,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:978,deployability,observ,observables,978,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1174,deployability,version,version,1174,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1193,deployability,Instal,Installation,1193,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:191,integrability,wrap,wraps,191,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:470,integrability,sub,submit,470,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:829,integrability,event,events,829,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1174,integrability,version,version,1174,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:200,modifiability,exten,extended,200,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:286,modifiability,exten,extended,286,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:847,modifiability,exten,extended,847,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1174,modifiability,version,version,1174,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1004,performance,ERROR,ERROR,1004,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:18,reliability,doe,does,18,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:391,reliability,doe,does,391,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1004,safety,ERROR,ERROR,1004,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1010,safety,Input,InputArguments,1010,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:978,testability,observ,observables,978,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1264,testability,context,context,1264,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:526,usability,minim,minimal,526,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:778,usability,Minim,Minimization,778,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1004,usability,ERROR,ERROR,1004,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/issues/16796:1010,usability,Input,InputArguments,1010,"RooBinSamplingPdf does not forward expectedEventsFunc creation calls; ### Check duplicate issues. - [ ] Checked for duplicates. ### Description. I found that putting a RooBinSamplingPdf that wraps an extended pdf inside a RooAddPdf (that is in 'no-coefficient' mode, so that it is also extended), you cannot construct the NLL for this. The reason I think is that the RooBinSamplingPdf class does not forward the createExpectedEventsFunc call to the underlying pdf. Will submit a fix in just a moment. ### Reproducer. Here's a minimal reproducer:. ```. RooWorkspace w;. w.factory(""RooAddPdf::apdf(RooBinSamplingPdf::p(x,RooExtendPdf::epdf(EXPR::pdf('x',x[0,10]),e[100])))"");. RooDataSet d(""data"",""data"",*w.var(""x""));. w.pdf(""apdf"")->createNLL(d);. ```. Produces:. ```. [#1] INFO:Minimization -- p.d.f. provides expected number of events, including extended term in likelihood. [#1] INFO:Fitting -- RooAbsPdf::fitTo(apdf) fixing normalization set for coefficient determination to observables in data. [#0] ERROR:InputArguments -- The pdf ""p"" of type RooBinSamplingPdf did not overload RooAbsPdf::createExpectedEventsFunc()! *** Break *** segmentation violation. ```. ### ROOT version. 6.34. ### Installation method. source. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16796
https://github.com/root-project/root/pull/16797:44,integrability,sub,subpdf,44,forward call to createExpectedEventsFunc to subpdf; . ## Changes or fixes:. https://github.com/root-project/root/issues/16796.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16797
https://github.com/root-project/root/pull/16798:50,interoperability,format,formatting,50,"[skip-ci][NFC][ntuple] Fix fundamental type table formatting; The original table format cannot be properly rendered by GH flavored markdown. This PR attempts to clear up the formatting, respecting the formatting specs (and limits thereof) of GH flavored Markdown. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16798
https://github.com/root-project/root/pull/16798:81,interoperability,format,format,81,"[skip-ci][NFC][ntuple] Fix fundamental type table formatting; The original table format cannot be properly rendered by GH flavored markdown. This PR attempts to clear up the formatting, respecting the formatting specs (and limits thereof) of GH flavored Markdown. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16798
https://github.com/root-project/root/pull/16798:174,interoperability,format,formatting,174,"[skip-ci][NFC][ntuple] Fix fundamental type table formatting; The original table format cannot be properly rendered by GH flavored markdown. This PR attempts to clear up the formatting, respecting the formatting specs (and limits thereof) of GH flavored Markdown. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16798
https://github.com/root-project/root/pull/16798:201,interoperability,format,formatting,201,"[skip-ci][NFC][ntuple] Fix fundamental type table formatting; The original table format cannot be properly rendered by GH flavored markdown. This PR attempts to clear up the formatting, respecting the formatting specs (and limits thereof) of GH flavored Markdown. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16798
https://github.com/root-project/root/pull/16798:161,usability,clear,clear,161,"[skip-ci][NFC][ntuple] Fix fundamental type table formatting; The original table format cannot be properly rendered by GH flavored markdown. This PR attempts to clear up the formatting, respecting the formatting specs (and limits thereof) of GH flavored Markdown. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16798
https://github.com/root-project/root/pull/16799:9,deployability,version,version,9,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:80,deployability,scale,scale,80,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:80,energy efficiency,scale,scale,80,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:9,integrability,version,version,9,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:9,modifiability,version,version,9,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:80,modifiability,scal,scale,80,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:80,performance,scale,scale,80,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:107,usability,custom,custom,107,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16799:198,usability,minim,minimal,198,[jsroot] version 7.7.5 [6.32]; 1. Fix - can enable exponent only for log10 axis scale. 2. Fix - proper set custom font size in latex. 3. Fix - do not force style 8 for hist markers. 4. Fix - ensure minimal hist title height. 5. Fix - disable Bloom effect on Android. 6. Fix - handle reordering of fragments in multipart reply. 7. Fix - properly show non-zero entries.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16799
https://github.com/root-project/root/pull/16801:194,deployability,updat,updated,194,[hist] fine-tune getquantile computation; # This Pull request:. ## Changes or fixes:. Fixes https://github.com/root-project/root/issues/12251. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16801
https://github.com/root-project/root/pull/16801:12,performance,tune,tune,12,[hist] fine-tune getquantile computation; # This Pull request:. ## Changes or fixes:. Fixes https://github.com/root-project/root/issues/12251. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16801
https://github.com/root-project/root/pull/16801:164,safety,test,tested,164,[hist] fine-tune getquantile computation; # This Pull request:. ## Changes or fixes:. Fixes https://github.com/root-project/root/issues/12251. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16801
https://github.com/root-project/root/pull/16801:194,safety,updat,updated,194,[hist] fine-tune getquantile computation; # This Pull request:. ## Changes or fixes:. Fixes https://github.com/root-project/root/issues/12251. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16801
https://github.com/root-project/root/pull/16801:194,security,updat,updated,194,[hist] fine-tune getquantile computation; # This Pull request:. ## Changes or fixes:. Fixes https://github.com/root-project/root/issues/12251. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16801
https://github.com/root-project/root/pull/16801:164,testability,test,tested,164,[hist] fine-tune getquantile computation; # This Pull request:. ## Changes or fixes:. Fixes https://github.com/root-project/root/issues/12251. ## Checklist:. - [x] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16801
https://github.com/root-project/root/pull/16802:41,deployability,build,build,41,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16802:209,deployability,upgrad,upgrade,209,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16802:397,deployability,patch,patch,397,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16802:209,modifiability,upgrad,upgrade,209,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16802:323,modifiability,portab,portable,323,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16802:397,safety,patch,patch,397,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16802:397,security,patch,patch,397,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16802:253,usability,command,command,253,"builtin_davix: Drop `PATCH_COMMAND`; The build fix for FreeBSD is included already since DAVIX 0.8.6, so the `PATCH_COMMAND` is not needed (it was merged because the PR was older, opened in February, than the upgrade of the builtin in May). In fact the command breaks builtin_davix on Linux systems because `sed -i` is not portable between GNU sed and BSD sed. (Note that the same is true for the patch itself, see my comment in https://github.com/cern-fts/davix/pull/113#issuecomment-2449788349.)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16802
https://github.com/root-project/root/pull/16803:11,deployability,resourc,resource,11,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:159,deployability,resourc,resource,159,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:11,energy efficiency,resourc,resource,11,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:28,energy efficiency,GPU,GPU,28,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:41,energy efficiency,reduc,reduce,41,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:68,energy efficiency,GPU,GPUs,68,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:159,energy efficiency,resourc,resource,159,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:11,performance,resourc,resource,11,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:20,performance,lock,lock,20,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:28,performance,GPU,GPU,28,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:48,performance,content,contention,48,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:68,performance,GPU,GPUs,68,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:122,performance,parallel,parallel,122,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:159,performance,resourc,resource,159,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:168,performance,lock,lock,168,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:11,safety,resourc,resource,11,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:32,safety,test,tests,32,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:74,safety,test,tests,74,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:144,safety,avoid,avoided,144,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:159,safety,resourc,resource,159,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:20,security,lock,lock,20,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:168,security,lock,lock,168,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:11,testability,resourc,resource,11,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:32,testability,test,tests,32,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:74,testability,test,tests,74,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/pull/16803:159,testability,resourc,resource,159,"[CI] Add a resource lock to GPU tests to reduce contention; On weak GPUs, tests might take very long when they all run in parallel. This can be avoided with a resource lock.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16803
https://github.com/root-project/root/issues/16804:1504,availability,Operat,Operating,1504,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:236,deployability,updat,updated,236,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:753,deployability,contain,containing,753,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1314,deployability,version,version,1314,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1457,deployability,Instal,Installation,1457,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1117,energy efficiency,Load,LoadTree,1117,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1172,energy efficiency,Load,LoadTree,1172,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1042,integrability,wrap,wrapping,1042,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1314,integrability,version,version,1314,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1314,modifiability,version,version,1314,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1117,performance,Load,LoadTree,1117,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1172,performance,Load,LoadTree,1172,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:236,safety,updat,updated,236,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:236,security,updat,updated,236,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:1583,testability,context,context,1583,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:349,usability,user,user-attachments,349,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:460,usability,behavi,behavior,460,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16804:997,usability,behavi,behavior,997,"TChain as a friend of TTree gets stuck after the first file; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. When a `TChain` is added as a friend to a `TTree` , branches coming from the `TChain` are no longer updated after switching to the second file in the chain. ### Reproducer. The [attached macro](https://github.com/user-attachments/files/17592119/bugDemo.txt) reproduces the issue. Save it `bugDemo.C` and run it. The correct behavior is to always print `true`, but we get some `false`. The code first constructs two trees with an `index` branch. The index is the entry number, going from 0 to 10 in the first file and 10 to 20 in the second one. Then, a longer tree is constructed with 20 empty entries. The two files containing the entry number as merged into a chain and attached as a friend to the empty tree. Iterating over the long tree yields the correct value of `index` until the 10th entry, than a constant 9 (the last value in the first file). Correct behavior is 0 to 20. This can be obtained by wrapping the long tree in a `TChain`. The underlying issue is that `TTree::LoadTree` lacks the following code present in `TChain::LoadTree`:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in `master` in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. Possibly related to the following Jira tickets:. * https://its.cern.ch/jira/browse/ROOT-10778 (open). * https://its.cern.ch/jira/browse/ROOT-2935 (reportedly fixed in 6.04.00)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16804
https://github.com/root-project/root/issues/16805:821,availability,operat,operation,821,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2607,availability,Operat,Operating,2607,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:47,deployability,updat,updating,47,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:306,deployability,updat,updating,306,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:376,deployability,updat,updating,376,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2007,deployability,updat,updated,2007,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2419,deployability,version,version,2419,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2560,deployability,Instal,Installation,2560,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:160,energy efficiency,load,loading,160,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:517,energy efficiency,Load,LoadTree,517,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:554,energy efficiency,Load,LoadTree,554,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:936,energy efficiency,current,current,936,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1544,energy efficiency,Load,LoadTree,1544,"hain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1939,energy efficiency,load,loads,1939,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1805,integrability,sub,subscribing,1805,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2419,integrability,version,version,2419,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2419,modifiability,version,version,2419,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:160,performance,load,loading,160,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:517,performance,Load,LoadTree,517,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:554,performance,Load,LoadTree,554,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1544,performance,Load,LoadTree,1544,"hain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1939,performance,load,loads,1939,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1091,reliability,doe,doesn,1091,"cked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1361,reliability,doe,doesn,1361," They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works simi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1399,reliability,doe,does,1399,"e boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1960,reliability,doe,doesn,1960,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:47,safety,updat,updating,47,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:306,safety,updat,updating,306,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:376,safety,updat,updating,376,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2007,safety,updat,updated,2007,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:47,security,updat,updating,47,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:306,security,updat,updating,306,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:376,security,updat,updating,376,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:1833,security,sign,signal,1833,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2007,security,updat,updated,2007,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2686,testability,context,context,2686,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:41,usability,stop,stops,41,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:301,usability,stop,stop,301,"A TChain whose trees have friend TChains stops updating; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Consider the following tree loading structure:. ```. TChain c2 ---> TTree ---(friend)---> TChain c1 ---> TTree. ```. When iterating over `c2`, branches coming from `c1` stop updating after the first file boundary is reached in `c1`. They start updating again once a file boundary is reached in `c2`. I think this is distinct from #16804 because in this case the issues lie in `TChain::LoadTree`, while for #16804 `TChain::LoadTree` is the sole culprit. As in #16804, the root cause of the issue is that the following code is not invoked often enough:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/issues/16805:2296,usability,user,user-attachments,2296,"project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1407-L1434. I will call the operation above an ""address refresh"". TChain has code triggering an address refresh when needed for friends of the current tree:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1384-L1393. Unfortunately this doesn't work for two reasons:. 1. The code cannot possibly be reached unless `c2` itself has friends because of the following condition:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1370. In our case `c2` doesn't have friends, but the `fTree` does. This is easy to fix (or work around). 2. Even if `fFriends` is made non-null, `fetree->IsUpdated()` always returns `false` because `TTree::LoadTree` resets it:. https://github.com/root-project/root/blob/18b4f317b389fa7931d7eb8e00525f4dca44be0f/tree/tree/src/TTree.cxx#L6512. Fixing this is much more annoying. For [my application](https://gitlab.cern.ch/Proto/Darwin/-/merge_requests/44), I ended up subscribing to the `Notify` signal and calling `TFriendElement::MarkUpdated` again. This is only a partial solution because when `c2` loads a new file, it doesn't reset friend elements that were marked updated, which would happen somewhere along this line:. https://github.com/root-project/root/blob/2cc4b70d2e2bd89d9b639c894b4e0558be47c22b/tree/tree/src/TChain.cxx#L1666. ### Reproducer. Rename to `recursiveBugDemo.C` and run the following macro: [recursiveBugDemo.txt](https://github.com/user-attachments/files/17593622/recursiveBugDemo.txt). It works similarly to #16804 and should only print `true`. ### ROOT version. Seen in:. * ROOT 6.30/04 (anaconda). * ROOT 6.28/04 (LCG 104). I couldn't find any code change in master in the relevant areas. ### Installation method. anaconda and LCG 104. ### Operating system. Linux (CentOS 9, Ubuntu 22.04, Ubuntu 24.04). ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16805
https://github.com/root-project/root/pull/16806:7,deployability,Integr,Integrate,7,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:369,deployability,Integr,Integrate,369,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:139,energy efficiency,draw,draw,139,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:199,energy efficiency,draw,draw,199,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:310,energy efficiency,draw,draw,310,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:7,integrability,Integr,Integrate,7,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:369,integrability,Integr,Integrate,369,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:7,interoperability,Integr,Integrate,7,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:369,interoperability,Integr,Integrate,369,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:7,modifiability,Integr,Integrate,7,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:369,modifiability,Integr,Integrate,369,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:7,reliability,Integr,Integrate,7,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:369,reliability,Integr,Integrate,369,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:430,safety,Test,Test,430,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:673,safety,Test,Test,673,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:747,safety,test,test,747,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:7,security,Integr,Integrate,7,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:369,security,Integr,Integrate,369,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:7,testability,Integr,Integrate,7,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:369,testability,Integr,Integrate,369,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:430,testability,Test,Test,430,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:673,testability,Test,Test,673,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:747,testability,test,test,747,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:237,usability,Support,Support,237,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:606,usability,user,user-attachments,606,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16806:860,usability,user,user-attachments,860,[reve] Integrate JSROOT TGeo geometry tessellation and hierarchy browser/table in REve; ## This PR introduces new functionality in REve to draw and browse TGeo geometry. * Use JSROOT tessellation to draw TGeo geometry in 3D REve Viewer. Support Three.js and RenderCore renderers. * Introduce REveGeoTopNode to draw TGeo geometry with given path and visibility level. * Integrate JSROOT geo hierarchy browser in REveGeo table. ### Test macro demonstrating geometry table and ReveGeoTopNode. The macro is located in `tutorials/eve7/eveGeoBrowser.C`. ![Screenshot from 2024-10-31 15-26-59](https://github.com/user-attachments/assets/b973c2ef-06b3-445c-80a5-a89aea9ec43b). ### Test macro demonstrating two REveGeoTopNodes without geometery table. The test macro is located in `tutorials/eve7geoTopNode.C`. ![Screenshot from 2024-10-31 15-30-55](https://github.com/user-attachments/assets/94d2dee0-0a97-4396-921a-bb7dd4494553),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16806
https://github.com/root-project/root/pull/16807:245,deployability,configurat,configuration,245,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:45,integrability,configur,configure,45,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:120,integrability,event,event,120,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:209,integrability,event,event,209,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:245,integrability,configur,configuration,245,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:300,integrability,configur,configured,300,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:351,integrability,batch,batch-mode,351,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:45,modifiability,configur,configure,45,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:245,modifiability,configur,configuration,245,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:300,modifiability,configur,configured,300,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:351,performance,batch,batch-mode,351,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:45,security,configur,configure,45,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:245,security,configur,configuration,245,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:300,security,configur,configured,300,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16807:463,usability,custom,customize-rootbrowse,463,Fix problem with rootbrowse in web mode; Let configure web display kind when running `rootbrowse`. More important - run event loop when web-based browser is started. In contrary to normal `TBrowser` one needs event loop running. Fix web-display configuration problem when `WebGui.Display: something` configured in rootrc file. In such case always web-batch-mode kind was selected. Addressing [question on forum](https://root-forum.cern.ch/t/is-there-an-option-to-customize-rootbrowse/62066/),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16807
https://github.com/root-project/root/pull/16808:92,integrability,event,event,92,"Fix rootbrowse problem in web mode [6.32]; If web mode enabled (via .rootrc parameter), run event loop. Correctly set web mode from .rootrc. Partial backport of #16807",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16808
https://github.com/root-project/root/pull/16808:76,modifiability,paramet,parameter,76,"Fix rootbrowse problem in web mode [6.32]; If web mode enabled (via .rootrc parameter), run event loop. Correctly set web mode from .rootrc. Partial backport of #16807",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16808
https://github.com/root-project/root/pull/16809:30,availability,Operat,Operators,30,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:123,availability,operat,operators,123,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:307,deployability,updat,updated,307,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:248,energy efficiency,model,models,248,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:233,safety,test,tests,233,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:277,safety,test,tested,277,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:307,safety,updat,updated,307,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:248,security,model,models,248,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:307,security,updat,updated,307,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:233,testability,test,tests,233,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:277,testability,test,tested,277,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16809:99,usability,support,support,99,[tmva][sofie] Add Sin and Cos Operators to SOFIE; # This Pull request:. This Pull request adds the support for Sin and Cos operators in SOFIE. ## Changes or fixes:. - Implemented the respective ROperator files. - Included respective tests and ONNX models. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16809
https://github.com/root-project/root/pull/16810:335,integrability,discover,discovered,335,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:335,interoperability,discover,discovered,335,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:77,modifiability,deco,decompression,77,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:204,modifiability,deco,decompression,204,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:409,modifiability,deco,decompression,409,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:68,performance,parallel,parallel,68,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:141,performance,memor,memory,141,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:195,performance,parallel,parallel,195,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:297,performance,memor,memory,297,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:400,performance,parallel,parallel,400,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:500,performance,memor,memory,500,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:141,usability,memor,memory,141,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:297,usability,memor,memory,297,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:335,usability,discov,discovered,335,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16810:500,usability,memor,memory,500,"[ntuple] fix IMT reading with type cast; Fixes reading in IMT mode (parallel decompression) of columns that are unpacked into non-default in-memory types. This has been a conceptional issue: the parallel decompression and the page pool were not aware, so far, of the possibility of non-default in-memory types of pages. The issues was discovered in IMT reading of `Double32_t` in CMS MiniAODs. Both, parallel decompression and the page pool are now fixed to handle non-default and multiple target in-memory types into which pages can be unsealed. The page pool will require more work. That's for a follow-up PR. Fixes #16815. @Dr15Jones FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16810
https://github.com/root-project/root/pull/16811:196,integrability,event,event,196,Implement `TBrowser::IsWeb()` method; Returns kTRUE if web-based browser is used. Works exactly the same way as `TWebCanvas::IsWeb()` - via TBrowserImp class. Use flag in `cmdLineUtils.py` to run event loop for web-based TBrowser. Also add check of `gROOT.IsInterrupted()` and `gSystem.ProcessEvents()` to break such event loop.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16811
https://github.com/root-project/root/pull/16811:317,integrability,event,event,317,Implement `TBrowser::IsWeb()` method; Returns kTRUE if web-based browser is used. Works exactly the same way as `TWebCanvas::IsWeb()` - via TBrowserImp class. Use flag in `cmdLineUtils.py` to run event loop for web-based TBrowser. Also add check of `gROOT.IsInterrupted()` and `gSystem.ProcessEvents()` to break such event loop.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16811
https://github.com/root-project/root/pull/16812:222,modifiability,variab,variable,222,[rootssh] export ROOT_WEBDISPLAY=server [skip-ci]; Exclude usage of local displays like `cef` or `qt6` on remote nodes . By default such displays are used before real http server is started . Therefore set explicitly such variable. Checked that rootssh from Linux to Mac is working.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16812
https://github.com/root-project/root/pull/16814:165,availability,down,downstream,165,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:238,availability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:89,deployability,API,API,89,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:153,deployability,API,API,153,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:238,deployability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:310,deployability,API,API,310,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:346,deployability,integr,integrating,346,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:396,deployability,infrastructur,infrastructure,396,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:524,deployability,patch,patches,524,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:89,integrability,API,API,89,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:153,integrability,API,API,153,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:238,integrability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:310,integrability,API,API,310,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:335,integrability,event,eventually,335,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:346,integrability,integr,integrating,346,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:89,interoperability,API,API,89,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:134,interoperability,compatib,compatibe,134,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:153,interoperability,API,API,153,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:310,interoperability,API,API,310,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:346,interoperability,integr,integrating,346,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:238,modifiability,servic,service,238,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:346,modifiability,integr,integrating,346,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:346,reliability,integr,integrating,346,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:524,safety,patch,patches,524,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:81,security,expos,exposes,81,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:346,security,integr,integrating,346,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:524,security,patch,patches,524,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:346,testability,integr,integrating,346,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:458,testability,simpl,simplify,458,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:157,usability,support,support,157,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:176,usability,tool,tools,176,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:195,usability,interact,interactive,195,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:453,usability,help,help,453,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/pull/16814:458,usability,simpl,simplify,458,"Enable CppInterOp; [CppInterOp](https://github.com/compiler-research/CppInterOp) exposes API from Clang and LLVM in a mostly backward compatibe way. The API support downstream tools that utilize interactive C++ by using the compiler as a service. This PR is the first step in using pure clang based reflection API in meta, and part of eventually integrating the JITCall and DynamicLibraryManager infrastructure. Adopting more of CppInterOp in ROOT will help simplify the LLVM migration process and allow us to upstream more patches to either CppInterOp or LLVM.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16814
https://github.com/root-project/root/issues/16815:458,availability,Operat,Operating,458,"[ntuple] Corruption reading `Double32_t` in IMT mode; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Found in IMT reading of MiniAODs: when reading `Double32_t`, RNTuple crashes overreading the page buffer. This happens because the page is filled with floats but the column expects to see doubles. ### Reproducer. Read data from a `Double32_t` field with IMT turned on. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16815
https://github.com/root-project/root/issues/16815:407,deployability,version,version,407,"[ntuple] Corruption reading `Double32_t` in IMT mode; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Found in IMT reading of MiniAODs: when reading `Double32_t`, RNTuple crashes overreading the page buffer. This happens because the page is filled with floats but the column expects to see doubles. ### Reproducer. Read data from a `Double32_t` field with IMT turned on. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16815
https://github.com/root-project/root/issues/16815:428,deployability,Instal,Installation,428,"[ntuple] Corruption reading `Double32_t` in IMT mode; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Found in IMT reading of MiniAODs: when reading `Double32_t`, RNTuple crashes overreading the page buffer. This happens because the page is filled with floats but the column expects to see doubles. ### Reproducer. Read data from a `Double32_t` field with IMT turned on. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16815
https://github.com/root-project/root/issues/16815:227,integrability,buffer,buffer,227,"[ntuple] Corruption reading `Double32_t` in IMT mode; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Found in IMT reading of MiniAODs: when reading `Double32_t`, RNTuple crashes overreading the page buffer. This happens because the page is filled with floats but the column expects to see doubles. ### Reproducer. Read data from a `Double32_t` field with IMT turned on. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16815
https://github.com/root-project/root/issues/16815:407,integrability,version,version,407,"[ntuple] Corruption reading `Double32_t` in IMT mode; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Found in IMT reading of MiniAODs: when reading `Double32_t`, RNTuple crashes overreading the page buffer. This happens because the page is filled with floats but the column expects to see doubles. ### Reproducer. Read data from a `Double32_t` field with IMT turned on. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16815
https://github.com/root-project/root/issues/16815:407,modifiability,version,version,407,"[ntuple] Corruption reading `Double32_t` in IMT mode; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Found in IMT reading of MiniAODs: when reading `Double32_t`, RNTuple crashes overreading the page buffer. This happens because the page is filled with floats but the column expects to see doubles. ### Reproducer. Read data from a `Double32_t` field with IMT turned on. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16815
https://github.com/root-project/root/issues/16815:496,testability,context,context,496,"[ntuple] Corruption reading `Double32_t` in IMT mode; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. Found in IMT reading of MiniAODs: when reading `Double32_t`, RNTuple crashes overreading the page buffer. This happens because the page is filled with floats but the column expects to see doubles. ### Reproducer. Read data from a `Double32_t` field with IMT turned on. ### ROOT version. master. ### Installation method. n/a. ### Operating system. n/a. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16815
https://github.com/root-project/root/pull/16816:27,interoperability,convers,conversion,27,"[CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; The `IsCTypesArrayOrPointer` gives false positives in Python 3.13, resulting the void pointer converter to take the wrong code path and crash. See:. https://github.com/wlav/cppyy/issues/272. This code path is used for implicit conversion from other `ctypes` pointer types to `void*`, which is not strictly required. One can always do an explicit cast: `ctypes.cast(my_ptr, ctypes.c_void_p )`. Given that this a niche feature that broke Python 3.13 support for functions taking `void*`, which is quite common, it can be argued that it's better to remove this implicit conversion. This commit fixes the following tests under Python 3.13:. ```. roottest-python-basic-datatype. roottest-python-cpp-cpp. ```. This reverts the following commit from upstream:. https://github.com/wlav/CPyCppyy/commit/80a0205f590394b88a583a296704356a9740606f. See also the Fedora 41 CI PR:. https://github.com/root-project/root/pull/16748.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16816
https://github.com/root-project/root/pull/16816:300,interoperability,convers,conversion,300,"[CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; The `IsCTypesArrayOrPointer` gives false positives in Python 3.13, resulting the void pointer converter to take the wrong code path and crash. See:. https://github.com/wlav/cppyy/issues/272. This code path is used for implicit conversion from other `ctypes` pointer types to `void*`, which is not strictly required. One can always do an explicit cast: `ctypes.cast(my_ptr, ctypes.c_void_p )`. Given that this a niche feature that broke Python 3.13 support for functions taking `void*`, which is quite common, it can be argued that it's better to remove this implicit conversion. This commit fixes the following tests under Python 3.13:. ```. roottest-python-basic-datatype. roottest-python-cpp-cpp. ```. This reverts the following commit from upstream:. https://github.com/wlav/CPyCppyy/commit/80a0205f590394b88a583a296704356a9740606f. See also the Fedora 41 CI PR:. https://github.com/root-project/root/pull/16748.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16816
https://github.com/root-project/root/pull/16816:640,interoperability,convers,conversion,640,"[CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; The `IsCTypesArrayOrPointer` gives false positives in Python 3.13, resulting the void pointer converter to take the wrong code path and crash. See:. https://github.com/wlav/cppyy/issues/272. This code path is used for implicit conversion from other `ctypes` pointer types to `void*`, which is not strictly required. One can always do an explicit cast: `ctypes.cast(my_ptr, ctypes.c_void_p )`. Given that this a niche feature that broke Python 3.13 support for functions taking `void*`, which is quite common, it can be argued that it's better to remove this implicit conversion. This commit fixes the following tests under Python 3.13:. ```. roottest-python-basic-datatype. roottest-python-cpp-cpp. ```. This reverts the following commit from upstream:. https://github.com/wlav/CPyCppyy/commit/80a0205f590394b88a583a296704356a9740606f. See also the Fedora 41 CI PR:. https://github.com/root-project/root/pull/16748.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16816
https://github.com/root-project/root/pull/16816:684,safety,test,tests,684,"[CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; The `IsCTypesArrayOrPointer` gives false positives in Python 3.13, resulting the void pointer converter to take the wrong code path and crash. See:. https://github.com/wlav/cppyy/issues/272. This code path is used for implicit conversion from other `ctypes` pointer types to `void*`, which is not strictly required. One can always do an explicit cast: `ctypes.cast(my_ptr, ctypes.c_void_p )`. Given that this a niche feature that broke Python 3.13 support for functions taking `void*`, which is quite common, it can be argued that it's better to remove this implicit conversion. This commit fixes the following tests under Python 3.13:. ```. roottest-python-basic-datatype. roottest-python-cpp-cpp. ```. This reverts the following commit from upstream:. https://github.com/wlav/CPyCppyy/commit/80a0205f590394b88a583a296704356a9740606f. See also the Fedora 41 CI PR:. https://github.com/root-project/root/pull/16748.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16816
https://github.com/root-project/root/pull/16816:684,testability,test,tests,684,"[CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; The `IsCTypesArrayOrPointer` gives false positives in Python 3.13, resulting the void pointer converter to take the wrong code path and crash. See:. https://github.com/wlav/cppyy/issues/272. This code path is used for implicit conversion from other `ctypes` pointer types to `void*`, which is not strictly required. One can always do an explicit cast: `ctypes.cast(my_ptr, ctypes.c_void_p )`. Given that this a niche feature that broke Python 3.13 support for functions taking `void*`, which is quite common, it can be argued that it's better to remove this implicit conversion. This commit fixes the following tests under Python 3.13:. ```. roottest-python-basic-datatype. roottest-python-cpp-cpp. ```. This reverts the following commit from upstream:. https://github.com/wlav/CPyCppyy/commit/80a0205f590394b88a583a296704356a9740606f. See also the Fedora 41 CI PR:. https://github.com/root-project/root/pull/16748.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16816
https://github.com/root-project/root/pull/16816:521,usability,support,support,521,"[CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; The `IsCTypesArrayOrPointer` gives false positives in Python 3.13, resulting the void pointer converter to take the wrong code path and crash. See:. https://github.com/wlav/cppyy/issues/272. This code path is used for implicit conversion from other `ctypes` pointer types to `void*`, which is not strictly required. One can always do an explicit cast: `ctypes.cast(my_ptr, ctypes.c_void_p )`. Given that this a niche feature that broke Python 3.13 support for functions taking `void*`, which is quite common, it can be argued that it's better to remove this implicit conversion. This commit fixes the following tests under Python 3.13:. ```. roottest-python-basic-datatype. roottest-python-cpp-cpp. ```. This reverts the following commit from upstream:. https://github.com/wlav/CPyCppyy/commit/80a0205f590394b88a583a296704356a9740606f. See also the Fedora 41 CI PR:. https://github.com/root-project/root/pull/16748.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16816
https://github.com/root-project/root/pull/16817:220,interoperability,distribut,distribution,220,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:404,interoperability,distribut,distribution,404,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:9,modifiability,Paramet,Parameter,9,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:179,modifiability,paramet,parameter,179,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:377,modifiability,paramet,parameters,377,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:19,usability,Document,Documentation,19,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:147,usability,document,documentation,147,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:252,usability,clarit,clarity,252,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:264,usability,usab,usability,264,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16817:285,usability,user,users,285,"Improved Parameter Documentation for Johnson and CBShape Classes with Added Images; The original ROOT CBShape and Johnson classes provided limited documentation on the effects of parameter variations on their respective distribution shapes. To improve clarity and usability for future users of these RooFit classes, I conducted a detailed study illustrating how changes in key parameters influence these distribution shapes. .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16817
https://github.com/root-project/root/pull/16818:54,deployability,updat,update,54,Comply to deprecations announced in the 6.32 RNs; and update the list of deprecations in the 6.36 RNs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16818
https://github.com/root-project/root/pull/16818:0,safety,Compl,Comply,0,Comply to deprecations announced in the 6.32 RNs; and update the list of deprecations in the 6.36 RNs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16818
https://github.com/root-project/root/pull/16818:54,safety,updat,update,54,Comply to deprecations announced in the 6.32 RNs; and update the list of deprecations in the 6.36 RNs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16818
https://github.com/root-project/root/pull/16818:0,security,Compl,Comply,0,Comply to deprecations announced in the 6.32 RNs; and update the list of deprecations in the 6.36 RNs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16818
https://github.com/root-project/root/pull/16818:54,security,updat,update,54,Comply to deprecations announced in the 6.32 RNs; and update the list of deprecations in the 6.36 RNs.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16818
https://github.com/root-project/root/pull/16819:281,availability,monitor,monitor,281,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:205,deployability,log,log,205,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:281,deployability,monitor,monitor,281,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:454,deployability,log,log,454,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:281,energy efficiency,monitor,monitor,281,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:23,interoperability,socket,sockets,23,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:64,interoperability,socket,sockets,64,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:180,interoperability,socket,socketfile,180,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:194,interoperability,socket,socketfile,194,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:223,interoperability,socket,socket,223,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:299,performance,content,content,299,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:281,reliability,monitor,monitor,281,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:205,safety,log,log,205,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:281,safety,monitor,monitor,281,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:454,safety,log,log,454,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:23,security,soc,sockets,23,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:64,security,soc,sockets,64,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:142,security,soc,socat,142,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:180,security,soc,socketfile,180,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:194,security,soc,socketfile,194,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:205,security,log,log,205,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:223,security,soc,socket,223,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:454,security,log,log,454,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:205,testability,log,log,205,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:281,testability,monitor,monitor,281,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:454,testability,log,log,454,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16819:334,usability,command,command,334,[rootssh] improve unix sockets handling; On the MacOS same unix sockets cannot be opened twice for listening - . when using with `netcat` or `socat`. Therefore start `nc -k -l -U $socketfile > $socketfile.log` to redirect. socket output into the plain file permanently. . And then monitor this file content - line by line. Use `trap` command to cleanup all temporary files afterwards. And from ROOT side need to send `\n` to ensure new lines in produced log file. This changes required to be able use `rootssh` from the MacOS,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16819
https://github.com/root-project/root/pull/16820:296,availability,monitor,monitor,296,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:223,deployability,log,log,223,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:296,deployability,monitor,monitor,296,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:465,deployability,log,log,465,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:296,energy efficiency,monitor,monitor,296,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:23,interoperability,socket,sockets,23,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:88,interoperability,socket,sockets,88,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:198,interoperability,socket,socketfile,198,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:212,interoperability,socket,socketfile,212,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:240,interoperability,socket,socket,240,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:314,performance,content,content,314,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:296,reliability,monitor,monitor,296,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:223,safety,log,log,223,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:296,safety,monitor,monitor,296,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:465,safety,log,log,465,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:23,security,soc,sockets,23,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:88,security,soc,sockets,88,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:162,security,soc,socat,162,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:198,security,soc,socketfile,198,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:212,security,soc,socketfile,212,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:223,security,log,log,223,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:240,security,soc,socket,240,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:465,security,log,log,465,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:223,testability,log,log,223,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:296,testability,monitor,monitor,296,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:465,testability,log,log,465,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16820:347,usability,command,command,347,[rootssh] improve unix sockets handling [6.34]; Backport #16819. On the MacOS same unix sockets cannot be opened twice for listening -. when using with netcat or socat. Therefore start nc -k -l -U $socketfile > $socketfile.log to redirect. socket output into the plain file permanently. And then monitor this file content - line by line. Use trap command to cleanup all temporary files afterwards. And from ROOT side need to send \n to ensure new lines in produced log file. This changes required to be able use rootssh from the MacOS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16820
https://github.com/root-project/root/pull/16821:109,deployability,releas,release,109,"[RF] Remove the deprecated RooFit code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16821
https://github.com/root-project/root/pull/16821:207,deployability,releas,release,207,"[RF] Remove the deprecated RooFit code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16821
https://github.com/root-project/root/pull/16821:290,deployability,releas,release,290,"[RF] Remove the deprecated RooFit code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16821
https://github.com/root-project/root/pull/16821:239,energy efficiency,current,current,239,"[RF] Remove the deprecated RooFit code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16821
https://github.com/root-project/root/pull/16821:127,usability,indicat,indicated,127,"[RF] Remove the deprecated RooFit code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16821
https://github.com/root-project/root/pull/16822:115,deployability,releas,release,115,"[TPython] Remove the deprecated TPython code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16822
https://github.com/root-project/root/pull/16822:213,deployability,releas,release,213,"[TPython] Remove the deprecated TPython code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16822
https://github.com/root-project/root/pull/16822:296,deployability,releas,release,296,"[TPython] Remove the deprecated TPython code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16822
https://github.com/root-project/root/pull/16822:245,energy efficiency,current,current,245,"[TPython] Remove the deprecated TPython code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16822
https://github.com/root-project/root/pull/16822:133,usability,indicat,indicated,133,"[TPython] Remove the deprecated TPython code to be removed in ROOT 6.36; Execute on what was announced in the 6.34 release notes and indicated by deprecation macros and doxygen tags. As ROOT 6.36 will be the next release after ROOT 6.34 and the current `master` branch is leading up to that next release, the code should be removed now.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16822
https://github.com/root-project/root/pull/16823:33,interoperability,convers,conversion,33,[v634][CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; Backport of #16816.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16823
https://github.com/root-project/root/pull/16824:33,interoperability,convers,conversion,33,[v634][CPyCppyy] Remove implicit conversion of any ctypes ptr type to `void*`; Backport of https://github.com/root-project/root/pull/16816.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16824
https://github.com/root-project/root/pull/16825:337,deployability,updat,updated,337,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/pull/16825:49,interoperability,XML,XML,49,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/pull/16825:184,safety,valid,valid,184,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/pull/16825:307,safety,test,tested,307,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/pull/16825:337,safety,updat,updated,337,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/pull/16825:337,security,updat,updated,337,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/pull/16825:307,testability,test,tested,307,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/pull/16825:237,usability,support,support,237,"[ntuple] forbid creating a RNTupleWriter with an XML TFile; RMiniFile only knows how to write into proper ROOT files. . I went with the blacklist approach because there are a bunch of valid cases that are not just TFiles that we want to support (e.g. TMemFile, TBufferMergerFile, ...). ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16825
https://github.com/root-project/root/issues/16826:558,availability,ERROR,ERROR,558,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1095,availability,ERROR,ERROR,1095,"roject/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1342,availability,ERROR,ERROR,1342," read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1824,availability,avail,available,1824,"RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1869,availability,ERROR,ERROR,1869,"_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NUL",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2518,availability,ERROR,ERROR,2518,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2930,availability,ERROR,ERROR,2930,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3010,availability,ERROR,ERROR,3010,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3106,availability,ERROR,ERROR,3106,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3153,availability,error,errors,3153,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:845,deployability,build,build,845,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:890,deployability,build,build,890,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1047,deployability,contain,container,1047,"s is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, co",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1610,deployability,fail,failed,1610," over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2284,deployability,fail,failed,2284,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2534,deployability,fail,failed,2534,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2807,deployability,fail,failed,2807,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3062,deployability,fail,failed,3062,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:398,integrability,event,event,398,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:489,integrability,messag,messages,489,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:989,integrability,Event,EventData,989,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1018,integrability,Event,EventInfo,1018,"ld iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::Pool",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1170,integrability,Event,EventData,1170,", see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::ba",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1199,integrability,Event,EventInfo,1199,"-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1441,integrability,Event,EventData,1441,"eading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][O",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1470,integrability,Event,EventInfo,1470,"ld, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-000009770",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1672,integrability,Event,EventData,1672," 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CA",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1701,integrability,Event,EventInfo,1701,":Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2243,integrability,Event,EventInfo,2243,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2346,integrability,Event,EventData,2346,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2375,integrability,Event,EventInfo,2375,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2614,integrability,Event,EventData,2614,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2643,integrability,Event,EventInfo,2643,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2839,integrability,Event,EventInfo,2839,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2955,integrability,Event,Event,2955,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3124,integrability,event,event,3124,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:489,interoperability,messag,messages,489,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2796,interoperability,convers,conversion,2796,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:558,performance,ERROR,ERROR,558,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1095,performance,ERROR,ERROR,1095,"roject/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1342,performance,ERROR,ERROR,1342," read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1869,performance,ERROR,ERROR,1869,"_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NUL",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2518,performance,ERROR,ERROR,2518,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2930,performance,ERROR,ERROR,2930,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3010,performance,ERROR,ERROR,3010,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3106,performance,ERROR,ERROR,3106,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3153,performance,error,errors,3153,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1610,reliability,fail,failed,1610," over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1824,reliability,availab,available,1824,"RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2284,reliability,fail,failed,2284,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2534,reliability,fail,failed,2534,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2807,reliability,fail,failed,2807,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3062,reliability,fail,failed,3062,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:558,safety,ERROR,ERROR,558,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1095,safety,ERROR,ERROR,1095,"roject/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1342,safety,ERROR,ERROR,1342," read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1589,safety,Except,Exception,1589,"ce> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1824,safety,avail,available,1824,"RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1869,safety,ERROR,ERROR,1869,"_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NUL",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1894,safety,except,exception,1894,"jects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1952,safety,except,exception,1952,"ew.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Ev",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2518,safety,ERROR,ERROR,2518,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2930,safety,ERROR,ERROR,2930,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3010,safety,ERROR,ERROR,3010,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3106,safety,ERROR,ERROR,3106,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3153,safety,error,errors,3153,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1387,security,Token,Token,1387,"y first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLI",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1618,security,Token,Token,1618,"pty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventDa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1824,security,availab,available,1824,"RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2056,security,Token,Token,2056,"ee/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2292,security,Token,Token,2292,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2560,security,Token,Token,2560,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2784,security,access,accessData,2784,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3044,testability,context,context,3044,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:167,usability,workflow,workflow,167,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:294,usability,workflow,workflow,294,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:558,usability,ERROR,ERROR,558,"RNTuple unexpected ""field iteration over empty fields is unsupported""; . https://github.com/root-project/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1095,usability,ERROR,ERROR,1095,"roject/root/pull/16768 seems to have unexpected consequence on ATLAS workflow, see https://github.com/root-project/root/pull/16768#discussion_r1829743338. Per @amete :. > This is in a mutli-chain workflow. The first step creates an RNTuple that is read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1342,usability,ERROR,ERROR,1342," read by the second step. We throw on the very first event of the second step, seemingly related to reading an empty top-level field, e.g. (the messages need to be improved but that's independent):. ```. 12:37:41 ERROR (pool):. 12:37:41 Unknown Source> field iteration over empty fields is unsupported: xAOD__EventInfo_v1_EventInfo. 12:37:41 At:. 12:37:41 ROOT::Experimental::RNTupleGlobalRange ROOT::Experimental::Internal::GetFieldRange(const ROOT::Experimental::RFieldBase&, const RPageSource&) [/build/jenkins/workspace/lcg_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1869,usability,ERROR,ERROR,1869,"_nightly_pipeline/build/projects/ROOT-HEAD/src/ROOT/HEAD/tree/ntuple/v7/src/RNTupleView.cxx:42]. 12:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NUL",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:1965,usability,Statu,StatusCode,1965,"2:37:41 . 12:37:41 EventData(xAOD::EventInfo_v1/EventInfo)> Cannot open ROOT container(Tree/Branch). 12:37:41 StorageSvc 0 0 ERROR Could not read object: [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root obje",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2518,usability,ERROR,ERROR,2518,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:2930,usability,ERROR,ERROR,2930,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3010,usability,ERROR,ERROR,3010,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3106,usability,ERROR,ERROR,3106,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/issues/16826:3153,usability,error,errors,3153,"CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR poolToObject: Could not get object for Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 Exception: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000] (no backtrace available). 12:37:41 AthenaPoolConverter 0 0 ERROR createObj - caught exception: AthenaPoolCnvSvc::::ExcCaughtException: Caught exception in StatusCode T_AthenaPoolCustomCnvWithKey<TRANS, PERS>::PoolToDataObject(DataObject*&, const Token*, const std::string&) [with TRANS = xAOD::EventInfo_v1; PERS = xAOD::EventInfo_v1; std::string = std::__cxx11::basic_string<char>] while creating transient objectxAOD::EventInfo_v1/EventInfo: std::runtime_error: POOL read failed. Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 AthenaPoolConverter 0 0 ERROR createObj failed to get DataObject, Token = [DB=7316ACAF-6478-5C4A-B7E8-29498AC3D2AB][CNT=EventData(xAOD::EventInfo_v1/EventInfo)][CLID=AE8BED6D-1D41-4CAF-994B-42613FC91A0A][TECH=00000205][OID=0000097700000026-0000097700000000]. 12:37:41 DataProxy 0 0 WARNING accessData: conversion failed for data object 45903698/EventInfo. 12:37:41 Returning NULL DataObject pointer. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Unable to retrieve Event root object. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR declareEventRootAddress for context s: 0 e: 0 failed. 12:37:41 AthenaHiveEventLoopMgr 0 0 ERROR Terminating event processing loop due to errors. ``` .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16826
https://github.com/root-project/root/pull/16828:30,usability,document,document,30,[skip-ci][v6.34][NFC][ntuple] document default RNTupleWriteOptions; Backport of #16745 .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16828
https://github.com/root-project/root/pull/16829:209,availability,error,error,209,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:352,deployability,log,log,352,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:434,deployability,Updat,Updates,434,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:165,integrability,filter,filter,165,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:215,integrability,messag,messages,215,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:356,integrability,messag,messages,356,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:215,interoperability,messag,messages,215,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:356,interoperability,messag,messages,356,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:209,performance,error,error,209,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:209,safety,error,error,209,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:297,safety,valid,validator,297,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:345,safety,Review,Review,345,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:352,safety,log,log,352,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:434,safety,Updat,Updates,434,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:297,security,validat,validator,297,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:352,security,log,log,352,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:434,security,Updat,Updates,434,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:119,testability,context,context,119,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:345,testability,Review,Review,345,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:352,testability,log,log,352,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16829:209,usability,error,error,209,[reve] Fix axis labels in 3D and projected views; ### This Pull request:. * Fix axis labels . * CaloTower selection in context of REveDataCollection when collection filter is applied. * Fix client's duplicate error messages from server. * Minor correction in Summary view layout. * Add expression validator for new column expression in table. * Review log messages. * Introduce HttpPublic option which disable usage of RFileDialog. * Updates REnderCore with fixes in font renderin. From verion 1.5 to 1.6.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16829
https://github.com/root-project/root/pull/16830:21,energy efficiency,Core,Core,21,"TPython, Geo, RF and Core removal of deprecated components; Superseeds https://github.com/root-project/root/pull/16822. Sister PR in roottest: https://github.com/root-project/roottest/pull/1212",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16830
https://github.com/root-project/root/pull/16830:48,integrability,compon,components,48,"TPython, Geo, RF and Core removal of deprecated components; Superseeds https://github.com/root-project/root/pull/16822. Sister PR in roottest: https://github.com/root-project/roottest/pull/1212",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16830
https://github.com/root-project/root/pull/16830:48,interoperability,compon,components,48,"TPython, Geo, RF and Core removal of deprecated components; Superseeds https://github.com/root-project/root/pull/16822. Sister PR in roottest: https://github.com/root-project/roottest/pull/1212",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16830
https://github.com/root-project/root/pull/16830:48,modifiability,compon,components,48,"TPython, Geo, RF and Core removal of deprecated components; Superseeds https://github.com/root-project/root/pull/16822. Sister PR in roottest: https://github.com/root-project/roottest/pull/1212",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16830
https://github.com/root-project/root/pull/16832:229,deployability,fail,fails,229,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16832:264,deployability,fail,fail,264,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16832:180,energy efficiency,Current,Currently,180,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16832:229,reliability,fail,fails,229,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16832:264,reliability,fail,fail,264,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16832:27,safety,valid,validity,27,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16832:44,security,access,access,44,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16832:296,security,access,access,296,"[ntuple] check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Fixes #16826 . @amete FYI.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16832
https://github.com/root-project/root/pull/16833:235,deployability,fail,fails,235,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/pull/16833:270,deployability,fail,fail,270,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/pull/16833:186,energy efficiency,Current,Currently,186,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/pull/16833:235,reliability,fail,fails,235,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/pull/16833:270,reliability,fail,fail,270,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/pull/16833:33,safety,valid,validity,33,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/pull/16833:50,security,access,access,50,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/pull/16833:302,security,access,access,302,"[v634][ntuple] Check field range validity only on access; The field range of a view is determined on construction. If the field is empty (no columns), the field range remains undefined. Currently, in this case the creation of the view fails. Change this to instead only fail on the attempt to actually access the field range (as opposed to, e.g., iterate over the entry range of the empty field). Backport of #16832 . Fixes #16826 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16833
https://github.com/root-project/root/issues/16834:554,availability,Operat,Operating,554,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:285,deployability,contain,containing,285,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:506,deployability,version,version,506,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:524,deployability,Instal,Installation,524,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:237,energy efficiency,current,currently,237,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:506,integrability,version,version,506,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:506,modifiability,version,version,506,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:20,reliability,doe,does,20,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:151,reliability,doe,doesn,151,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:37,safety,valid,valid,37,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:214,safety,valid,valid,214,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/issues/16834:592,testability,context,context,592,"`RFieldBase::Clone` does not enforce valid field names; ### Check duplicate issues. - [X] Checked for duplicates. ### Description. `RFieldBase::Clone` doesn't check whether the provided name of the cloned field is valid. This means that currently, it is possible to create field names containing dots in this way. ### Reproducer. ```cpp. auto field = RFieldBase::Create(""x"", ""float"").Unwrap();. auto clonedField = field->Clone(""x.y"");. std::cout << clonedField->GetFieldName() << std::endl;. ```. ### ROOT version. any. ### Installation method. any. ### Operating system. any. ### Additional context. _No response_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/16834
https://github.com/root-project/root/pull/16835:12,deployability,releas,release,12,Delete v636 release notes [v6.34]; They should not be part of the `v6-34-00-patches` branch. This reverts commit 24da4ed1e3e03203cf6dcaf9c3d1c26a66c3eccc.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16835
https://github.com/root-project/root/pull/16835:76,deployability,patch,patches,76,Delete v636 release notes [v6.34]; They should not be part of the `v6-34-00-patches` branch. This reverts commit 24da4ed1e3e03203cf6dcaf9c3d1c26a66c3eccc.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16835
https://github.com/root-project/root/pull/16835:76,safety,patch,patches,76,Delete v636 release notes [v6.34]; They should not be part of the `v6-34-00-patches` branch. This reverts commit 24da4ed1e3e03203cf6dcaf9c3d1c26a66c3eccc.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16835
https://github.com/root-project/root/pull/16835:76,security,patch,patches,76,Delete v636 release notes [v6.34]; They should not be part of the `v6-34-00-patches` branch. This reverts commit 24da4ed1e3e03203cf6dcaf9c3d1c26a66c3eccc.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16835
https://github.com/root-project/root/pull/16836:197,deployability,contain,containing,197,"[ntuple] Enforce valid field names when cloning fields; `RFieldBase::Clone` currently doesn't check whether the provided name of the cloned field is valid, making it possible to create field names containing dots in this way. Fixes #16834 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16836
https://github.com/root-project/root/pull/16836:76,energy efficiency,current,currently,76,"[ntuple] Enforce valid field names when cloning fields; `RFieldBase::Clone` currently doesn't check whether the provided name of the cloned field is valid, making it possible to create field names containing dots in this way. Fixes #16834 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16836
https://github.com/root-project/root/pull/16836:86,reliability,doe,doesn,86,"[ntuple] Enforce valid field names when cloning fields; `RFieldBase::Clone` currently doesn't check whether the provided name of the cloned field is valid, making it possible to create field names containing dots in this way. Fixes #16834 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16836
https://github.com/root-project/root/pull/16836:17,safety,valid,valid,17,"[ntuple] Enforce valid field names when cloning fields; `RFieldBase::Clone` currently doesn't check whether the provided name of the cloned field is valid, making it possible to create field names containing dots in this way. Fixes #16834 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16836
https://github.com/root-project/root/pull/16836:149,safety,valid,valid,149,"[ntuple] Enforce valid field names when cloning fields; `RFieldBase::Clone` currently doesn't check whether the provided name of the cloned field is valid, making it possible to create field names containing dots in this way. Fixes #16834 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16836
https://github.com/root-project/root/pull/16837:81,availability,failur,failures,81,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:27,deployability,log,logic,27,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:81,deployability,fail,failures,81,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:9,performance,memor,memory,9,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:81,performance,failur,failures,81,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:81,reliability,fail,failures,81,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:27,safety,log,logic,27,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:27,security,log,logic,27,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:0,testability,Simpl,Simplify,0,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:27,testability,log,logic,27,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:0,usability,Simpl,Simplify,0,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
https://github.com/root-project/root/pull/16837:9,usability,memor,memory,9,"Simplify memory regulation logic; With *all* these changes, I do not see anymore failures in a local run with the ubuntu 24.10 CI image. let's see if the rest of the CI agrees. Note that one of the changes is equivalent to https://github.com/root-project/root/pull/16671",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/16837
