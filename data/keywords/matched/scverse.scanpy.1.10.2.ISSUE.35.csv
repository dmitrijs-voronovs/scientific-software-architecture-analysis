id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2993:16596,testability,test,testing,16596,py/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16652,testability,test,tests,16652,residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16803,testability,test,testing,16803,OR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16859,testability,test,tests,16859,earson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17008,testability,test,testing,17008,ion). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' f,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17064,testability,test,tests,17064,rmalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17213,testability,test,testing,17213,ation). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' fro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17269,testability,test,tests,17269,normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ER,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17418,testability,test,testing,17418,ocation). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=Non,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17474,testability,test,tests,17474,t_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 's,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17623,testability,test,testing,17623, location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17679,testability,test,tests,17679,est_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17821,testability,test,testing,17821, (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17877,testability,test,tests,17877,ion.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18024,testability,test,testing,18024,a' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-i,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18080,testability,test,tests,18080,ation.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18227,testability,test,testing,18227,ata' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1],MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18283,testability,test,tests,18283,ization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18483,testability,test,testing,18483,rmalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18539,testability,test,tests,18539,[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18690,testability,test,testing,18690,alization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18746,testability,test,tests,18746,[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18897,testability,test,testing,18897,.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERR,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18953,testability,test,tests,18953,t64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19104,testability,test,testing,19104,:test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19160,testability,test,tests,19160,theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportEr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19289,testability,test,testing,19289,_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::tes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19345,testability,test,tests,19345,ors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: canno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19486,testability,test,testing,19486,._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_ne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19542,testability,test,tests,19542,test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19671,testability,test,testing,19671,' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19727,testability,test,tests,19727,). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19855,testability,test,testing,19855,not import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarra,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19911,testability,test,tests,19911,data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20033,testability,test,testing,20033,vg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20089,testability,test,tests,20089,rom 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20210,testability,test,testing,20210,doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/te,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20266,testability,test,tests,20266,bmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20385,testability,test,testing,20385,[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unk,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20441,testability,test,tests,20441,cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20558,testability,test,testing,20558,py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' f,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20614,testability,test,tests,20614,mportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20731,testability,test,testing,20731,st_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - Imp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20787,testability,test,tests,20787,-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20938,testability,test,testing,20938,rublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20994,testability,test,tests,20994, import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21150,testability,test,testing,21150, ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21206,testability,test,tests,21206,.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21362,testability,test,testing,21362,mc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21418,testability,test,tests,21418,tion). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21574,testability,test,testing,21574,a' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21630,testability,test,tests,21630,.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21786,testability,test,testing,21786,ts/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - Impor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21842,testability,test,tests,21842,als_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21998,testability,test,testing,21998,st_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError:,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22054,testability,test,tests,22054,ca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._help,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22210,testability,test,testing,22210,st_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22266,testability,test,tests,22266,ca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.dat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22422,testability,test,testing,22422,st_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22478,testability,test,tests,22478,ca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unk,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22634,testability,test,testing,22634,st_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22690,testability,test,tests,22690,ca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown loca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22839,testability,test,testing,22839,ests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22895,testability,test,tests,22895,duals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown locati,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23044,testability,test,testing,23044,canpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23100,testability,test,tests,23100,on_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23249,testability,test,testing,23249,ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23305,testability,test,tests,23305,e_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23454,testability,test,testing,23454,tion). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23510,testability,test,tests,23510,ormalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). E,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23657,testability,test,testing,23657,nown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23713,testability,test,tests,23713,y::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown locatio,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23860,testability,test,testing,23860,nknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23916,testability,test,tests,23916,.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown lo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24063,testability,test,testing,24063,"(unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24119,testability,test,tests,24119,"on.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ======================================================",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24266,testability,test,testing,24266,"' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24322,testability,test,tests,24322,"tion.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24469,testability,test,testing,24469,"ta' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24525,testability,test,tests,24525,"zation.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24677,testability,test,testing,24677,"unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24733,testability,test,tests,24733,"n.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24885,testability,test,testing,24885,"wn location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:25204,testability,test,test,25204,"00] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.1 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.4.1 pypi_0 pypi. dask-expr 1.0.10 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:25993,testability,coverag,coverage,25993," 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.1 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.4.1 pypi_0 pypi. dask-expr 1.0.10 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pypi_0 pypi. fonttools 4.51.0 pypi_0 pypi. fsspec 2024.3.1 pypi_0 pypi. h5py 3.10.0 pypi_0 pypi. identify 2.5.35 pypi_0 pypi. igraph 0.11.4 pypi_0 pypi. imageio 2.34.0 pypi_0 pypi. iniconfig 2.0.0 pypi_0 pypi. joblib 1.4.0 pypi_0 pypi. kiwisolver 1.4.5 pypi_0 pypi. lazy-loader 0.4 pypi_0 pypi. ld_impl_linux-64 2.40 h41732ed_0 conda-forge. legacy-api-wrap 1.4 pypi_0 pypi. leidenalg 0.10.2 pypi_0 pypi. libexpat 2.6.2 h59595ed_0 conda-forge. libffi 3.4.2 h7f98852_5 conda-forge. libgcc-ng 13.2.0 h807b86a_5 conda-forge. libgomp 13.2.0 h807b86a_5 conda-forge. libnsl 2.0.1 hd590300_0 conda-forge. libsqlite 3.45.2 h2797004_0 conda-forge. libuuid 2.38.1 h0b41bf4_0 conda-forge. libxcrypt 4.4.36 hd590300_1 conda-forge. libzlib 1.2.13 hd590300_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:27746,testability,mock,mock,27746,5 conda-forge. libnsl 2.0.1 hd590300_0 conda-forge. libsqlite 3.45.2 h2797004_0 conda-forge. libuuid 2.38.1 h0b41bf4_0 conda-forge. libxcrypt 4.4.36 hd590300_1 conda-forge. libzlib 1.2.13 hd590300_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1.0.0 pypi_0 pypi. matplotlib 3.8.4 pypi_0 pypi. natsort 8.4.0 pypi_0 pypi. ncurses 6.4.20240210 h59595ed_0 conda-forge. networkx 3.3 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.1 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd590300_1 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.3.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pyarrow 15.0.2 pypi_0 pypi. pynndescent 0.5.12 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 7.4.4 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bda,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:29358,testability,coverag,coverage,29358,0.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. <details>. <summary> My failing env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.1 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.4.1 pypi_0 pypi. dask-expr 1.0.10 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pypi_0 pypi. fonttools 4.51.0 pypi_0 pypi. fsspec 2024.3.1 pypi_0 pypi. h5py 3.10.0 pypi_0 pypi. identify 2.5.35 pypi_0 pypi. igraph 0.11.4 pypi_0 pypi. imageio 2.34.0 pypi_0 pypi. iniconfig 2.0.0 pypi_0 pypi. joblib 1.4.0 pypi_0 pypi. kiwisolver 1.4.5 pypi_0 pypi. lazy-loader 0.4 pypi_0 pypi. ld_impl_linux-64 2.40 h41732ed_0 conda-forge. legacy-api-wrap 1.4 pypi_0 pypi. leidenalg 0.10.2 pypi_0 pypi. libexpat 2.6.2 h59595ed_0 conda-forge. libffi 3.4.2 h7f98852_5 conda-forge. libgcc-ng 13.2.0 h807b86a_5 conda-forge. libgomp 13.2.0 h807b86a_5 conda-forge. libnsl 2.0.1 hd590300_0 conda-forge. libsqlite 3.45.2 h2797004_0 conda-forge. libuuid 2.38.1 h0b41bf4_0 conda-forge. libxcrypt 4.4.36 hd590300_1 conda-forge. libzlib 1.2.13 hd590300_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:31111,testability,mock,mock,31111,5 conda-forge. libnsl 2.0.1 hd590300_0 conda-forge. libsqlite 3.45.2 h2797004_0 conda-forge. libuuid 2.38.1 h0b41bf4_0 conda-forge. libxcrypt 4.4.36 hd590300_1 conda-forge. libzlib 1.2.13 hd590300_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1.0.0 pypi_0 pypi. matplotlib 3.8.4 pypi_0 pypi. natsort 8.4.0 pypi_0 pypi. ncurses 6.4.20240210 h59595ed_0 conda-forge. networkx 3.3 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.1 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd590300_1 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.3.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pyarrow 15.0.2 pypi_0 pypi. pynndescent 0.5.12 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bda,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:32713,testability,coverag,coverage,32713,b-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. Luke's environment: MacOS Ventura 13.4.1. Intel MacBook pro. <details>. <summary> Luke's failing env </summary>. ```. # packages in environment at /Users/luke.zappia/miniconda3/envs/scanpy-dev:. #. # Name Version Build Channel. anndata 0.10.6 pypi_0 pypi. array-api-compat 1.4.1 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 h10d778d_5 conda-forge. ca-certificates 2024.2.2 h8857fd0_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.0 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.3.0 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pypi_0 pypi. fonttools 4.49.0 pypi_0 pypi. fsspec 2024.2.0 pypi_0 pypi. h5py 3.10.0 pypi_0 pypi. identify 2.5.35 pypi_0 pypi. igraph 0.11.4 pypi_0 pypi. imageio 2.34.0 pypi_0 pypi. iniconfig 2.0.0 pypi_0 pypi. joblib 1.3.2 pypi_0 pypi. kiwisolver 1.4.5 pypi_0 pypi. lazy-loader 0.3 pypi_0 pypi. legacy-api-wrap 1.4 pypi_0 pypi. leidenalg 0.10.2 pypi_0 pypi. libexpat 2.6.2 h73e2aa4_0 conda-forge. libffi 3.4.2 h0d85af4_5 conda-forge. libsqlite 3.45.2 h92b6c6a_0 conda-forge. libzlib 1.2.13 h8a1eda9_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1.0.0 pypi_0 pypi. matplotlib 3.8.3 pypi_0 pypi. natsort 8.4.0 pypi_0 pypi. ncurses 6.4 h93d8f39_2 conda-forge. networkx 3.2.1 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.0 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd75f5a5_0 ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:34158,testability,mock,mock,34158,azy-loader 0.3 pypi_0 pypi. legacy-api-wrap 1.4 pypi_0 pypi. leidenalg 0.10.2 pypi_0 pypi. libexpat 2.6.2 h73e2aa4_0 conda-forge. libffi 3.4.2 h0d85af4_5 conda-forge. libsqlite 3.45.2 h92b6c6a_0 conda-forge. libzlib 1.2.13 h8a1eda9_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1.0.0 pypi_0 pypi. matplotlib 3.8.3 pypi_0 pypi. natsort 8.4.0 pypi_0 pypi. ncurses 6.4 h93d8f39_2 conda-forge. networkx 3.2.1 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.0 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd75f5a5_0 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.2.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pynndescent 0.5.11 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 4.1.0 pypi_0 pypi. pytest-mock 3.12.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 h9f0c242_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h9e318b2_1 conda-forge. scanpy 1.10.0rc2.dev16+g60aa7180 pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.12.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.3.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 h1abcd95_1 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.5 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.42.0 pyhd8ed1ab_0 conda-forge. xz 5.2.6 h775f41a_0 cond,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:89,usability,confirm,confirmed,89,"Tests fail with pytest 8.1 when a `data` dir exists; First reported by @lazappi, but now confirmed by me. Tests error during collection for a fresh dev install. ```. mamba create -yn scanpy-dev ""python=3.12"". conda activate scanpy-dev. pip install -e "".[dev,test]"" pytest-xdist # pytest-xdist isn't required, but makes this faster. conda deactivate scanpy-dev. conda activate scanpy-dev. pytest -n auto. ```. First everything fails since `dask-expr` isn't installed. This must be someone upstream pinning dask, but is easily solvable by adding dask-expr to the environment. ```. pip install dask-expr. pytest -n auto. ```. <details>. <summary> Failures </summary>. ```. FAILED scanpy/tests/test_score_genes.py::test_score_with_reference - TypeError: 'module' object is not callable. FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/te",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:112,usability,error,error,112,"Tests fail with pytest 8.1 when a `data` dir exists; First reported by @lazappi, but now confirmed by me. Tests error during collection for a fresh dev install. ```. mamba create -yn scanpy-dev ""python=3.12"". conda activate scanpy-dev. pip install -e "".[dev,test]"" pytest-xdist # pytest-xdist isn't required, but makes this faster. conda deactivate scanpy-dev. conda activate scanpy-dev. pytest -n auto. ```. First everything fails since `dask-expr` isn't installed. This must be someone upstream pinning dask, but is easily solvable by adding dask-expr to the environment. ```. pip install dask-expr. pytest -n auto. ```. <details>. <summary> Failures </summary>. ```. FAILED scanpy/tests/test_score_genes.py::test_score_with_reference - TypeError: 'module' object is not callable. FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/te",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:1930,usability,ERROR,ERROR,1930,own location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:1985,usability,ERROR,ERROR,1985,st_scrublet[True-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_gr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2041,usability,ERROR,ERROR,2041,e '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2087,usability,ERROR,ERROR,2087,' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-f,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2128,usability,ERROR,ERROR,2128,/test_scrublet.py::test_scrublet[False-sparse] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2185,usability,ERROR,ERROR,2185,ror: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown lo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2231,usability,ERROR,ERROR,2231,.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2270,usability,ERROR,ERROR,2270,on). FAILED scanpy/tests/test_scrublet.py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_e,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2309,usability,ERROR,ERROR,2309,py::test_scrublet[False-dense] - ImportError: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportE,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2348,usability,ERROR,ERROR,2348,Error: cannot import name '_paul15' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2389,usability,ERROR,ERROR,2389,'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown l,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2427,usability,ERROR,ERROR,2427,n location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_norm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2473,usability,ERROR,ERROR,2473,.py::test_scrublet_batched - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2517,usability,ERROR,ERROR,2517,nnot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportErro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2570,usability,ERROR,ERROR,2570,ers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2602,usability,ERROR,ERROR,2602,ILED scanpy/tests/test_scrublet.py::test_scrublet_data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2652,usability,ERROR,ERROR,2652,data - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_n,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2687,usability,ERROR,ERROR,2687,ame '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2723,usability,ERROR,ERROR,2723,helpers.data' (unknown location). FAILED scanpy/tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson resid,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2771,usability,ERROR,ERROR,2771,tests/test_scrublet.py::test_scrublet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - Import,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2804,usability,ERROR,ERROR,2804,blet_simulate_doublets - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2836,usability,ERROR,ERROR,2836,rror: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2873,usability,ERROR,ERROR,2873,om 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2915,usability,ERROR,ERROR,2915, location). ERROR scanpy/tests/external/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normal,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2951,usability,ERROR,ERROR,2951,nal/test_harmony_integrate.py. ERROR scanpy/tests/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-fl,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:2997,usability,ERROR,ERROR,2997,sts/external/test_harmony_timeseries.py. ERROR scanpy/tests/external/test_palantir.py. ERROR scanpy/tests/external/test_sam.py. ERROR scanpy/tests/external/test_scanorama_integrate.py. ERROR scanpy/tests/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot imp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:3197,usability,ERROR,ERROR,3197,sts/external/test_wishbone.py. ERROR scanpy/tests/test_aggregated.py. ERROR scanpy/tests/test_clustering.py. ERROR scanpy/tests/test_dendrogram.py. ERROR scanpy/tests/test_deprecations.py. ERROR scanpy/tests/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:3402,usability,ERROR,ERROR,3402,ts/test_embedding.py. ERROR scanpy/tests/test_embedding_density.py. ERROR scanpy/tests/test_embedding_plots.py. ERROR scanpy/tests/test_filter_rank_genes_groups.py. ERROR scanpy/tests/test_get.py. ERROR scanpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportErro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:3607,usability,ERROR,ERROR,3607,anpy/tests/test_highly_variable_genes.py. ERROR scanpy/tests/test_ingest.py. ERROR scanpy/tests/test_metrics.py. ERROR scanpy/tests/test_neighbors_key_added.py. ERROR scanpy/tests/test_paga.py. ERROR scanpy/tests/test_pca.py. ERROR scanpy/tests/test_plotting.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - Import,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:3865,usability,ERROR,ERROR,3865,.py. ERROR scanpy/tests/test_preprocessing.py. ERROR scanpy/tests/test_queries.py. ERROR scanpy/tests/test_rank_genes_groups.py. ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'sca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:4074,usability,ERROR,ERROR,4074,ngs[toarray-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:4283,usability,ERROR,ERROR,4283,-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=Non,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:4492,usability,ERROR,ERROR,4492,at32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:4701,usability,ERROR,ERROR,4701,-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_h,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:4915,usability,ERROR,ERROR,4915,ize_pearson_residuals_pca[toarray-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:5129,usability,ERROR,ERROR,5129,earson_residuals_pca[toarray-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:5390,usability,ERROR,ERROR,5390,- ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:5602,usability,ERROR,ERROR,5602,mportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:5814,usability,ERROR,ERROR,5814, ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot impor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:6026,usability,ERROR,ERROR,6026, - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:6238,usability,ERROR,ERROR,6238,rson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: ca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:6455,usability,ERROR,ERROR,6455,iduals_pca[csr_matrix-float32-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot impo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:6672,usability,ERROR,ERROR,6672,s_pca[csr_matrix-float32-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:6889,usability,ERROR,ERROR,6889,[csr_matrix-float32-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:7106,usability,ERROR,ERROR,7106,matrix-float32-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:7323,usability,ERROR,ERROR,7323,x-float32-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:7531,usability,ERROR,ERROR,7531,csr_matrix-float32-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:7739,usability,ERROR,ERROR,7739,uals_pca[csr_matrix-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:7940,usability,ERROR,ERROR,7940,ze_pearson_residuals_pca[csr_matrix-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-10,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:8157,usability,ERROR,ERROR,8157,ze_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - Im,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:8363,usability,ERROR,ERROR,8363,est_normalize_pearson_residuals_recipe[csr_matrix-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:8569,usability,ERROR,ERROR,8569,:test_normalize_pearson_residuals_recipe[csr_matrix-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_o,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:8828,usability,ERROR,ERROR,8828,ix-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:9045,usability,ERROR,ERROR,9045,t-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:9255,usability,ERROR,ERROR,9255,eta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:9465,usability,ERROR,ERROR,9465,] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:9682,usability,ERROR,ERROR,9682,esiduals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:9892,usability,ERROR,ERROR,9892,siduals_pca[csr_matrix-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:10102,usability,ERROR,ERROR,10102,rson_residuals_pca[csr_matrix-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:10312,usability,ERROR,ERROR,10312,rson_residuals_pca[csr_matrix-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:10527,usability,ERROR,ERROR,10527,residuals_pca[csr_matrix-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:10737,usability,ERROR,ERROR,10737,earson_residuals_pca[csr_matrix-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:10952,usability,ERROR,ERROR,10952,n_residuals_pca[csr_matrix-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:11162,usability,ERROR,ERROR,11162,n_residuals_pca[csr_matrix-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:11377,usability,ERROR,ERROR,11377,iduals_pca[csr_matrix-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' fro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:11592,usability,ERROR,ERROR,11592,iduals_pca[csr_matrix-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:11802,usability,ERROR,ERROR,11802,iduals_pca[csr_matrix-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:12017,usability,ERROR,ERROR,12017,iduals_pca[csr_matrix-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:12225,usability,ERROR,ERROR,12225,esiduals_pca[csr_matrix-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:12433,usability,ERROR,ERROR,12433,arson_residuals_pca[csr_matrix-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.t,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:12641,usability,ERROR,ERROR,12641,lize_pearson_residuals_pca[csr_matrix-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.tes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:12849,usability,ERROR,ERROR,12849,malize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'sca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:13064,usability,ERROR,ERROR,13064,malize_pearson_residuals_pca[csr_matrix-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:13270,usability,ERROR,ERROR,13270,ormalize_pearson_residuals_recipe[csr_matrix-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:13478,usability,ERROR,ERROR,13478,ormalize_pearson_residuals_pca[csr_matrix-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:13684,usability,ERROR,ERROR,13684,_normalize_pearson_residuals_pca[csr_matrix-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'sca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:13899,usability,ERROR,ERROR,13899,ize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:14105,usability,ERROR,ERROR,14105,st_normalize_pearson_residuals_recipe[csr_matrix-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' fr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:14311,usability,ERROR,ERROR,14311,st_normalize_pearson_residuals_recipe[csr_matrix-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:14526,usability,ERROR,ERROR,14526,alize_pearson_residuals_recipe[csr_matrix-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbm,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:14734,usability,ERROR,ERROR,14734,ize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:14948,usability,ERROR,ERROR,14948,lize_pearson_residuals_recipe[csr_matrix-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import nam,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:15162,usability,ERROR,ERROR,15162,rson_residuals_recipe[csr_matrix-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:15376,usability,ERROR,ERROR,15376,iduals_pca[csr_matrix-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' fro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:15590,usability,ERROR,ERROR,15590,siduals_pca[csr_matrix-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:15804,usability,ERROR,ERROR,15804,s_pca[toarray-float32-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.test,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16018,usability,ERROR,ERROR,16018,s_pca[toarray-float32-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._help,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16225,usability,ERROR,ERROR,16225,esiduals_pca[toarray-float32-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helper,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16432,usability,ERROR,ERROR,16432,arson_residuals_pca[toarray-float32-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16639,usability,ERROR,ERROR,16639,lize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.da,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:16846,usability,ERROR,ERROR,16846,t_normalize_pearson_residuals_pca[toarray-float32-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkn,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17051,usability,ERROR,ERROR,17051,n.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17256,usability,ERROR,ERROR,17256,ion.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17461,usability,ERROR,ERROR,17461,ation.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pb,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17666,usability,ERROR,ERROR,17666,ization.py::test_normalize_pearson_residuals_pca[toarray-float32-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:17864,usability,ERROR,ERROR,17864,st_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot impo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18067,usability,ERROR,ERROR,18067,test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18270,usability,ERROR,ERROR,18270,s/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18526,usability,ERROR,ERROR,18526,iduals_recipe[toarray-float32-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18733,usability,ERROR,ERROR,18733,uals_warnings[toarray-int64] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/tes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:18940,usability,ERROR,ERROR,18940,rs[toarray-int64-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19147,usability,ERROR,ERROR,19147,oarray-int64-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-Fals,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19332,usability,ERROR,ERROR,19332,residuals_errors[toarray-int64-params2-Pearson residuals require `clip>=0` or `clip=None`.] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - Impor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19529,usability,ERROR,ERROR,19529,scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import na,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19714,usability,ERROR,ERROR,19714,nown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:19898,usability,ERROR,ERROR,19898,ing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cann,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20076,usability,ERROR,ERROR,20076,me 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[expected_doublet_rate-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20253,usability,ERROR,ERROR,20253,port name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[synthetic_doublet_umi_subsampling-0.8] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearso,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20428,usability,ERROR,ERROR,20428,ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[knn_dist_metric-manhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_no,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20601,usability,ERROR,ERROR,20601,anhattan] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[normalize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknow,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20774,usability,ERROR,ERROR,20774,lize_variance-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[log_transform-True] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:20981,usability,ERROR,ERROR,20981,Error: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[mean_center-False] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21193,usability,ERROR,ERROR,21193, from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_prin_comps-10] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21405,usability,ERROR,ERROR,21405,(unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[n_neighbors-2] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21617,usability,ERROR,ERROR,21617,test_scrublet.py::test_scrublet_params[threshold-0.1] - ImportError: cannot import name '_pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:21829,usability,ERROR,ERROR,21829,earson_residuals_pca[toarray-int64-no_hvg-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from ',MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22041,usability,ERROR,ERROR,22041,n_residuals_pca[toarray-int64-hvg_default-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22253,usability,ERROR,ERROR,22253,n_residuals_pca[toarray-int64-hvg_default-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22465,usability,ERROR,ERROR,22465,n_residuals_pca[toarray-int64-hvg_default-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpe,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22677,usability,ERROR,ERROR,22677,n_residuals_pca[toarray-int64-hvg_default-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:22882,usability,ERROR,ERROR,22882,_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (u,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23087,usability,ERROR,ERROR,23087,rmalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unk,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23292,usability,ERROR,ERROR,23292,test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unkno,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23497,usability,ERROR,ERROR,23497,on.py::test_normalize_pearson_residuals_pca[toarray-int64-hvg_opt_out-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23700,usability,ERROR,ERROR,23700,rmalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (un,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23903,usability,ERROR,ERROR,23903,normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24106,usability,ERROR,ERROR,24106,"t_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s =========================================",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24309,usability,ERROR,ERROR,24309,"est_normalization.py::test_normalize_pearson_residuals_pca[toarray-int64-mask-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any ide",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24512,usability,ERROR,ERROR,24512,"/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in enviro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24720,usability,ERROR,ERROR,24720,"_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-30-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-100] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-com",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:25051,usability,error,errors,25051," 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_recipe[toarray-int64-50-200] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.1 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:25217,usability,help,helpers,25217,"or: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_warnings[csr_matrix-float32] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta0] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). ERROR scanpy/tests/test_normalization.py::test_normalize_pearson_residuals_errors[csr_matrix-float32-theta1] - ImportError: cannot import name 'pbmc3k' from 'scanpy.testing._helpers.data' (unknown location). =========================================================== 8 failed, 670 passed, 40 skipped, 3 xfailed, 400 warnings, 130 errors in 44.70s ============================================================. ```. </details> . Now we get a ton of failures due to a failure to import test dataset helpers. -----. Pinning `pytest<8` seems to resolve the issue. @flying-sheep any ideas? Any idea why CI is working with pytest 8.1.1 while we get failures locally? ### Environment info. My environments are both using ubuntu. <details>. <summary> My working env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.1 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.4.1 pypi_0 pypi. dask-expr 1.0.10 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pypi_0 pypi. fontt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:28096,usability,learn,learn,28096,ed_0 conda-forge. networkx 3.3 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.1 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd590300_1 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.3.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pyarrow 15.0.2 pypi_0 pypi. pynndescent 0.5.12 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 7.4.4 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. <details>. <summary> My failing env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pyp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:28515,usability,tool,toolz,28515,1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pyarrow 15.0.2 pypi_0 pypi. pynndescent 0.5.12 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 7.4.4 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. <details>. <summary> My failing env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.1 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.4.1 pypi_0 pypi. dask-expr 1.0.10 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:28636,usability,learn,learn,28636,2 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 7.4.4 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. <details>. <summary> My failing env </summary>. ```. # packages in environment at /mnt/workspace/mambaforge/envs/scanpy-dev2:. #. # Name Version Build Channel. _libgcc_mutex 0.1 conda_forge conda-forge. _openmp_mutex 4.5 2_gnu conda-forge. anndata 0.10.7 pypi_0 pypi. array-api-compat 1.6 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 hd590300_5 conda-forge. ca-certificates 2024.2.2 hbcca054_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.1 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.4.1 pypi_0 pypi. dask-expr 1.0.10 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pypi_0 pypi. fonttools 4.51.0 pypi_0 pypi. fsspec 2024.3.1 pypi_0 pypi.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:31461,usability,learn,learn,31461,ed_0 conda-forge. networkx 3.3 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.1 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd590300_1 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.3.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pyarrow 15.0.2 pypi_0 pypi. pynndescent 0.5.12 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. Luke's environment: MacOS Ventura 13.4.1. Intel MacBook pro. <details>. <summary> Luke's failing env </summary>. ```. # packages in environment at /Users/luke.zappia/miniconda3/envs/scanpy-dev:. #. # Name Version Build Channel. anndata 0.10.6 pypi_0 pypi. array-api-compat 1.4.1 pypi_0 pypi. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:31880,usability,tool,toolz,31880,1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pyarrow 15.0.2 pypi_0 pypi. pynndescent 0.5.12 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. Luke's environment: MacOS Ventura 13.4.1. Intel MacBook pro. <details>. <summary> Luke's failing env </summary>. ```. # packages in environment at /Users/luke.zappia/miniconda3/envs/scanpy-dev:. #. # Name Version Build Channel. anndata 0.10.6 pypi_0 pypi. array-api-compat 1.4.1 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 h10d778d_5 conda-forge. ca-certificates 2024.2.2 h8857fd0_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.0 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.3.0 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:32001,usability,learn,learn,32001,2 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 5.0.0 pypi_0 pypi. pytest-mock 3.14.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 hab00c5b_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. Luke's environment: MacOS Ventura 13.4.1. Intel MacBook pro. <details>. <summary> Luke's failing env </summary>. ```. # packages in environment at /Users/luke.zappia/miniconda3/envs/scanpy-dev:. #. # Name Version Build Channel. anndata 0.10.6 pypi_0 pypi. array-api-compat 1.4.1 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 h10d778d_5 conda-forge. ca-certificates 2024.2.2 h8857fd0_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.0 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.3.0 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pypi_0 pypi. fonttools 4.49.0 pypi_0 pypi. fsspec 2024.2.0 pypi_0 pypi. h5py 3.10.0 pypi_0 pypi. identify 2.5.3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:32320,usability,User,Users,32320,1 pypi_0 pypi. readline 8.2 h8228510_1 conda-forge. scanpy 1.10.0rc2.dev33+g9c8c095d pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.13.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.4.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 noxft_h4845f30_101 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.6 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.43.0 pyhd8ed1ab_1 conda-forge. xz 5.2.6 h166bdaf_0 conda-forge. zarr 2.17.2 pypi_0 pypi. ```. </details>. Luke's environment: MacOS Ventura 13.4.1. Intel MacBook pro. <details>. <summary> Luke's failing env </summary>. ```. # packages in environment at /Users/luke.zappia/miniconda3/envs/scanpy-dev:. #. # Name Version Build Channel. anndata 0.10.6 pypi_0 pypi. array-api-compat 1.4.1 pypi_0 pypi. asciitree 0.3.3 pypi_0 pypi. attrs 23.2.0 pypi_0 pypi. bzip2 1.0.8 h10d778d_5 conda-forge. ca-certificates 2024.2.2 h8857fd0_0 conda-forge. cfgv 3.4.0 pypi_0 pypi. click 8.1.7 pypi_0 pypi. cloudpickle 3.0.0 pypi_0 pypi. contourpy 1.2.0 pypi_0 pypi. coverage 7.4.4 pypi_0 pypi. cycler 0.12.1 pypi_0 pypi. dask 2024.3.0 pypi_0 pypi. distlib 0.3.8 pypi_0 pypi. execnet 2.1.1 pypi_0 pypi. fasteners 0.19 pypi_0 pypi. filelock 3.13.3 pypi_0 pypi. fonttools 4.49.0 pypi_0 pypi. fsspec 2024.2.0 pypi_0 pypi. h5py 3.10.0 pypi_0 pypi. identify 2.5.35 pypi_0 pypi. igraph 0.11.4 pypi_0 pypi. imageio 2.34.0 pypi_0 pypi. iniconfig 2.0.0 pypi_0 pypi. joblib 1.3.2 pypi_0 pypi. kiwisolver 1.4.5 pypi_0 pypi. lazy-loader 0.3 pypi_0 pypi. legacy-api-wrap 1.4 pypi_0 pypi. leidenalg 0.10.2 pypi_0 pypi. libexpat 2.6.2 h73e2aa4_0 conda-forge. libffi 3.4.2 h0d85af4_5 conda-for,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:34508,usability,learn,learn,34508,ypi_0 pypi. libexpat 2.6.2 h73e2aa4_0 conda-forge. libffi 3.4.2 h0d85af4_5 conda-forge. libsqlite 3.45.2 h92b6c6a_0 conda-forge. libzlib 1.2.13 h8a1eda9_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1.0.0 pypi_0 pypi. matplotlib 3.8.3 pypi_0 pypi. natsort 8.4.0 pypi_0 pypi. ncurses 6.4 h93d8f39_2 conda-forge. networkx 3.2.1 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.0 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd75f5a5_0 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.2.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pynndescent 0.5.11 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 4.1.0 pypi_0 pypi. pytest-mock 3.12.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 h9f0c242_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h9e318b2_1 conda-forge. scanpy 1.10.0rc2.dev16+g60aa7180 pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.12.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.3.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 h1abcd95_1 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.5 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.42.0 pyhd8ed1ab_0 conda-forge. xz 5.2.6 h775f41a_0 conda-forge. zarr 2.17.1 pypi_0 pypi. ```. </details>. ## TODO:. - [ ] Unpin pytest,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:34919,usability,tool,toolz,34919,ypi_0 pypi. libexpat 2.6.2 h73e2aa4_0 conda-forge. libffi 3.4.2 h0d85af4_5 conda-forge. libsqlite 3.45.2 h92b6c6a_0 conda-forge. libzlib 1.2.13 h8a1eda9_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1.0.0 pypi_0 pypi. matplotlib 3.8.3 pypi_0 pypi. natsort 8.4.0 pypi_0 pypi. ncurses 6.4 h93d8f39_2 conda-forge. networkx 3.2.1 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.0 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd75f5a5_0 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.2.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pynndescent 0.5.11 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 4.1.0 pypi_0 pypi. pytest-mock 3.12.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 h9f0c242_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h9e318b2_1 conda-forge. scanpy 1.10.0rc2.dev16+g60aa7180 pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.12.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.3.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 h1abcd95_1 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.5 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.42.0 pyhd8ed1ab_0 conda-forge. xz 5.2.6 h775f41a_0 conda-forge. zarr 2.17.1 pypi_0 pypi. ```. </details>. ## TODO:. - [ ] Unpin pytest,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:35040,usability,learn,learn,35040,ypi_0 pypi. libexpat 2.6.2 h73e2aa4_0 conda-forge. libffi 3.4.2 h0d85af4_5 conda-forge. libsqlite 3.45.2 h92b6c6a_0 conda-forge. libzlib 1.2.13 h8a1eda9_5 conda-forge. llvmlite 0.42.0 pypi_0 pypi. locket 1.0.0 pypi_0 pypi. matplotlib 3.8.3 pypi_0 pypi. natsort 8.4.0 pypi_0 pypi. ncurses 6.4 h93d8f39_2 conda-forge. networkx 3.2.1 pypi_0 pypi. nodeenv 1.8.0 pypi_0 pypi. numba 0.59.0 pypi_0 pypi. numcodecs 0.12.1 pypi_0 pypi. numpy 1.26.4 pypi_0 pypi. openssl 3.2.1 hd75f5a5_0 conda-forge. packaging 24.0 pypi_0 pypi. pandas 2.2.1 pypi_0 pypi. partd 1.4.1 pypi_0 pypi. patsy 0.5.6 pypi_0 pypi. pbr 6.0.0 pypi_0 pypi. pillow 10.2.0 pypi_0 pypi. pip 24.0 pyhd8ed1ab_0 conda-forge. platformdirs 4.2.0 pypi_0 pypi. pluggy 1.4.0 pypi_0 pypi. pre-commit 3.7.0 pypi_0 pypi. profimp 0.1.0 pypi_0 pypi. pynndescent 0.5.11 pypi_0 pypi. pyparsing 3.1.2 pypi_0 pypi. pytest 8.1.1 pypi_0 pypi. pytest-cov 4.1.0 pypi_0 pypi. pytest-mock 3.12.0 pypi_0 pypi. pytest-nunit 1.0.7 pypi_0 pypi. pytest-xdist 3.5.0 pypi_0 pypi. python 3.12.2 h9f0c242_0_cpython conda-forge. python-dateutil 2.9.0.post0 pypi_0 pypi. pytz 2024.1 pypi_0 pypi. pyyaml 6.0.1 pypi_0 pypi. readline 8.2 h9e318b2_1 conda-forge. scanpy 1.10.0rc2.dev16+g60aa7180 pypi_0 pypi. scikit-image 0.22.0 pypi_0 pypi. scikit-learn 1.4.1.post1 pypi_0 pypi. scipy 1.12.0 pypi_0 pypi. seaborn 0.13.2 pypi_0 pypi. session-info 1.0.0 pypi_0 pypi. setuptools 69.2.0 pyhd8ed1ab_0 conda-forge. setuptools-scm 8.0.4 pypi_0 pypi. six 1.16.0 pypi_0 pypi. statsmodels 0.14.1 pypi_0 pypi. stdlib-list 0.10.0 pypi_0 pypi. texttable 1.7.0 pypi_0 pypi. threadpoolctl 3.3.0 pypi_0 pypi. tifffile 2024.2.12 pypi_0 pypi. tk 8.6.13 h1abcd95_1 conda-forge. toolz 0.12.1 pypi_0 pypi. tqdm 4.66.2 pypi_0 pypi. typing-extensions 4.11.0 pypi_0 pypi. tzdata 2024.1 pypi_0 pypi. umap-learn 0.5.5 pypi_0 pypi. virtualenv 20.25.1 pypi_0 pypi. wheel 0.42.0 pyhd8ed1ab_0 conda-forge. xz 5.2.6 h775f41a_0 conda-forge. zarr 2.17.1 pypi_0 pypi. ```. </details>. ## TODO:. - [ ] Unpin pytest,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/pull/2994:8,deployability,instal,installs,8,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:392,deployability,instal,install,392,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:458,deployability,releas,release,458,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:483,deployability,Releas,Release,483,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:237,safety,review,review,237,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:341,safety,Test,Tests,341,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:237,testability,review,review,237,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:341,testability,Test,Tests,341,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:88,usability,guid,guidelines,88,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:119,usability,guid,guide,119,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:215,usability,workflow,workflow,215,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2994:321,usability,Close,Closes,321,Fix dev installs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because: fixing dev install. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2994
https://github.com/scverse/scanpy/pull/2996:0,deployability,Updat,Update,0,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2996:41,deployability,upgrad,upgrade,41,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2996:188,deployability,upgrad,upgrading,188,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2996:41,modifiability,upgrad,upgrade,41,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2996:188,modifiability,upgrad,upgrading,188,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2996:0,safety,Updat,Update,0,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2996:0,security,Updat,Update,0,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2996:7,testability,coverag,coverage,7,"Update coverage job; CI is bugging us to upgrade this. It's also saying we aren't uploading anything, and we already have another task for uploading... I'm going to use this pr to. 1. try upgrading. 2. try removing. and seeing what the effects are.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2996
https://github.com/scverse/scanpy/pull/2997:44,deployability,instal,installs,44,Backport PR #2994 on branch 1.10.x (Fix dev installs); Backport PR #2994: Fix dev installs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2997
https://github.com/scverse/scanpy/pull/2997:82,deployability,instal,installs,82,Backport PR #2994 on branch 1.10.x (Fix dev installs); Backport PR #2994: Fix dev installs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2997
https://github.com/scverse/scanpy/pull/2998:1286,availability,mask,masking,1286,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1457,availability,mask,masking,1457,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1481,availability,Error,Errors,1481,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:462,deployability,releas,release,462,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:487,deployability,Releas,Release,487,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1301,deployability,Continu,Continuous,1301,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:669,energy efficiency,current,current,669,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1481,performance,Error,Errors,1481,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:652,reliability,Doe,Doesn,652,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:260,safety,review,review,260,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:364,safety,Test,Tests,364,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:940,safety,input,input,940,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:985,safety,Test,Test,985,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1160,safety,Test,Tests,1160,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1481,safety,Error,Errors,1481,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1517,safety,input,input,1517,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1556,safety,input,input,1556,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1110,security,modif,modify,1110,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:260,testability,review,review,260,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:364,testability,Test,Tests,364,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:985,testability,Test,Test,985,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1160,testability,Test,Tests,1160,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:111,usability,guid,guidelines,111,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:142,usability,guid,guide,142,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:238,usability,workflow,workflow,238,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:344,usability,Close,Closes,344,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:546,usability,close,close,546,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:742,usability,user,user,742,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:940,usability,input,input,940,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1033,usability,support,support,1033,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1481,usability,Error,Errors,1481,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1517,usability,input,input,1517,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2998:1556,usability,input,input,1556,"Start overhaul for embedding sort order; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #1263. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Implements something close to what is described here:. * https://github.com/scverse/scanpy/issues/1263#issuecomment-776508554. Doesn't:. * Use ""current"", instead that's just `None`. * Include random, instead lets the user pass an array to order by, so random can be `rng.permutation(adata.n_obs)`. * Do broadcasting. Can either be added later or we can tell people to do this themselves. ## TODO:. - [ ] Check when input order array has repeated values. - [ ] Test sort_order argument deprecation. - [ ] Add support for `pd.Series` array values. - [ ] Maybe `list`s? - [ ] ""How to"" or modify existing advanced plotting tutorial. - [ ] Tests for. - [ ] Categorical ordering. - [ ] None is same as `np.arange(N)`. - [ ] direct overlap + ordering is equivalent to masking. - [ ] Continuous ordering. - [ ] ""ascending"" is like `np.argsort(values)` and vice versa. - [ ] ""ascending"" is like ""descending"" for inverted values. - [ ] Check masking for both. - [ ] Errors. - [ ] For incorrectly sized input array. - [ ] incorrect non-array input. - [ ] ""ascending"" is when the highest value goes on top, right?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2998
https://github.com/scverse/scanpy/pull/2999:266,availability,Error,Error,266,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:432,availability,cluster,clustering,432,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:297,deployability,releas,release,297,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:432,deployability,cluster,clustering,432,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:666,deployability,releas,release,666,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:691,deployability,Releas,Release,691,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:266,performance,Error,Error,266,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:243,safety,review,review,243,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:266,safety,Error,Error,266,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:547,safety,Test,Tests,547,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:243,testability,review,review,243,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:547,testability,Test,Tests,547,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:15,usability,support,support,15,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:94,usability,guid,guidelines,94,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:125,usability,guid,guide,125,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:221,usability,workflow,workflow,221,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/2999:266,usability,Error,Error,266,"Matplotlib 3.9 support; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes:. * Error caused by new matplotlib release candidate (it had been deprecated for a while, we just hadn't caught it....). * Corrects deprecation warnings in igraph leiden clustering code and pearson residuals code. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Tests included or not required because: just fixin' warnings. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2999
https://github.com/scverse/scanpy/pull/3000:51,usability,support,support,51,Backport PR #2999 on branch 1.10.x (Matplotlib 3.9 support); Backport PR #2999: Matplotlib 3.9 support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3000
https://github.com/scverse/scanpy/pull/3000:95,usability,support,support,95,Backport PR #2999 on branch 1.10.x (Matplotlib 3.9 support); Backport PR #2999: Matplotlib 3.9 support,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3000
https://github.com/scverse/scanpy/pull/3001:0,deployability,Updat,Update,0,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:470,deployability,releas,release,470,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:495,deployability,Releas,Release,495,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:0,safety,Updat,Update,0,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:267,safety,review,review,267,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:367,safety,Test,Tests,367,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:0,security,Updat,Update,0,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:267,testability,review,review,267,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:367,testability,Test,Tests,367,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:118,usability,guid,guidelines,118,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:149,usability,guid,guide,149,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:245,usability,workflow,workflow,245,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3001:351,usability,Close,Closes,351,Update marsilea tutorial to use group_ methods; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [ ] Closes #. - [x] Tests included or not required because: docs. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3001
https://github.com/scverse/scanpy/pull/3002:36,deployability,Updat,Update,36,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3002:77,deployability,Updat,Update,77,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3002:36,safety,Updat,Update,36,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3002:77,safety,Updat,Update,77,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3002:36,security,Updat,Update,36,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3002:77,security,Updat,Update,77,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3002:43,testability,coverag,coverage,43,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3002:84,testability,coverag,coverage,84,Backport PR #2996 on branch 1.10.x (Update coverage job); Backport PR #2996: Update coverage job,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3002
https://github.com/scverse/scanpy/pull/3003:36,deployability,Updat,Update,36,Backport PR #3001 on branch 1.10.x (Update marsilea tutorial to use group_ methods); Backport PR #3001: Update marsilea tutorial to use group_ methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003
https://github.com/scverse/scanpy/pull/3003:104,deployability,Updat,Update,104,Backport PR #3001 on branch 1.10.x (Update marsilea tutorial to use group_ methods); Backport PR #3001: Update marsilea tutorial to use group_ methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003
https://github.com/scverse/scanpy/pull/3003:36,safety,Updat,Update,36,Backport PR #3001 on branch 1.10.x (Update marsilea tutorial to use group_ methods); Backport PR #3001: Update marsilea tutorial to use group_ methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003
https://github.com/scverse/scanpy/pull/3003:104,safety,Updat,Update,104,Backport PR #3001 on branch 1.10.x (Update marsilea tutorial to use group_ methods); Backport PR #3001: Update marsilea tutorial to use group_ methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003
https://github.com/scverse/scanpy/pull/3003:36,security,Updat,Update,36,Backport PR #3001 on branch 1.10.x (Update marsilea tutorial to use group_ methods); Backport PR #3001: Update marsilea tutorial to use group_ methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003
https://github.com/scverse/scanpy/pull/3003:104,security,Updat,Update,104,Backport PR #3001 on branch 1.10.x (Update marsilea tutorial to use group_ methods); Backport PR #3001: Update marsilea tutorial to use group_ methods,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3003
https://github.com/scverse/scanpy/issues/3004:878,availability,Error,Error,878,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:222,deployability,version,version,222,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3041,deployability,Version,Versions,3041,"op, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:4930,deployability,updat,updated,4930,"Error: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.2. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 25.1.2. -----. IPython 8.23.0. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. -----. Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]. Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34. -----. Session information updated at 2024-04-12 13:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:340,energy efficiency,Load,Loading,340,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:2466,energy efficiency,core,core,2466,"nplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:2723,energy efficiency,core,core,2723," 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:222,integrability,version,version,222,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3041,integrability,Version,Versions,3041,"op, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3980,interoperability,platform,platformdirs,3980,"Error: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.2. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 25.1.2. -----. IPython 8.23.0. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. -----. Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]. Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34. -----. Session information updated at 2024-04-12 13:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:222,modifiability,version,version,222,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:1335,modifiability,pac,packages,1335," Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:1451,modifiability,layer,layer,1451," different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:1941,modifiability,pac,packages,1941,"-------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:2049,modifiability,layer,layer,2049,"r['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:2451,modifiability,pac,packages,2451,"r, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:2708,modifiability,pac,packages,2708,"ace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3041,modifiability,Version,Versions,3041,"op, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3354,modifiability,deco,decorator,3354,"{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3924,modifiability,pac,packaging,3924,"s, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.2. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 25.1.2. -----. IPython 8.23.0. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. -----. Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]. Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34. -----. Session information",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:4776,modifiability,pac,packaged,4776,"Error: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.2. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 25.1.2. -----. IPython 8.23.0. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. -----. Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]. Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34. -----. Session information updated at 2024-04-12 13:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:340,performance,Load,Loading,340,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:519,performance,memor,memory,519,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:878,performance,Error,Error,878,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:1483,performance,parallel,parallel,1483,"appen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:2084,performance,parallel,parallel,2084,"ith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, log1p, inplace, X, parallel). 107 obs_metrics[f""n_{var_type}_by_{expr_type}""] = X.getnnz(axis=1). 108 else:. --> 109 obs_metrics[f""n_{var_type}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:478,reliability,doe,doesn,478,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:878,safety,Error,Error,878,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:4930,safety,updat,updated,4930,"Error: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.2. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 25.1.2. -----. IPython 8.23.0. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. -----. Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]. Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34. -----. Session information updated at 2024-04-12 13:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3202,security,certif,certifi,3202,"e}_by_{expr_type}""] = np.count_nonzero(X, axis=1). 110 if log1p:. 111 obs_metrics[f""log1p_n_{var_type}_by_{expr_type}""] = np.log1p(. 112 obs_metrics[f""n_{var_type}_by_{expr_type}""]. 113 ). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/numeric.py:486, in count_nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pypa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:3490,security,iso,isoduration,3490,"nonzero(a, axis, keepdims). 483 else:. 484 a_bool = a.astype(np.bool_, copy=False). --> 486 return a_bool.sum(axis=axis, dtype=np.intp, keepdims=keepdims). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/numpy/core/_methods.py:49, in _sum(a, axis, dtype, out, keepdims, initial, where). 47 def _sum(a, axis=None, dtype=None, out=None, keepdims=False,. 48 initial=_NoValue, where=True):. ---> 49 return umr_sum(a, axis, dtype, out, keepdims, initial, where). AxisError: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:4910,security,Session,Session,4910,"Error: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.2. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 25.1.2. -----. IPython 8.23.0. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. -----. Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]. Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34. -----. Session information updated at 2024-04-12 13:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:4930,security,updat,updated,4930,"Error: axis 1 is out of bounds for array of dimension 0. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.11.4. ipykernel 6.29.4. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 2.2.2. parso 0.8.4. patsy 0.5.6. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.2. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 25.1.2. -----. IPython 8.23.0. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. -----. Python 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 20:50:58) [GCC 12.3.0]. Linux-5.14.0-362.8.1.el9_3.x86_64-x86_64-with-glibc2.34. -----. Session information updated at 2024-04-12 13:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:988,testability,Trace,Traceback,988,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:182,usability,confirm,confirmed,182,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:265,usability,confirm,confirmed,265,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:519,usability,memor,memory,519,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:531,usability,Minim,Minimal,531,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:878,usability,Error,Error,878,"AxisError when calculating QC metrics on backed data; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Loading data in backed mode, I get an AxisError when trying to calculate QC metrics. Problem has happened on three different datasets but doesn't happen when I read the data into memory. ### Minimal code sample. ```python. sc.datasets.pbmc3k(). pbmc = sc.read_h5ad('data/pbmc3k_raw.h5ad', backed = 'r+'). pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). Cell In[8], line 3. 1 pbmc.var['mt'] = pbmc.var_names.str.startswith('MT-'). 2 pbmc.var['ribo'] = pbmc.var_names.str.startswith((""RPS"", ""RPL"")). ----> 3 sc.pp.calculate_qc_metrics(pbmc, qc_vars=['mt', 'ribo'], percent_top=None, log1p=False, inplace=True). File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:315, in calculate_qc_metrics(adata, expr_type, var_type, qc_vars, percent_top, layer, use_raw, inplace, log1p, parallel). 312 if isinstance(qc_vars, str):. 313 qc_vars = [qc_vars]. --> 315 obs_metrics = describe_obs(. 316 adata,. 317 expr_type=expr_type,. 318 var_type=var_type,. 319 qc_vars=qc_vars,. 320 percent_top=percent_top,. 321 inplace=inplace,. 322 X=X,. 323 log1p=log1p,. 324 ). 325 var_metrics = describe_var(. 326 adata,. 327 expr_type=expr_type,. (...). 331 log1p=log1p,. 332 ). 334 if not inplace:. File ~/miniconda3/envs/parse_sepsis/lib/python3.12/site-packages/scanpy/preprocessing/_qc.py:109, in describe_obs(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3005:1283,availability,Error,Error,1283,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:0,deployability,Fail,Failed,0,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:184,deployability,version,version,184,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:1316,deployability,Version,Versions,1316,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:184,integrability,version,version,184,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:1316,integrability,Version,Versions,1316,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:184,modifiability,version,version,184,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:1316,modifiability,Version,Versions,1316,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:1283,performance,Error,Error,1283,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:0,reliability,Fail,Failed,0,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:1283,safety,Error,Error,1283,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:144,usability,confirm,confirmed,144,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:227,usability,confirm,confirmed,227,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:804,usability,Minim,Minimal,804,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:1283,usability,Error,Error,1283,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:1418,usability,learn,learn,1418,"Failed violins; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? ![Untitled-1](https://github.com/scverse/scanpy/assets/32550896/141d1f4b-1eaa-45eb-8a75-24e46172d408). This was supposed to be a violin plot of total_counts. Notice that some cell categories have no data. This is by design: some categories defined but not assigned to any samples. They are assigned and used elsewhere. This totally breaks the violin plots, which work only if all categories have at least some data. I like that empty categories are still but I would like to see non-empty violins. ### Minimal code sample. ```python. This code can be used to have additional unassigned categories added:. ord = ['B', 'B_mz', 'B_gro', 'B_pls', 'B_mem',. 'Th', 'Th_reg', 'Th_mem', 'Tc', 'Tc_act', 'Tc_mem',. 'NKT', 'NK_0', 'NK_1', 'NK_2',. 'ncMo', 'cMo', 'DC_1', 'DC_2', 'M_1', 'M_2',. 'Ne', 'RBC', 'PLT', 'HSC', 'Whatever', 'Whatnot', 'Unassigned', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. ```. ### Error output. _No response_. ### Versions. scanpy==1.10.1 anndata==0.10.7 umap==0.5.5 numpy==1.26.4 scipy==1.13.0 pandas==2.2.2 scikit-learn==1.4.2 statsmodels==0.14.1 igraph==0.10.3 pynndescent==0.5.12",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3007:121,modifiability,paramet,parameters,121,"Pass n_iterations argument to scanpy.tl.louvain; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Is there any way to pass n_iterations argument to scanpy.tl.louvain (just as in scanpy.tl.leiden)? Also, what is the default number of iterations for scanpy.tl.louvain? Having this as an extra argument just like in scanpy.tl.leiden would be really helpful",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3007
https://github.com/scverse/scanpy/issues/3007:457,usability,help,helpful,457,"Pass n_iterations argument to scanpy.tl.louvain; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Is there any way to pass n_iterations argument to scanpy.tl.louvain (just as in scanpy.tl.leiden)? Also, what is the default number of iterations for scanpy.tl.louvain? Having this as an extra argument just like in scanpy.tl.leiden would be really helpful",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3007
https://github.com/scverse/scanpy/issues/3010:12,security,triag,triage,12,Add a needs triage tag; Added by default for new issues and PRs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3010
https://github.com/scverse/scanpy/issues/3011:243,availability,operat,operations,243,Update Preprocessing functions with numba; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be useful to switch from array operations to `numba` kernels in for most of the preprocessing. I would start writing those.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:0,deployability,Updat,Update,0,Update Preprocessing functions with numba; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be useful to switch from array operations to `numba` kernels in for most of the preprocessing. I would start writing those.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:115,modifiability,paramet,parameters,115,Update Preprocessing functions with numba; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be useful to switch from array operations to `numba` kernels in for most of the preprocessing. I would start writing those.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:0,safety,Updat,Update,0,Update Preprocessing functions with numba; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be useful to switch from array operations to `numba` kernels in for most of the preprocessing. I would start writing those.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:0,security,Updat,Update,0,Update Preprocessing functions with numba; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be useful to switch from array operations to `numba` kernels in for most of the preprocessing. I would start writing those.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3013:60,integrability,sub,subsets,60,Benchmarks: Add all from Dask tutorial; Different data:. 1. subsets. 2. sparse / dense chunks. Also all from disk.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:109,performance,disk,disk,109,Benchmarks: Add all from Dask tutorial; Different data:. 1. subsets. 2. sparse / dense chunks. Also all from disk.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3014:1650,availability,Error,Error,1650,"raph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:3085,availability,ping,pingouin,3085,cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions N,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:248,deployability,version,version,248,"sc.pp.neighbors(..., knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1745,deployability,Version,Versions,1745,". `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:4523,deployability,updat,updated,4523,"n5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. uri_template NA. url_normalize 1.4.3. urllib3 2.2.1. uvloop 0.19.0. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. wget 3.2. xarray 2024.2.0. yaml 6.0.1. zmq 25.1.2. zoneinfo NA. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.5. notebook 7.1.2. -----. Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]. Linux-6.5.0-27-generic-x86_64-with-glibc2.35. -----. Session information updated at 2024-04-18 18:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1017,energy efficiency,load,load,1017,", knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:2089,energy efficiency,cloud,cloudpickle,2089,"9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:248,integrability,version,version,248,"sc.pp.neighbors(..., knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1745,integrability,Version,Versions,1745,". `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:3119,interoperability,platform,platformdirs,3119,olorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. uri_template NA. url_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:248,modifiability,version,version,248,"sc.pp.neighbors(..., knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1745,modifiability,Version,Versions,1745,". `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:2220,modifiability,deco,decorator,2220,"# compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:3011,modifiability,pac,packaging,3011,A. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. tor,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1017,performance,load,load,1017,", knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1650,performance,Error,Error,1650,"raph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:2909,performance,network,networkx,2909,nparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_dat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:46,reliability,doe,does,46,"sc.pp.neighbors(..., knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1650,safety,Error,Error,1650,"raph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:2287,safety,except,exceptiongroup,2287,"ata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:4523,safety,updat,updated,4523,"n5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. uri_template NA. url_normalize 1.4.3. urllib3 2.2.1. uvloop 0.19.0. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. wget 3.2. xarray 2024.2.0. yaml 6.0.1. zmq 25.1.2. zoneinfo NA. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.5. notebook 7.1.2. -----. Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]. Linux-6.5.0-27-generic-x86_64-with-glibc2.35. -----. Session information updated at 2024-04-18 18:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:2030,security,certif,certifi,2030,"_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:2508,security,iso,isoduration,2508," # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:2909,security,network,networkx,2909,nparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_dat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:4503,security,Session,Session,4503,"n5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. uri_template NA. url_normalize 1.4.3. urllib3 2.2.1. uvloop 0.19.0. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. wget 3.2. xarray 2024.2.0. yaml 6.0.1. zmq 25.1.2. zoneinfo NA. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.5. notebook 7.1.2. -----. Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]. Linux-6.5.0-27-generic-x86_64-with-glibc2.35. -----. Session information updated at 2024-04-18 18:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:4523,security,updat,updated,4523,"n5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. uri_template NA. url_normalize 1.4.3. urllib3 2.2.1. uvloop 0.19.0. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. wget 3.2. xarray 2024.2.0. yaml 6.0.1. zmq 25.1.2. zoneinfo NA. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.5. notebook 7.1.2. -----. Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]. Linux-6.5.0-27-generic-x86_64-with-glibc2.35. -----. Session information updated at 2024-04-18 18:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:3774,testability,simpl,simplejson,3774,"n5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. uri_template NA. url_normalize 1.4.3. urllib3 2.2.1. uvloop 0.19.0. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. wget 3.2. xarray 2024.2.0. yaml 6.0.1. zmq 25.1.2. zoneinfo NA. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.5. notebook 7.1.2. -----. Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]. Linux-6.5.0-27-generic-x86_64-with-glibc2.35. -----. Session information updated at 2024-04-18 18:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:208,usability,confirm,confirmed,208,"sc.pp.neighbors(..., knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:291,usability,confirm,confirmed,291,"sc.pp.neighbors(..., knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:939,usability,Minim,Minimal,939,"sc.pp.neighbors(..., knn=True, n_neighbors=k) does not threshold the adjacency; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? According to the `pp.neighbors()` [docs we have](https://github.com/scverse/scanpy/blob/4642cf8e2e51b257371792cb4fcb9611c0a81123/scanpy/neighbors/__init__.py#L96):. ```. knn. If `True`, use a hard threshold to restrict the number of neighbors to. `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:1650,usability,Error,Error,1650,"raph. Otherwise, use a Gaussian. Kernel to assign low weights to neighbors more distant than the. `n_neighbors` nearest neighbor. ```. However, the adjacency represented by `adata.uns['neighbors']['connectivities_key']` shows many more neighbors than `n_neighbors` when `knn=True`. ### Minimal code sample. ```python. import urllib.request. import scanpy as sc. # load the data. h5_data = ""https://datasets.cellxgene.cziscience.com/6ff309fa-e9f6-405d-b24e-3c35528f154e.h5ad"". urllib.request.urlretrieve(h5_data, ""/tmp/data.h5ad"") . adata = sc.read_h5ad(""/tmp/data.h5ad""). # compute the adjacency thresholded at k=10. k=10. sc.pp.neighbors(adata, n_neighbors=k, n_pcs=40, random_state=42,knn=True). adjacency = (adata.obsp[adata.uns['neighbors']['connectivities_key']].todense() > 0).astype(np.int32). print(f""adjacency matrix (k={k}) shape: {adjacency.shape}""). # check to see if we got a threshold. max_neighbors = np.max(adjacency.sum(axis=0)). print(f""Max neighbors={max_neighbors}""). ```. ### Error output. ```pytb. adjacency matrix (k=10) shape: (1011, 1011). Max neighbors=91. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.9.8. -----. Bio 1.83. MOODS NA. PIL 10.2.0. absl NA. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.2.0. attrs 23.2.0. babel 2.14.0. biothings_client 0.3.1. bpnetlite 0.6.0. cattr NA. cattrs NA. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. colorlog NA. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.8. dragonnfruit 0.3.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. filelock 3.13.1. fqdn NA. fsspec 2024.3.1. goatools 1.3.11. google NA. h5py 3.10.0. hdf5plugin 4.4.0. idna 3.6. igraph 0.11.4. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/issues/3014:3774,usability,simpl,simplejson,3774,"n5 0.9.24. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.13.0. jupyterlab_server 2.25.4. kiwisolver 1.4.5. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.6.2. mpl_toolkits NA. msgpack 1.0.8. mudata 0.2.3. muon 0.1.5. mygene 3.2.2. natsort 8.4.0. nbformat 5.10.3. networkx 3.2.1. numba 0.59.1. numexpr 2.9.0. numpy 1.26.4. optree 0.10.0. optuna 3.6.0. overrides NA. packaging 24.0. pandas 1.5.3. pandas_flavor NA. parso 0.8.3. patsy 0.5.6. pingouin 0.5.4. pkg_resources NA. platformdirs 4.2.0. plotly 5.20.0. prometheus_client NA. prompt_toolkit 3.0.43. psutil 5.9.8. pure_eval 0.2.2. pyBigWig 0.3.22. pyarrow 15.0.2. pychromvar 0.0.4. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pyfaidx 0.8.1.1. pygments 2.17.2. pyjaspar 3.0.0. pynndescent 0.5.11. pyparsing 3.1.2. pysam 0.22.0. pythonjsonlogger NA. pytz 2024.1. ray 2.10.0. referencing NA. requests 2.31.0. requests_cache 1.2.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rich NA. rpds NA. scipy 1.12.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. setproctitle 1.2.2. simplejson 3.19.2. sitecustomize NA. six 1.16.0. sklearn 1.4.1.post1. sniffio 1.3.1. stack_data 0.6.3. statsmodels 0.14.1. swig_runtime_data4 NA. tabulate 0.9.0. tensorboard 2.16.2. texttable 1.7.0. threadpoolctl 3.4.0. torch 2.2.1+cu121. torchgen NA. tornado 6.4. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. uri_template NA. url_normalize 1.4.3. urllib3 2.2.1. uvloop 0.19.0. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. wget 3.2. xarray 2024.2.0. yaml 6.0.1. zmq 25.1.2. zoneinfo NA. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.5. notebook 7.1.2. -----. Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]. Linux-6.5.0-27-generic-x86_64-with-glibc2.35. -----. Session information updated at 2024-04-18 18:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3014
https://github.com/scverse/scanpy/pull/3015:41,energy efficiency,core,cores,41,`sparse_mean_variance_axis` now uses all cores; This functions now uses all cores for `mean` & `var` calculations.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015
https://github.com/scverse/scanpy/pull/3015:76,energy efficiency,core,cores,76,`sparse_mean_variance_axis` now uses all cores; This functions now uses all cores for `mean` & `var` calculations.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015
https://github.com/scverse/scanpy/pull/3017:122,performance,memor,memory,122,Hvg seurat v3 numba kernel; Adds a numba kernel for `seurat_v3` for sparse matrices. This kernel is a lot faster and more memory efficient. I doesn't copy nor promotes the matrix to 64-bit floats.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:142,reliability,doe,doesn,142,Hvg seurat v3 numba kernel; Adds a numba kernel for `seurat_v3` for sparse matrices. This kernel is a lot faster and more memory efficient. I doesn't copy nor promotes the matrix to 64-bit floats.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:122,usability,memor,memory,122,Hvg seurat v3 numba kernel; Adds a numba kernel for `seurat_v3` for sparse matrices. This kernel is a lot faster and more memory efficient. I doesn't copy nor promotes the matrix to 64-bit floats.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:129,usability,efficien,efficient,129,Hvg seurat v3 numba kernel; Adds a numba kernel for `seurat_v3` for sparse matrices. This kernel is a lot faster and more memory efficient. I doesn't copy nor promotes the matrix to 64-bit floats.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3019:74,interoperability,format,formatting,74,Backport PR #3018 on branch 1.10.x (manually sort bibtex entries ahead of formatting); Backport PR #3018: manually sort bibtex entries ahead of formatting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3019
https://github.com/scverse/scanpy/pull/3019:144,interoperability,format,formatting,144,Backport PR #3018 on branch 1.10.x (manually sort bibtex entries ahead of formatting); Backport PR #3018: manually sort bibtex entries ahead of formatting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3019
https://github.com/scverse/scanpy/issues/3021:10,availability,cluster,clustering,10,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:508,availability,cluster,clustering,508,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:864,availability,cluster,clusters,864,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:897,availability,cluster,clusters,897,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:933,availability,cluster,clusters,933,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1379,availability,cluster,clusters,1379,"f scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1446,availability,cluster,clusters,1446,"cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1470,availability,cluster,clusters,1470,".pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1856,availability,cluster,clusters,1856," 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decora",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1923,availability,cluster,clusters,1923,"s 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1947,availability,cluster,clusters,1947,"nimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2461,availability,cluster,clusters,2461,"(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2528,availability,cluster,clusters,2528,"os_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2552,availability,cluster,clusters,2552,"lculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2575,availability,Error,Error,2575,"return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extension",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2605,availability,cluster,clusters,2605,"(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2626,availability,cluster,clusters,2626,"orm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2648,availability,cluster,clusters,2648,". transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:10,deployability,cluster,clustering,10,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:294,deployability,version,version,294,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:508,deployability,cluster,clustering,508,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:864,deployability,cluster,clusters,864,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:897,deployability,cluster,clusters,897,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:933,deployability,cluster,clusters,933,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1379,deployability,cluster,clusters,1379,"f scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1446,deployability,cluster,clusters,1446,"cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1470,deployability,cluster,clusters,1470,".pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1856,deployability,cluster,clusters,1856," 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decora",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1923,deployability,cluster,clusters,1923,"s 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1947,deployability,cluster,clusters,1947,"nimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolv",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2461,deployability,cluster,clusters,2461,"(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2528,deployability,cluster,clusters,2528,"os_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2552,deployability,cluster,clusters,2552,"lculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2605,deployability,cluster,clusters,2605,"(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2626,deployability,cluster,clusters,2626,"orm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2648,deployability,cluster,clusters,2648,". transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2672,deployability,Version,Versions,2672,"rsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:3737,deployability,updat,updated,3737,"). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]. macOS-14.3.1-arm64-arm-64bit. -----. Session information updated at 2024-04-22 09:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:294,integrability,version,version,294,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:697,integrability,transform,transformer,697,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1654,integrability,transform,transformer,1654,"eighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1751,integrability,transform,transformer,1751,"computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1763,integrability,transform,transformer,1763,"ine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2672,integrability,Version,Versions,2672,"rsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:697,interoperability,transform,transformer,697,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1654,interoperability,transform,transformer,1654,"eighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 18",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1751,interoperability,transform,transformer,1751,"computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:1763,interoperability,transform,transformer,1763,"ine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:294,modifiability,version,version,294,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2672,modifiability,Version,Versions,2672,"rsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2854,modifiability,deco,decorator,2854,"). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]. macOS-14.3.1-arm64-arm-64bit. -----. Session information updated at 2024-04-22 09:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:3094,modifiability,pac,packaging,3094,"). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]. macOS-14.3.1-arm64-arm-64bit. -----. Session information updated at 2024-04-22 09:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2575,performance,Error,Error,2575,"return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extension",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:117,safety,input,input,117,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2575,safety,Error,Error,2575,"return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extension",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:3737,safety,updat,updated,3737,"). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]. macOS-14.3.1-arm64-arm-64bit. -----. Session information updated at 2024-04-22 09:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:3717,security,Session,Session,3717,"). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]. macOS-14.3.1-arm64-arm-64bit. -----. Session information updated at 2024-04-22 09:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:3737,security,updat,updated,3737,"). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extensions NA. umap 0.5.5. wcwidth 0.2.13. -----. Python 3.11.7 (main, Dec 15 2023, 12:09:56) [Clang 14.0.6 ]. macOS-14.3.1-arm64-arm-64bit. -----. Session information updated at 2024-04-22 09:58. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:117,usability,input,input,117,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:254,usability,confirm,confirmed,254,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:337,usability,confirm,confirmed,337,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:949,usability,Minim,Minimal,949,"Different clustering results when setting metrics = ""cosine"", using callable cosine function and direct cos distance input. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? The following three ways use the same cosine similarity for sc.pp.neighbors following by leiden clustering renders different results:. 1. set `metric = ""cosine""` in `sc.pp.neighbors()`. 2. use self-written callable cosine similarity function in `KNeighborsTransformer` and pass to the transformer option in `sc.pp.neighbors()`. 3. calculate pre-computed cosine similarity matrix then use it to add `adata.obsp['connectivities']`. Option 1 generates 85 clusters, option 2 generates 170 clusters and option 3 generates 183 clusters. . ### Minimal code sample. ```python. import scanpy as sc. from sklearn.neighbors import KNeighborsTransformer. import numpy as np. from numpy.linalg import norm. from sklearn.metrics.pairwise import cosine_similarity. adata = sc.datasets.pbmc68k_reduced(). ###use built-in cosine similarity option. sc.pp.neighbors(adata, n_neighbors=15,n_pcs=0,metric= ""cosine""). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use callable cosine similarity metrics. def cos_distance(A, B):. # calculate the distance, return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/issues/3021:2575,usability,Error,Error,2575,"return a float. cosine = np.dot(A, B) / (norm(A) * norm(B)). return cosine. transformer = KNeighborsTransformer(n_neighbors=15, metric=cos_distance). sc.pp.neighbors(adata, transformer=transformer,n_pcs=0). sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ###use precomputed cosine distance metrics. dis_mat = cosine_similarity(adata.X). tmp = sc.neighbors._common._get_indices_distances_from_dense_matrix(dis_mat, n_neighbors=15). adata.obsp[""connectivities""] = sc.neighbors._connectivity.umap(. knn_indices = tmp[0],. knn_dists = tmp[1],. n_obs = dis_mat.shape[0],. n_neighbors = 15,. ). adata.uns[""neighbors""] = {""connectivities_key"": ""connectivities"", ""params"": {""method"": None}}. sc.tl.umap(adata,random_state =42). sc.tl.leiden(adata,resolution=10). clusters= np.array(adata.obs[""leiden""]).astype(int). print('num of clusters: '+str(len(set(clusters)))). ```. ### Error output. ```pytb. num of clusters: 85. num of clusters: 170. num of clusters: 183. ```. ### Versions. <details>. ```. -----. anndata 0.10.6. scanpy 1.10.1. -----. IPython 8.22.2. PIL 10.2.0. asttokens NA. console_thrift NA. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. decorator 5.1.1. executing 2.0.1. h5py 3.10.0. igraph 0.11.4. jedi 0.19.1. joblib 1.3.2. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. matplotlib 3.8.3. mpl_toolkits NA. natsort 8.4.0. numba 0.59.1. numpy 1.26.4. packaging 24.0. pandas 2.2.1. parso 0.8.3. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.42. psutil 5.9.0. pure_eval 0.2.2. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 3.1.2. pytz 2024.1. scipy 1.12.0. session_info 1.0.0. six 1.16.0. sklearn 1.4.1.post1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tqdm 4.66.2. traitlets 5.14.2. typing_extension",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3021
https://github.com/scverse/scanpy/pull/3024:77,energy efficiency,core,cores,77,Backport PR #3015 on branch 1.10.x (`sparse_mean_variance_axis` now uses all cores); Backport PR #3015: `sparse_mean_variance_axis` now uses all cores,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3024
https://github.com/scverse/scanpy/pull/3024:145,energy efficiency,core,cores,145,Backport PR #3015 on branch 1.10.x (`sparse_mean_variance_axis` now uses all cores); Backport PR #3015: `sparse_mean_variance_axis` now uses all cores,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3024
https://github.com/scverse/scanpy/issues/3025:16,availability,error,error,16,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1509,availability,Error,Error,1509,"X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_q",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5074,availability,reliab,reliable,5074,"olation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:234,deployability,version,version,234,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:459,deployability,fail,fails,459,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:770,deployability,fail,fails,770,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4419,deployability,patch,patch,4419,":. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5234,deployability,Version,Versions,5234,"olation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:7548,deployability,updat,updated,7548,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:392,energy efficiency,heat,heatmap,392,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5486,energy efficiency,cloud,cloudpickle,5486,"_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:7036,energy efficiency,cpu,cpu,7036,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:234,integrability,version,version,234,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1231,integrability,sub,subplots,1231,"ersion of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1648,integrability,sub,subplots,1648," because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2147,integrability,wrap,wrapper,2147,"a.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2200,integrability,wrap,wraps,2200,"b.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3363,integrability,wrap,wraps,3363,"s. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # im",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3932,integrability,filter,filternorm,3932,"x). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisati",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3944,integrability,filter,filterrad,3944,"nt(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4137,integrability,filter,filternorm,4137,"al\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4148,integrability,filter,filternorm,4148,"\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dty",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4166,integrability,filter,filterrad,4166,"ndation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4176,integrability,filter,filterrad,4176,"thon.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. Type",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5018,integrability,wrap,wraps,5018,"mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5234,integrability,Version,Versions,5234,"olation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2147,interoperability,wrapper,wrapper,2147,"a.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3535,interoperability,bind,bind,3535,"ocal-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4802,interoperability,format,format,4802,"es.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:6302,interoperability,platform,platformdirs,6302,9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. I,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:234,modifiability,version,version,234,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:427,modifiability,paramet,parameter,427,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1982,modifiability,Pac,Packages,1982,"eighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2059,modifiability,pac,packages,2059,", groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2083,modifiability,pac,packages,2083,"l.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2465,modifiability,Pac,Packages,2465,"pt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2542,modifiability,pac,packages,2542,"eback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:2566,modifiability,pac,packages,2566,"last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 aut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3145,modifiability,Pac,Packages,3145,"apper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3222,modifiability,pac,packages,3222,"tible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3246,modifiability,pac,packages,3246," **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3535,modifiability,bind,bind,3535,"ocal-packages\Python311\site-packages\scanpy\plotting\_tools\paga.py:1255, in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3676,modifiability,Pac,Packages,3676,"lor_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 70",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3753,modifiability,pac,packages,3753,"rgin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeE",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3777,modifiability,pac,packages,3777,"tle_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:3903,modifiability,exten,extent,3903,"map, return_data, show, save, ax). 1253 print(X.shape). 1254 if as_heatmap:. -> 1255 img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map). 1256 if show_yticks:. 1257 ax.set_yticks(range(len(X))). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4122,modifiability,exten,extent,4122,"ile ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4129,modifiability,exten,extent,4129,"ppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\__init__.py:1459, in _preprocess_data.<locals>.inner(ax, data, *args, **kwargs). 1456 @functools.wraps(func). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4447,modifiability,Pac,Packages,4447,"1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4524,modifiability,pac,packages,4524,"ew_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4548,modifiability,pac,packages,4548,"*kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5234,modifiability,Version,Versions,5234,"olation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5614,modifiability,deco,decorator,5614,"self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:6227,modifiability,pac,packaging,6227,# Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:16,performance,error,error,16,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1509,performance,Error,Error,1509,"X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_q",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:7036,performance,cpu,cpu,7036,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:459,reliability,fail,fails,459,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:770,reliability,fail,fails,770,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4370,reliability,doe,does,4370,"c). 1457 def inner(ax, *args, data=None, **kwargs):. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. at",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5074,reliability,reliab,reliable,5074,"olation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:16,safety,error,error,16,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1509,safety,Error,Error,1509,"X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_q",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4419,safety,patch,patch,4419,":. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4866,safety,input,input,4866,"ation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4900,safety,valid,valid,4900,"extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:7548,safety,updat,updated,7548,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4419,security,patch,patch,4419,":. 1458 if data is None:. -> 1459 return func(ax, *map(sanitize_sequence, args), **kwargs). 1461 bound = new_sig.bind(ax, *args, **kwargs). 1462 auto_label = (bound.arguments.get(label_namer). 1463 or bound.kwargs.get(label_namer)). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\axes\_axes.py:5665, in Axes.imshow(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5427,security,certif,certifi,5427,"~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:5767,security,iso,isoduration,5767,"ape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scip",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:7528,security,Session,Session,7528,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:7548,security,updat,updated,7548,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1542,testability,Trace,Traceback,1542,"imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:6834,testability,simpl,simplejson,6834,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:16,usability,error,error,16,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:194,usability,confirm,confirmed,194,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:277,usability,confirm,confirmed,277,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:809,usability,Minim,Minimal,809,"sc.pl.paga_path error in dimensions of array passed to ax.imshow; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? sc.pl.paga_path is supposed to output a heatmap. However, with the default parameter n_avg=1, the plotting fails. Internally, the function passes an array X, ` X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSof",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:1509,usability,Error,Error,1509,"X = np.asarray(X).squeeze()` to ax.imshow `img = ax.imshow(X, aspect=""auto"", interpolation=""nearest"", cmap=color_map)`. X is one dimensional because of the squeeze() and imshow only accepts 2d arrays. It's fixed for n_avg=1 when squeeze is removed but still fails when n_avg is other numbers. ### Minimal code sample. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.recipe_zheng17(adata). sc.tl.pca(adata, svd_solver=""arpack""). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=50). sc.tl.leiden(adata, resolution=1.0). sc.tl.paga(adata, groups=""leiden""). sc.pl.paga(adata, color=[""leiden"", ""Hba-a2"", ""Elane"", ""Irf8""]). adata.uns['iroot']=0. sc.tl.dpt(adata). import matplotlib.pyplot as plt. fig,ax=plt.subplots(1,1,figsize=(7,1)). path_data = sc.pl.paga_path(. adata,. [4, 5],. [""Elane""],. ax=ax,. show_node_names=False,. ytick_fontsize=12,. return_data=True,. #n_avg=1,. color_map=""Greys"",. groups_key=""leiden"",. color_maps_annotations={""dpt_pseudotime"": ""viridis""}. ). ```. ### Error output. ```pytb. TypeError Traceback (most recent call last). Cell In[1], line 15. 13 import matplotlib.pyplot as plt. 14 fig,ax=plt.subplots(1,1,figsize=(7,1)). ---> 15 path_data = sc.pl.paga_path(. 16 adata,. 17 [4, 5],. 18 [""Elane""],. 19 ax=ax,. 20 show_node_names=False,. 21 ytick_fontsize=12,. 22 return_data=True,. 23 #n_avg=1,. 24 color_map=""Greys"",. 25 groups_key=""leiden"",. 26 color_maps_annotations={""dpt_pseudotime"": ""viridis""}. 27 ). File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_q",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:4866,usability,input,input,4866,"ation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs). 5657 self.set_aspect(aspect). 5658 im = mimage.AxesImage(self, cmap=cmap, norm=norm,. 5659 interpolation=interpolation, origin=origin,. 5660 extent=extent, filternorm=filternorm,. 5661 filterrad=filterrad, resample=resample,. 5662 interpolation_stage=interpolation_stage,. 5663 **kwargs). -> 5665 im.set_data(X). 5666 im.set_alpha(alpha). 5667 if im.get_clip_path() is None:. 5668 # image does not already have clipping set, clip to axes patch. File ~\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\matplotlib\image.py:710, in _ImageBase.set_data(self, A). 706 self._A = self._A[:, :, 0]. 708 if not (self._A.ndim == 2. 709 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):. --> 710 raise TypeError(""Invalid shape {} for image data"". 711 .format(self._A.shape)). 713 if self._A.ndim == 3:. 714 # If the input data has values outside the valid range (after. 715 # normalisation), we issue a warning and then clip X to the bounds. 716 # - otherwise casting wraps extreme values, hiding outliers and. 717 # making reliable interpretation impossible. 718 high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1. TypeError: Invalid shape (633,) for image data. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.10.1. -----. PIL 9.5.0. anyio NA. arrow 1.3.0. asttokens NA. astunparse 1.6.3. attr 23.1.0. attrs 23.1.0. babel 2.13.0. backcall 0.2.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dask 2023.10.0. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:6834,usability,simpl,simplejson,6834,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3025:7010,usability,tool,toolz,7010,".8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.0. fastjsonschema NA. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. ipykernel 6.25.2. ipywidgets 8.1.1. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.19.1. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.3. jupyterlab_server 2.25.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.41.0. markupsafe 2.1.3. matplotlib 3.7.1. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.58.0. numpy 1.24.3. opt_einsum v3.3.0. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pickleshare 0.7.5. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. pure_eval 0.2.2. pyarrow 15.0.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 2.0.0. pygments 2.16.1. pyparsing 3.0.9. pythoncom NA. pythonjsonlogger NA. pytz 2023.3. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.13.0. send2trash NA. session_info 1.0.0. simplejson 3.19.2. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. sparse 0.14.0. stack_data 0.6.3. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. tlz 0.12.0. toolz 0.12.0. torch 2.0.1+cpu. tornado 6.3.3. tqdm 4.66.1. traitlets 5.10.1. typing_extensions NA. uri_template NA. urllib3 2.0.6. vscode NA. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.3. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.16.1. jupyter_client 8.3.1. jupyter_core 5.3.2. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.11.9 (tags/v3.11.9:de54cf5, Apr 2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-04-23 21:26. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3025
https://github.com/scverse/scanpy/issues/3026:480,availability,cluster,clustering,480,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:509,availability,error,error,509,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:779,availability,Error,Error,779,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:16,deployability,modul,module,16,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:243,deployability,version,version,243,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:480,deployability,cluster,clustering,480,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:588,deployability,modul,module,588,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:968,deployability,modul,module,968,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1046,deployability,modul,module,1046," no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1114,deployability,Version,Versions,1114,"et. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:2467,deployability,updat,updated,2467,"or in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.5. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.3. -----. Python 3.9.0 (default, Oct 6 2020, 11:01:41) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]. Linux-3.10.0-1160.108.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-04-23 14:43. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:243,integrability,version,version,243,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1114,integrability,Version,Versions,1114,"et. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:16,modifiability,modul,module,16,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:243,modifiability,version,version,243,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:588,modifiability,modul,module,588,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:968,modifiability,modul,module,968,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1046,modifiability,modul,module,1046," no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1114,modifiability,Version,Versions,1114,"et. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1275,modifiability,deco,decorator,1275," have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.5. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. noteboo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1647,modifiability,pac,packaging,1647,"or in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.5. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.3. -----. Python 3.9.0 (default, Oct 6 2020, 11:01:41) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]. Linux-3.10.0-1160.108.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-04-23 14:43. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:509,performance,error,error,509,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:779,performance,Error,Error,779,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:16,safety,modul,module,16,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:509,safety,error,error,509,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:588,safety,modul,module,588,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:779,safety,Error,Error,779,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:968,safety,modul,module,968,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1046,safety,modul,module,1046," no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:1310,safety,except,exceptiongroup,1310,"e main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.5. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.3. -----. Python 3.9.0 (default",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:2467,safety,updat,updated,2467,"or in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.5. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.3. -----. Python 3.9.0 (default, Oct 6 2020, 11:01:41) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]. Linux-3.10.0-1160.108.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-04-23 14:43. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:2447,security,Session,Session,2447,"or in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.5. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.3. -----. Python 3.9.0 (default, Oct 6 2020, 11:01:41) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]. Linux-3.10.0-1160.108.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-04-23 14:43. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:2467,security,updat,updated,2467,"or in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.3.2. statsmodels 0.14.0. storemagic NA. threadpoolctl 3.2.0. torch 1.12.1+cu102. tornado 6.1. tqdm 4.66.1. traitlets 5.0.5. typing_extensions NA. umap 0.5.5. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 22.2.1. -----. IPython 7.26.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.3. -----. Python 3.9.0 (default, Oct 6 2020, 11:01:41) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]. Linux-3.10.0-1160.108.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-04-23 14:43. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:894,testability,Trace,Traceback,894,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:203,usability,confirm,confirmed,203,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:286,usability,confirm,confirmed,286,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:383,usability,help,helping,383,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:509,usability,error,error,509,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:655,usability,help,help,655,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:693,usability,Minim,Minimal,693,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:779,usability,Error,Error,779,"AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi,. Thanks a lot for helping! I was following this tutorial (https://scanpy.readthedocs.io/en/stable/tutorials/basics/clustering.html) and get the error in this step: sc.pp.scrublet(adata, batch_key=""sample""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. Can you help with this? Thanks! Best,. B. ### Minimal code sample. ```python. sc.pp.scrublet(adata, batch_key=""lib_prep""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). /tmp/ipykernel_54187/3500521297.py in <module>. ----> 1 sc.pp.scrublet(adata, batch_key=""lib_prep""). AttributeError: module 'scanpy.preprocessing' has no attribute 'scrublet'. ```. ### Versions. <details>. ```. -----. anndata 0.10.3. scanpy 1.9.6. -----. PIL 10.1.0. backcall 0.2.0. cffi 1.14.6. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. decorator 5.0.9. defusedxml 0.7.1. exceptiongroup 1.2.0. get_annotations NA. google NA. h5py 3.10.0. importlib_resources NA. ipykernel 6.2.0. ipython_genutils 0.2.0. ipywidgets 7.6.3. jedi 0.18.0. joblib 1.3.2. kiwisolver 1.4.5. llvmlite 0.41.1. matplotlib 3.8.2. matplotlib_inline NA. mpl_toolkits NA. mudata 0.2.3. muon 0.1.6. natsort 8.4.0. numba 0.58.1. numpy 1.26.2. packaging 21.0. pandas 2.1.3. parso 0.8.2. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.19. ptyprocess 0.7.0. pycparser 2.20. pyexpat NA. pygments 2.10.0. pynndescent 0.5.11. pyparsing 2.4.7. pytz 2023.3.post1. scipy 1.11.4. scrublet NA. seaborn 0.12.2. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3027:1533,availability,Error,Error,1533,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:235,deployability,version,version,235,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1816,deployability,Version,Versions,1816,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:42,integrability,sub,subset,42,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:235,integrability,version,version,235,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:411,integrability,sub,subset,411,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:475,integrability,sub,subset,475,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:553,integrability,sub,subsetting,553,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:969,integrability,Filter,Filter,969,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1091,integrability,Sub,Subset,1091,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1209,integrability,sub,subset,1209,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1228,integrability,Sub,Subset,1228,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1251,integrability,sub,subset,1251,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1395,integrability,Sub,Subset,1395,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1508,integrability,sub,subset,1508,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1816,integrability,Version,Versions,1816,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:235,modifiability,version,version,235,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:815,modifiability,layer,layers,815,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1816,modifiability,Version,Versions,1816,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1533,performance,Error,Error,1533,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1533,safety,Error,Error,1533,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:57,usability,behavi,behavior,57,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:195,usability,confirm,confirmed,195,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:278,usability,confirm,confirmed,278,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:672,usability,Minim,Minimal,672,"Unexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:1533,usability,Error,Error,1533,"nexplainable sc.pp.highly_variable_genes(subset = True) behavior; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When doing HVG selection with batch_key = ""something"" and subset = True, I noticed unexpected genes to be selected in the subset anndata. Upon further investigation, it seems that somehow the inplace subsetting goes wrong. (Though I checked the source code and could not find any issue that may explain it there.). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. np.random.seed(0). # Get AnnData. adata = sc.datasets.pbmc3k(). adata.layers['counts'] = adata.X.copy().tocsr(). adata.obs[""Age""] = np.random.randint(0, 6, (2700,)). adata.obs[""Age""] = adata.obs[""Age""].astype('category'). # Filter genes, preprocess. sc.pp.filter_genes(adata, min_counts = 10). sc.pp.normalize_total(adata). sc.pp.log1p(adata). # Subset = False. ad_nosub = adata.copy(). sc.pp.highly_variable_genes(ad_nosub, n_top_genes = 1000, batch_key = ""Age"", subset = False). # Subset = False, manual subset afterwards. ad_nosub_subbed = ad_nosub.copy(). ad_nosub_subbed._inplace_subset_var(ad_nosub_subbed.var[""highly_variable""].to_numpy()). # Subset = True. ad_sub = adata.copy(). sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True). ```. ### Error output. ```pytb. >>> # As expected. >>> print(np.sum(ad_nosub.var[""highly_variable""])). 1000. >>> . >>> # As expected. >>> print(np.sum(ad_nosub_subbed.var[""highly_variable""])). 1000. >>> . >>> # Not as expected. >>> print(np.sum(ad_sub.var[""highly_variable""])). 101. ```. ### Versions. <details>. ``` bash.  conda list | grep scanpy. scanpy 1.10.1 pyhd8ed1ab_0 conda-forge.  conda list | grep anndata. anndata 0.10.7 pyhd8ed1ab_0 conda-forge. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3028:473,availability,error,error,473,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:519,availability,down,down,519,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:585,availability,error,error,585,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:776,availability,error,error,776,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:935,availability,error,error,935,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1007,availability,error,error,1007,"en with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1029,availability,error,error,1029,"h'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1200,availability,error,error,1200,"t already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. att",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1739,availability,Error,Error,1739,"pe=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:281,deployability,version,version,281,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1286,deployability,version,versions,1286,"f scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2087,deployability,Version,Versions,2087,"=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:4053,deployability,updat,updated,4053,"details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-04-24 08:28. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:281,integrability,version,version,281,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1286,integrability,version,versions,1286,"f scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2087,integrability,Version,Versions,2087,"=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:3014,interoperability,platform,platformdirs,3014,"_rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:281,modifiability,version,version,281,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1286,modifiability,version,versions,1286,"f scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1419,modifiability,pac,packages,1419,"doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2087,modifiability,Version,Versions,2087,"=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2425,modifiability,deco,decorator,2425,"ed in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2952,modifiability,pac,packaging,2952,"ed_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:3911,modifiability,pac,packaged,3911,"details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-04-24 08:28. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:473,performance,error,error,473,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:585,performance,error,error,585,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:636,performance,time,times,636,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:776,performance,error,error,776,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:935,performance,error,error,935,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1007,performance,error,error,1007,"en with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1029,performance,error,error,1029,"h'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1200,performance,error,error,1200,"t already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. att",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1739,performance,Error,Error,1739,"pe=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2241,performance,bottleneck,bottleneck,2241,"class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:423,reliability,doe,doesn,423,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:473,safety,error,error,473,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:585,safety,error,error,585,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:776,safety,error,error,776,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:792,safety,except,except,792,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:935,safety,error,error,935,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1007,safety,error,error,1007,"en with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1029,safety,error,error,1029,"h'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1200,safety,error,error,1200,"t already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. att",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1491,safety,test,test,1491,"o the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1739,safety,Error,Error,1739,"pe=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1762,safety,Except,Exception,1762,"the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:4053,safety,updat,updated,4053,"details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-04-24 08:28. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2273,security,certif,certifi,2273,"ed numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjso",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:2546,security,iso,isoduration,2546,"passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:3532,security,soc,socks,3532,"details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-04-24 08:28. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:4033,security,Session,Session,4033,"details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-04-24 08:28. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:4053,security,updat,updated,4053,"details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numexpr 2.8.7. numpy 1.26.4. overrides NA. packaging 23.1. pandas 2.2.1. parso 0.8.4. pickleshare 0.7.5. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pyparsing 3.1.2. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. ruamel NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. threadpoolctl 3.4.0. tornado 6.4. traitlets 5.14.3. uri_template NA. urllib3 1.26.18. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. -----. Session information updated at 2024-04-24 08:28. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1491,testability,test,test,1491,"o the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1806,testability,Trace,Traceback,1806,"ile referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.26.0. kiwisolver 1.4.5. legacy_api_wrap NA. llvmlite 0.42.0. m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:241,usability,confirm,confirmed,241,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:324,usability,confirm,confirmed,324,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:431,usability,stop,stop,431,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:473,usability,error,error,473,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:554,usability,stop,stop,554,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:585,usability,error,error,585,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:776,usability,error,error,776,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:935,usability,error,error,935,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:970,usability,stop,stops,970,"sc.tl.leiden with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.rando",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1007,usability,error,error,1007,"en with `flavor='igraph'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1029,usability,error,error,1029,"h'` raises an (ignored by igraph) ValueError: high is out of bounds for int32; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1200,usability,error,error,1200,"t already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? When I run the code, it doesn't stop running, just repeatedly returns the error code below into the box (I have to shut down the kernel to get the code to stop running and repeating the error). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. att",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1585,usability,Minim,Minimal,1585,"r). I've tried changing random_state=0 several times. `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` and `numpy.random.randint(0, high=5, dtype=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1739,usability,Error,Error,1739,"pe=numpy.int32)` gave me the same error as below, except the second file referenced line 2881 instead of line 1423. Also, `numpy.random.randint(0, high=2**32-2, dtype=numpy.int32)` returns the error more normally (i.e. the code stops running and returns the normal error box, though the error is the same). `random_state=numpy.random.randint(0, high=2**32-2, dtype=numpy.int64)` and `numpy.random.randint(0, high=5, dtype=numpy.int64)` also gave me the same error as below. `print(numpy.int_)` returns `<class 'numpy.int32'>`. I've tried numpy versions 1.26.3 and 1.24.4 as well. I've also tried uninstalling and reinstalling scanpy, jupyter notebook, and (consequently) other packages used in the tutorials (igraph, leidenalg, etc.). `numpy.random.test(label='full', verbose=2)` returned True, but noted 1322 passed, 6 skipped in 30.78s. ### Minimal code sample. ```python. sc.tl.leiden(. adata, . resolution=0.9,. random_state=0,. flavor=""igraph"",. n_iterations=2,. directed=False,. ). ```. ### Error output. ```pytb. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\\random\\mtrand.pyx"", line 780, in numpy.random.mtrand.RandomState.randint. File ""numpy\\random\\_bounded_integers.pyx"", line 1423, in numpy.random._bounded_integers._rand_int32. ValueError: high is out of bounds for int32. ```. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bottleneck 1.3.7. brotli 1.0.9. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 2.0.4. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.4. ipykernel 6.29.3. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.1. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3029:107,availability,error,error,107,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:510,availability,Error,Error,510,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:56,deployability,version,version,56,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:283,deployability,version,version,283,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:633,deployability,modul,module,633,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:724,deployability,modul,module,724,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:837,deployability,modul,module,837,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:967,deployability,modul,module,967,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1093,deployability,modul,module,1093,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1214,deployability,modul,module,1214,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1428,deployability,Version,Versions,1428,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1486,deployability,log,logging,1486,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:56,integrability,version,version,56,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:283,integrability,version,version,283,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1253,integrability,Sub,SubplotBase,1253,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1360,integrability,sub,subclass,1360,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1428,integrability,Version,Versions,1428,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1294,interoperability,conflict,conflict,1294,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:56,modifiability,version,version,56,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:283,modifiability,version,version,283,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:633,modifiability,modul,module,633,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:724,modifiability,modul,module,724,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:794,modifiability,pac,packages,794,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:837,modifiability,modul,module,837,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:916,modifiability,pac,packages,916,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:967,modifiability,modul,module,967,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1041,modifiability,pac,packages,1041,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1093,modifiability,modul,module,1093,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1164,modifiability,pac,packages,1164,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1214,modifiability,modul,module,1214,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1428,modifiability,Version,Versions,1428,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:107,performance,error,error,107,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:510,performance,Error,Error,510,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:107,safety,error,error,107,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:510,safety,Error,Error,510,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:633,safety,modul,module,633,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:724,safety,modul,module,724,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:837,safety,modul,module,837,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:967,safety,modul,module,967,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1093,safety,modul,module,1093,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1214,safety,modul,module,1214,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1486,safety,log,logging,1486,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1486,security,log,logging,1486,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:533,testability,Trace,Traceback,533,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:1486,testability,log,logging,1486,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:107,usability,error,error,107,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:243,usability,confirm,confirmed,243,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:326,usability,confirm,confirmed,326,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:448,usability,Minim,Minimal,448,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:510,usability,Error,Error,510,"When importing Scanpy 1.9.1, if you're using matplotlib version below 3.7, you might encounter a metaclass error.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? scanpy1.9.1matplotlib3.7. ### Minimal code sample. ```python. import scanpy as sc. ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""G:/stmgcn-main/stmgcn-main/STMGCN/DLPFC.py"", line 15, in <module>. from util import *. File ""G:\stmgcn-main\stmgcn-main\STMGCN\util.py"", line 1, in <module>. import scanpy as sc. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\__init__.py"", line 16, in <module>. from . import plotting as pl. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\__init__.py"", line 1, in <module>. from ._anndata import (. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_anndata.py"", line 28, in <module>. from . import _utils. File ""E:\Anaconda3\envs\stmgcn\lib\site-packages\scanpy\plotting\_utils.py"", line 35, in <module>. class _AxesSubplot(Axes, axes.SubplotBase, ABC):. TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases. ,1. ```. ### Versions. You can't get to on account of the crash.scanpy.logging.print_versions().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3030:20,deployability,scale,scaled,20,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:312,deployability,scale,scaled,312,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1817,deployability,scale,scaled,1817,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1896,deployability,scale,scaled,1896,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:20,energy efficiency,scale,scaled,20,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:312,energy efficiency,scale,scaled,312,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1817,energy efficiency,scale,scaled,1817,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1896,energy efficiency,scale,scaled,1896,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1465,integrability,sub,subset,1465,", I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:262,interoperability,Specif,Specifically,262,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:20,modifiability,scal,scaled,20,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:312,modifiability,scal,scaled,312,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:569,modifiability,scal,scaling,569,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1360,modifiability,scenario,scenario,1360,"ing sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1817,modifiability,scal,scaled,1817,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1896,modifiability,scal,scaled,1896,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:20,performance,scale,scaled,20,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:312,performance,scale,scaled,312,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1817,performance,scale,scaled,1817,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1896,performance,scale,scaled,1896,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1687,security,ident,identify,1687,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:341,testability,unit,unit,341,"Loophole with using scaled adata for sc.tl.score_genes_cell_cycle; I have a question regarding the recommendations provided in : . https://github.com/scverse/scanpy_usage/blob/master/180209_cell_cycle/cell_cycle.ipynb. to compute cell cycle scores using Scanpy. Specifically it mentions that the adata should be scaled to have zero mean and unit variance before using sc.tl.score_genes_cell_cycle. But when I look at the source code, particularly the part pasted below, I notice that unless the 'use_raw' option is set to True, obs_avg will be zero for the adata after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:1976,usability,confirm,confirmations,1976,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/issues/3030:2006,usability,help,helpful,2006,"a after scaling assuming gene_pool is not set. ___________________________________________________________________________________________. _adata = adata.raw if use_raw else adata. _adata_subset = (. _adata[:, gene_pool] if len(gene_pool) < len(_adata.var_names) else _adata. ). # average expression of genes. if issparse(_adata_subset.X):. obs_avg = pd.Series(. np.array(_sparse_nanmean(_adata_subset.X, axis=0)).flatten(),. index=gene_pool,. ). else:. obs_avg = pd.Series(np.nanmean(_adata_subset.X, axis=0), index=gene_pool). # Sometimes (and I don't know how) missing data may be there, with nansfor. obs_avg = obs_avg[np.isfinite(obs_avg)]. _____________________________________________________________________________________________. How is the selection of control_genes meaningful in this scenario? We will basically have, control_genes=min(len(s_genes, g2m_genes)) which is a randomly sampled subset of the total genes but this won't have this feature of selecting genes that are similar in expression levels to the marker gene list. I think we should find control_genes using the expression data in the raw adata, identify the control_genes using the binning procedure below and then calculate s_scores and g2m_scores for these genes using the scaled data if that is necessary (mean of these randomly selected genes in the scaled adata expression matrix). I hope this makes sense. Any clarifications or confirmations would be really helpful. . _____________________________________________________________________________________________. n_items = int(np.round(len(obs_avg) / (n_bins - 1))). obs_cut = obs_avg.rank(method=""min"") // n_items. control_genes = pd.Index([], dtype=""string""). # now pick `ctrl_size` genes from every cut. for cut in np.unique(obs_cut.loc[gene_list]):. r_genes: pd.Index[str] = obs_cut[obs_cut == cut].index. if ctrl_size < len(r_genes):. r_genes = r_genes.to_series().sample(ctrl_size).index. control_genes = control_genes.union(r_genes.difference(gene_list)).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3030
https://github.com/scverse/scanpy/pull/3031:621,availability,slo,slow,621,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:461,deployability,releas,release,461,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:486,deployability,Releas,Release,486,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:0,modifiability,Exten,Extend,0,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:621,reliability,slo,slow,621,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:258,safety,review,review,258,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:363,safety,Test,Tests,363,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:258,testability,review,review,258,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:363,testability,Test,Tests,363,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:109,usability,guid,guidelines,109,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:140,usability,guid,guide,140,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:236,usability,workflow,workflow,236,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3031:342,usability,Close,Closes,342,"Extend benchmarks from basic tutorial; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3012 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. I added a sparse dataset to cover more code paths in most benchmarks. `regress_out` seems pretty slow with sparse data, maybe that should be tackled instead of hidden by disabling the benchmark.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3034:13,deployability,version,version,13,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:455,deployability,releas,release,455,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:480,deployability,Releas,Release,480,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:543,deployability,releas,released,543,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:603,deployability,instal,installed,603,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:13,integrability,version,version,13,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:13,modifiability,version,version,13,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:592,reliability,doe,does,592,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:253,safety,review,review,253,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:357,safety,Test,Tests,357,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:620,safety,test,test,620,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:253,testability,review,review,253,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:357,testability,Test,Tests,357,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:620,testability,test,test,620,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:104,usability,guid,guidelines,104,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:135,usability,guid,guide,135,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:231,usability,workflow,workflow,231,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3034:337,usability,Close,Closes,337,Relax pytest version restriction; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2993. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: dev change. Pytest 8.2 is released and should solve the problem. /edit: it does. Its installed in the test jobs and works.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3034
https://github.com/scverse/scanpy/pull/3035:14,safety,test,test,14,Fix benchmark test run; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035
https://github.com/scverse/scanpy/pull/3035:243,safety,review,review,243,Fix benchmark test run; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035
https://github.com/scverse/scanpy/pull/3035:14,testability,test,test,14,Fix benchmark test run; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035
https://github.com/scverse/scanpy/pull/3035:243,testability,review,review,243,Fix benchmark test run; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035
https://github.com/scverse/scanpy/pull/3035:94,usability,guid,guidelines,94,Fix benchmark test run; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035
https://github.com/scverse/scanpy/pull/3035:125,usability,guid,guide,125,Fix benchmark test run; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035
https://github.com/scverse/scanpy/pull/3035:221,usability,workflow,workflow,221,Fix benchmark test run; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3035
https://github.com/scverse/scanpy/pull/3036:49,deployability,version,version,49,Backport PR #3034 on branch 1.10.x (Relax pytest version restriction); Backport PR #3034: Relax pytest version restriction,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3036
https://github.com/scverse/scanpy/pull/3036:103,deployability,version,version,103,Backport PR #3034 on branch 1.10.x (Relax pytest version restriction); Backport PR #3034: Relax pytest version restriction,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3036
https://github.com/scverse/scanpy/pull/3036:49,integrability,version,version,49,Backport PR #3034 on branch 1.10.x (Relax pytest version restriction); Backport PR #3034: Relax pytest version restriction,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3036
https://github.com/scverse/scanpy/pull/3036:103,integrability,version,version,103,Backport PR #3034 on branch 1.10.x (Relax pytest version restriction); Backport PR #3034: Relax pytest version restriction,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3036
https://github.com/scverse/scanpy/pull/3036:49,modifiability,version,version,49,Backport PR #3034 on branch 1.10.x (Relax pytest version restriction); Backport PR #3034: Relax pytest version restriction,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3036
https://github.com/scverse/scanpy/pull/3036:103,modifiability,version,version,103,Backport PR #3034 on branch 1.10.x (Relax pytest version restriction); Backport PR #3034: Relax pytest version restriction,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3036
https://github.com/scverse/scanpy/pull/3037:50,safety,test,test,50,Backport PR #3035 on branch 1.10.x (Fix benchmark test run); Backport PR #3035: Fix benchmark test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3037
https://github.com/scverse/scanpy/pull/3037:94,safety,test,test,94,Backport PR #3035 on branch 1.10.x (Fix benchmark test run); Backport PR #3035: Fix benchmark test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3037
https://github.com/scverse/scanpy/pull/3037:50,testability,test,test,50,Backport PR #3035 on branch 1.10.x (Fix benchmark test run); Backport PR #3035: Fix benchmark test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3037
https://github.com/scverse/scanpy/pull/3037:94,testability,test,test,94,Backport PR #3035 on branch 1.10.x (Fix benchmark test run); Backport PR #3035: Fix benchmark test run,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3037
https://github.com/scverse/scanpy/pull/3040:463,deployability,releas,release,463,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:488,deployability,Releas,Release,488,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:260,safety,review,review,260,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:365,safety,Test,Tests,365,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:4,security,triag,triage,4,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:260,testability,review,review,260,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:365,testability,Test,Tests,365,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:20,usability,user,user,20,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:111,usability,guid,guidelines,111,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:142,usability,guid,guide,142,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:238,usability,workflow,workflow,238,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3040:344,usability,Close,Closes,344,Add triage label to user created issues; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3010 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:. no need to backport github changes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3040
https://github.com/scverse/scanpy/pull/3041:659,availability,slo,slowdown,659,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:437,deployability,releas,release,437,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:462,deployability,Releas,Release,462,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:739,modifiability,Paramet,Parameter,739,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:530,performance,perform,performance,530,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:659,reliability,slo,slowdown,659,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:235,safety,review,review,235,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:339,safety,Test,Tests,339,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:235,testability,review,review,235,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:339,testability,Test,Tests,339,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:86,usability,guid,guidelines,86,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:117,usability,guid,guide,117,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:213,usability,workflow,workflow,213,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:319,usability,Close,Closes,319,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:530,usability,perform,performance,530,Use modern RNG; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #2969. - [ ] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. Seems like this code is super performance sensitive: Having a Python implementation of `getrandbits` in 8572ecb1b38616f98f2af6462aa4fe5a3a8871ae resulted in a slowdown:. | Change | Before [0d4554b4] | After [1b2d9dd5] | Ratio | Benchmark (Parameter) |. |----------|----------------------|---------------------|---------|------------------------------------------|. | + | 15.20.03ms |	31.70.1ms |	2.09 | preprocessing.time_highly_variable_genes |.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3042:482,deployability,releas,release,482,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:507,deployability,Releas,Release,507,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:39,integrability,batch,batch,39,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:53,integrability,sub,subset,53,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:830,integrability,batch,batch,830,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:706,modifiability,refact,refactor,706,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:39,performance,batch,batch,39,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:706,performance,refactor,refactor,706,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:830,performance,batch,batch,830,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:280,safety,review,review,280,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:384,safety,Test,Tests,384,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:619,safety,test,test,619,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:280,testability,review,review,280,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:384,testability,Test,Tests,384,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:619,testability,test,test,619,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:131,usability,guid,guidelines,131,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:162,usability,guid,guide,162,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:258,usability,workflow,workflow,258,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:364,usability,Close,Closes,364,"hvg flavors seurat and cellranger with batch: bug in subset; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3027. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because: they are, added. This PR fixes the bug reported in the linked issue. A new test which spots the erroneous computations has been added. I would use this chance to refactor the `_highly_variable_genes.py`, rather than using the 2-lines fix suggested in the first commit:. Doing the multi-batch hvg flagging differently for seurat_v3 and seurat/cell_ranger is what made this bug hard to spot in the first place I think.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3043:974,deployability,releas,release,974," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:1000,deployability,Releas,Release,1000," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:41,energy efficiency,heat,heatmap,41," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:269,safety,review,review,269," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:867,safety,Test,Tests,867," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:269,testability,review,review,269," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:867,testability,Test,Tests,867," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:120,usability,guid,guidelines,120," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:151,usability,guid,guide,151," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3043:247,usability,workflow,workflow,247," Add colorblocks to baseplot similar to heatmap; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Hi there, . I wrote a color annotation function for the Baseplot class called `add_colorblocks()`, which borrows some functionality of the `add_totals()` function and creates a colorblock for the annotation each assigned group. ```. sc.pl.dotplot(adata, [""CD79A"", ""MS4A1""], ""bulk_labels"", return_fig=True, show=False,. #swap_axes=True. ).add_colorblocks(color='Paired', size=0.1).show(). ```. ![image](https://github.com/scverse/scanpy/assets/24408322/eb50f18c-8fd7-4586-b63c-41c4e4f44a93). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Addresses #2194. - [x] Tests included or not required because: plotting. <!-- Only check the following box if you did not include release notes -->. - [ x] Release notes not necessary because: tbd.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3043
https://github.com/scverse/scanpy/pull/3047:30,usability,learn,learn,30,"Fixes for sklearn 1.5; Scikit-learn 1.5.0 will no longer have `issparse` exported, so lets import it from where it belongs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3048:16,availability,error,errors,16,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:314,availability,error,errors,314,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1444,deployability,releas,release,1444,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1469,deployability,Releas,Release,1469,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:354,energy efficiency,current,currently,354,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:578,energy efficiency,core,core,578,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:701,energy efficiency,current,current,701,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:599,modifiability,deco,decorator,599,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:663,modifiability,deco,decorator,663,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:16,performance,error,errors,16,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:314,performance,error,errors,314,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:16,safety,error,errors,16,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:275,safety,review,review,275,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:314,safety,error,errors,314,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1346,safety,Test,Tests,1346,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:275,testability,review,review,275,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1346,testability,Test,Tests,1346,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:16,usability,error,errors,16,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:45,usability,support,supported,45,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:126,usability,guid,guidelines,126,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:157,usability,guid,guide,157,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:253,usability,workflow,workflow,253,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:314,usability,error,errors,314,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:896,usability,support,support,896,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1069,usability,support,support,1069,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1120,usability,support,support,1120,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1309,usability,Close,Closes,1309,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:1326,usability,close,closes,1326,"(feat): raising errors where `backed` is not supported; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. The idea here is to raise errors where I have checked that things currently don't work, regardless of the reason why, and do not make any attempt to fix this problem. Once https://github.com/scverse/anndata/pull/1469 is merged, we can make concrete recommendations for how to handle out-of-core data. I think a decorator could work but we would have to check the type in the decorator like (instead of relying on current checks like in `filter_genes`):. ```python. if isinstance(arg1, AnnData) and arg1.isbacked:. raise NotImplementedErrror(...). ```. But then there is something like `log1p` where we quasi-support `backed` via this `chunked` kwarg, which would no really fit the above paradigm. Nonetheless, I think I need to go one-by-one through the functions to check what we support and don't. Separately, we may want to drop support where it exists already (which from my searching, is only `obs_df` and `var_df` and then `subsample_counts`). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3004 and closes #2894. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/issues/3049:336,availability,error,error,336,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:443,energy efficiency,Current,Currently,443,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:151,modifiability,paramet,parameters,151,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:336,performance,error,error,336,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:274,reliability,doe,doesn,274,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:336,safety,error,error,336,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:31,usability,support,support,31,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:282,usability,support,support,282,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:336,usability,error,error,336,"will rank_genes_groups_dotplot support results from filter_rank_genes_groups?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It seems rank_genes_groups_dotplot doesn't support the results from filter_rank_genes_groups? An error raised:. Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3051:73,deployability,contain,contain,73,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:93,deployability,contain,contains,93,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:431,deployability,log,logarithmized,431,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:465,integrability,filter,filtered,465,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:272,interoperability,standard,standard-,272,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:5,safety,compl,complete,5,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:431,safety,log,logarithmized,431,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:5,security,compl,complete,5,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:431,security,log,logarithmized,431,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:431,testability,log,logarithmized,431,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:22,usability,document,documentation,22,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:52,usability,document,documentation,52,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:309,usability,clear,clear,309,"More complete dataset documentation; Each datasets documentation should contain. 1. what it contains (listing obs, ). 2. what steps have been run on it. 3. better links (e.g. is pbmc68k_reduced [this one](https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0)? the docstring isnt clear. It was added by @fidelram in https://github.com/scverse/scanpy/pull/228 ). Especially important is if its `.X` is logarithmized, normalized, and/or filtered. See also: https://github.com/orgs/scverse/projects/18/views/1?pane=issue&itemId=62702062. cc @ilan-gold",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3052:456,availability,reliab,reliably,456,"Switch away from asv; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Its basically unmaintained: https://github.com/airspeed-velocity/asv/issues/1219. In https://github.com/scverse/scanpy/pull/3031, I ran into https://github.com/airspeed-velocity/asv/issues/966 which seems to make it almost unusable for our purposes. We need `setup` to run reliably.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3052
https://github.com/scverse/scanpy/issues/3052:94,modifiability,paramet,parameters,94,"Switch away from asv; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Its basically unmaintained: https://github.com/airspeed-velocity/asv/issues/1219. In https://github.com/scverse/scanpy/pull/3031, I ran into https://github.com/airspeed-velocity/asv/issues/966 which seems to make it almost unusable for our purposes. We need `setup` to run reliably.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3052
https://github.com/scverse/scanpy/issues/3052:456,reliability,reliab,reliably,456,"Switch away from asv; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Its basically unmaintained: https://github.com/airspeed-velocity/asv/issues/1219. In https://github.com/scverse/scanpy/pull/3031, I ran into https://github.com/airspeed-velocity/asv/issues/966 which seems to make it almost unusable for our purposes. We need `setup` to run reliably.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3052
https://github.com/scverse/scanpy/issues/3054:490,availability,robust,robust,490,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1009,availability,robust,robust,1009,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1151,availability,cluster,clustering,1151,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:84,deployability,API,API,84,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:334,deployability,API,API,334,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:815,deployability,API,API,815,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1151,deployability,cluster,clustering,1151,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:657,energy efficiency,power,power,657,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1209,energy efficiency,model,model,1209,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1284,energy efficiency,model,model,1284,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:84,integrability,API,API,84,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:334,integrability,API,API,334,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:445,integrability,transform,transform,445,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:815,integrability,API,API,815,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1242,integrability,transform,transform,1242,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1319,integrability,interfac,interface,1319,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:84,interoperability,API,API,84,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:334,interoperability,API,API,334,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:445,interoperability,transform,transform,445,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:815,interoperability,API,API,815,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1023,interoperability,specif,specifically,1023,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1242,interoperability,transform,transform,1242,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1319,interoperability,interfac,interface,1319,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:161,modifiability,paramet,parameters,161,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:863,modifiability,pac,package,863,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1001,modifiability,pac,package,1001,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1319,modifiability,interfac,interface,1319,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:490,reliability,robust,robust,490,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1009,reliability,robust,robust,1009,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:490,safety,robust,robust,490,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:929,safety,test,tests,929,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1009,safety,robust,robust,1009,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:0,security,Access,Access,0,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:549,security,access,accessible,549,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1209,security,model,model,1209,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1284,security,model,model,1284,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:929,testability,test,tests,929,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:944,testability,simpl,simple,944,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:72,usability,Learn,Learn,72,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:271,usability,help,helpful,271,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:305,usability,tool,tools,305,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:322,usability,learn,learn,322,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:564,usability,user,users,564,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:711,usability,workflow,workflow,711,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:944,usability,simpl,simple,944,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1333,usability,user,users,1333,"Access to Diffusion Map methods (and other embedding methods) as Scikit-Learn style API; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be extremely helpful if the embedding manifold tools had scikit-learn style API. . For example, https://pydiffmap.readthedocs.io/en/master/reference/diffusion_map.html. Having the .fit, .transform, and .fit_transform would make the robust implementations in the backend of ScanPy a lot more accessible for users. Right now, the usage feels a bit restrictive and I'm having difficulty leveraging the power of the methods if it's not part of some similar workflow that is in the tutorials. . I'm trying to use the code in the backend of ScanPy implement this API myself but ScanPy is an extremely confusing package from an outside developer. There are nested functions and tests for even simple steps (many of which handle edge cases making the package robust). More specifically, I'm trying to use the ScanPy implementation of Diffusion Maps as I would use those from pyDiffMap or the spectral clustering from Sklearn. I would like to be able to fit a model with data. Pickle it. Then transform new samples based on the fitted model. This would provide a useful interface for users looking for a non linear alternative to pca.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/pull/3056:36,modifiability,Exten,Extend,36,Backport PR #3031 on branch 1.10.x (Extend benchmarks from basic tutorial); Backport PR #3031: Extend benchmarks from basic tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3056
https://github.com/scverse/scanpy/pull/3056:95,modifiability,Exten,Extend,95,Backport PR #3031 on branch 1.10.x (Extend benchmarks from basic tutorial); Backport PR #3031: Extend benchmarks from basic tutorial,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3056
https://github.com/scverse/scanpy/pull/3057:202,interoperability,plug,plugin,202,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:285,interoperability,plug,plugin,285,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:390,interoperability,plug,plugin,390,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:4,safety,test,testing,4,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:238,safety,test,tests,238,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:451,safety,test,testing,451,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:479,safety,test,testing,479,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:556,safety,test,testing,556,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:4,testability,test,testing,4,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:173,testability,coverag,coverage,173,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:238,testability,test,tests,238,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:373,testability,coverag,coverage,373,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:451,testability,test,testing,451,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:479,testability,test,testing,479,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3057:556,testability,test,testing,556,"Fix testing; Fixes the doctest setup that was broken in https://github.com/scverse/scanpy/pull/2874. The goal here is to make `_modify_doctests` work again without breaking coverage. That means. 1. the plugin cant be imported in `scanpy/tests` but has to be imported globally. 2. the plugin has to live outside of `scanpy` since importing scanpy while importing it breaks coverage. 1. The plugin cant import scanpy at the top level (neither `import testing.scanpy` nor `import testing.scanpy._pytest` is allowed to transitively `import scanpy`). having `testing.scanpy` in `src` and `scanpy` in the root of the repo is a bit gross, but better than adding even more top level stuff",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3057
https://github.com/scverse/scanpy/pull/3059:40,safety,test,testing,40,Backport PR #3057 on branch 1.10.x (Fix testing); Backport PR #3057: Fix testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3059
https://github.com/scverse/scanpy/pull/3059:73,safety,test,testing,73,Backport PR #3057 on branch 1.10.x (Fix testing); Backport PR #3057: Fix testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3059
https://github.com/scverse/scanpy/pull/3059:40,testability,test,testing,40,Backport PR #3057 on branch 1.10.x (Fix testing); Backport PR #3057: Fix testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3059
https://github.com/scverse/scanpy/pull/3059:73,testability,test,testing,73,Backport PR #3057 on branch 1.10.x (Fix testing); Backport PR #3057: Fix testing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3059
https://github.com/scverse/scanpy/pull/3060:897,availability,down,download,897,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:914,availability,down,downloaded,914,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:440,deployability,releas,release,440,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:465,deployability,Releas,Release,465,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:516,deployability,releas,release,516,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:644,deployability,continu,continue,644,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:1067,deployability,build,build,1067,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:1081,deployability,api,api,1081,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:1081,integrability,api,api,1081,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:1081,interoperability,api,api,1081,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:608,performance,cach,caching,608,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:841,performance,cach,caching,841,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:943,performance,cach,cached,943,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:996,performance,cach,caching,996,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:238,safety,review,review,238,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:342,safety,Test,Tests,342,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:591,safety,test,tests,591,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:677,safety,test,tests,677,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:727,safety,test,tests,727,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:821,safety,test,tests,821,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:934,safety,valid,validate,934,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:984,safety,test,tests,984,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:934,security,validat,validate,934,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:238,testability,review,review,238,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:342,testability,Test,Tests,342,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:591,testability,test,tests,591,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:677,testability,test,tests,677,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:727,testability,test,tests,727,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:821,testability,test,tests,821,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:984,testability,test,tests,984,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:0,usability,Document,Document,0,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:89,usability,guid,guidelines,89,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:120,usability,guid,guide,120,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:216,usability,workflow,workflow,216,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:322,usability,Close,Closes,322,"Document datasets; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3051. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:. TODO:. - [x] release notes. - [x] some added text explaining things. - [x] run internet tests, implement caching for datasets. Optional:. 1. continue to not run the internet tests in CI. A side effect of this PR is that our tests get less flaky by not running the flaky `ebi_expression_atlas` doctest. 2. run internet tests in CI. 1. add caching to CI. 2. make sure the dataset functions dont download already-downloaded data. 3. validate cached data instead. 4. run the internet tests (with caching) in CI. ## [Rendered](https://icb-scanpy--3060.com.readthedocs.build/en/3060/api/datasets.html)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3061:620,availability,cluster,cluster,620,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:857,availability,Down,Downloading,857,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:892,availability,down,download,892,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1691,availability,cluster,clusters,1691,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1805,availability,cluster,cluster,1805,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:620,deployability,cluster,cluster,620,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1691,deployability,cluster,clusters,1691,"lterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1805,deployability,cluster,cluster,1805,"ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2510,deployability,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3333,deployability,scale,scale,3333,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3362,deployability,scale,scale,3362,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3403,deployability,scale,scale,3403,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:4091,deployability,releas,release,4091,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:4113,deployability,Releas,Release,4113,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:6,energy efficiency,optim,optimization,6,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2071,energy efficiency,reduc,reduce,2071,"ial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3333,energy efficiency,scale,scale,3333,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3362,energy efficiency,scale,scale,3362,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3403,energy efficiency,scale,scale,3403,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:693,integrability,filter,filterwarnings,693,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1173,integrability,filter,filtering,1173,"ocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1217,integrability,Filter,Filter,1217,"arize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1300,integrability,Filter,Filter,1300,"rates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1356,integrability,filter,filtering,1356,"ing in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normal",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1398,integrability,Filter,Filter,1398,"vement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1562,integrability,compon,components,1562,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1632,integrability,compon,components,1632,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2408,integrability,filter,filter,2408,"nes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale ti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2808,integrability,Filter,Filter,2808,"r. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1562,interoperability,compon,components,1562,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1632,interoperability,compon,components,1632,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:444,modifiability,pac,package,444,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1489,modifiability,variab,variable,1489,"nt was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1562,modifiability,compon,components,1562,"port pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1632,modifiability,compon,components,1632,"eans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2562,modifiability,variab,variable,2562,"onents to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2830,modifiability,variab,variable,2830," jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3333,modifiability,scal,scale,3333,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3362,modifiability,scal,scale,3362,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3403,modifiability,scal,scale,3403,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:6,performance,optimiz,optimization,6,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:539,performance,time,time,539,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1826,performance,parallel,parallel,1826,"xists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1898,performance,time,time,1898,"('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1903,performance,time,time,1903,"ps://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1914,performance,time,time,1914,"-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1919,performance,time,time,1919,"le-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2018,performance,time,time,2018,"enes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2032,performance,time,time,2032,"E_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2037,performance,time,time,2037,"FIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2053,performance,time,time,2053,"efix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2058,performance,time,time,2058,"for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_coun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2429,performance,time,time,2429,"er cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.tim",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2443,performance,time,time,2443,"this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2448,performance,time,time,2448," n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2464,performance,time,time,2464,"000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2469,performance,time,time,2469," Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2514,performance,time,time,2514," PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2528,performance,time,time,2528,"ents = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.Scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2533,performance,time,time,2533,"= 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyCon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2894,performance,time,time,2894,"t=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2899,performance,time,time,2899,"e.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3300,performance,time,time,3300,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3314,performance,time,time,3314,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3319,performance,time,time,3319,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3333,performance,scale,scale,3333,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3343,performance,time,time,3343,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3348,performance,time,time,3348,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3362,performance,scale,scale,3362,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3403,performance,scale,scale,3403,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3409,performance,time,time,3409,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3423,performance,time,time,3423,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3428,performance,time,time,3428,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3444,performance,time,time,3444,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3449,performance,time,time,3449,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3500,performance,time,time,3500,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3505,performance,time,time,3505,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3871,performance,time,time,3871,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3879,performance,time,time,3879,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3884,performance,time,time,3884,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:266,safety,review,review,266,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2510,safety,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3988,safety,Test,Tests,3988,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2510,security,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:266,testability,review,review,266,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:741,testability,simpl,simplefilter,741,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1087,testability,regress,regress,1087,"ase be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2510,testability,log,log,2510,"n. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time().",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:2908,testability,Regress,Regress,2908,"r=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Ple",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3288,testability,regress,regress,3288,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3988,testability,Test,Tests,3988,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:32,usability,learn,learn-intelex,32,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:117,usability,guid,guidelines,117,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:148,usability,guid,guide,148,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:244,usability,workflow,workflow,244,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:332,usability,learn,learn-intelex,332,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:741,usability,simpl,simplefilter,741,"t-SNE optimization using scikit-learn-intelex; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:1156,usability,visual,visualization,1156,"scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This pull request accelerates t-SNE using the scikit-learn-intelex library, resulting in approximately a 10x runtime improvement for the t-SNE implementation in the package for the given example below. The experiment was run on AWS r7i.24xlarge. ```py. import time. import numpy as np. import pandas as pd. import scanpy as sc. from sklearn.cluster import KMeans. import os. import wget. import warnings. warnings.filterwarnings('ignore', 'Expected '). warnings.simplefilter('ignore'). input_file = ""./1M_brain_cells_10X.sparse.h5ad"". if not os.path.exists(input_file):. print('Downloading import file...'). wget.download('https://rapids-single-cell-examples.s3.us-east-2.amazonaws.com/1M_brain_cells_10X.sparse.h5ad',input_file). # marker genes. MITO_GENE_PREFIX = ""mt-"" # Prefix for mitochondrial genes to regress out. markers = [""Stmn2"", ""Hes1"", ""Olig1""] # Marker genes for visualization. # filtering cells. min_genes_per_cell = 200 # Filter out cells with fewer genes than this expressed. max_genes_per_cell = 6000 # Filter out cells with more genes than this expressed. # filtering genes. min_cells_per_gene = 1 # Filter out genes expressed in fewer cells than this. n_top_genes = 4000 # Number of highly variable genes to retain. # PCA. n_components = 50 # Number of principal components to compute. # t-SNE. tsne_n_pcs = 20 # Number of principal components to use for t-SNE. # k-means. k = 35 # Number of clusters for k-means. # Gene ranking. ranking_n_top_genes = 50 # Number of differential genes to compute for each cluster. # Number of parallel jobs. sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). start=time.time(). tr=time.time(). adata = sc.read(input_file). adata.var_names_make_unique(). adata.shape. print(""Total read time : %s"" % (time.time()-tr)). tr=time.time(). # To reduce the number of cells:. USE_FIRST_N_CELLS = 1300000. adata = adata[0:USE_FIRST_N_CELLS]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3673,usability,tool,tools,3673,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:3972,usability,Close,Closes,3972,"_N_CELLS]. adata.shape. sc.pp.filter_cells(adata, min_genes=min_genes_per_cell). sc.pp.filter_cells(adata, max_genes=max_genes_per_cell). sc.pp.filter_genes(adata, min_cells=min_cells_per_gene). sc.pp.normalize_total(adata, target_sum=1e4). print(""Total filter and normalize time : %s"" % (time.time()-tr)). tr=time.time(). sc.pp.log1p(adata). print(""Total log time : %s"" % (time.time()-tr)). # Select highly variable genes. sc.pp.highly_variable_genes(adata, n_top_genes=n_top_genes, flavor = ""cell_ranger""). # Retain marker gene expression. for marker in markers:. adata.obs[marker + ""_raw""] = adata.X[:, adata.var.index == marker].toarray().ravel(). # Filter matrix to only variable genes. adata = adata[:, adata.var.highly_variable]. ts=time.time(). #Regress out confounding factors (number of counts, mitochondrial gene expression). mito_genes = adata.var_names.str.startswith(MITO_GENE_PREFIX). n_counts = np.array(adata.X.sum(axis=1)). adata.obs['percent_mito'] = np.array(np.sum(adata[:, mito_genes].X, axis=1)) / n_counts. adata.obs['n_counts'] = n_counts. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). print(""Total regress out time : %s"" % (time.time()-ts)). #scale. ts=time.time(). sc.pp.scale(adata, max_value=10). print(""Total scale time : %s"" % (time.time()-ts)). t0=time.time(). sc.tl.pca(adata, n_comps=n_components). t0=time.time(). sc._settings.ScanpyConfig.n_jobs = os.cpu_count(). sc.tl.tsne(adata, n_pcs=tsne_n_pcs, use_fast_tsne=True). '''. from sklearn.manifold import TSNE. from scanpy.tools._utils import _choose_representation. X = _choose_representation(adata, n_pcs=tsne_n_pcs). X_tsne = TSNE().fit_transform(X.astype(np.float32)). adata.obsm['X_tsne'] = X_tsne. '''. print(""Tsne time:"", time.time()-t0). ``` . . <!-- Please check (- [x]) and fill in the following boxes . - [ ] Closes #. - [ ] Tests included or not required because:. -->. <!-- Only check the following box if you did not include release notes . - [ ] Release notes not necessary because:. -->",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/issues/3062:1971,availability,Error,Error,1971,"_do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1995,availability,Error,Error,1995,"alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyproces",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:235,deployability,version,version,235,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:567,deployability,compos,compose,567,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:633,deployability,observ,observations,633,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:2069,deployability,Version,Versions,2069,"below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:3642,deployability,updat,updated,3642,"``python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. zarr 2.14.2. zc NA. zipp NA. zoneinfo NA. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-05-15 18:46. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:2243,energy efficiency,cloud,cloudpickle,2243,"lot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:235,integrability,version,version,235,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:2069,integrability,Version,Versions,2069,"below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1516,interoperability,mismatch,mismatching,1516," requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:235,modifiability,version,version,235,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:567,modifiability,compos,compose,567,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:2069,modifiability,Version,Versions,2069,"below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:2360,modifiability,deco,decorator,2360,"erse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:2860,modifiability,pac,packaging,2860,"``python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. zarr 2.14.2. zc NA. zipp NA. zoneinfo NA. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-05-15 18:46. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:3510,modifiability,pac,packaged,3510,"``python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. zarr 2.14.2. zc NA. zipp NA. zoneinfo NA. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-05-15 18:46. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1971,performance,Error,Error,1971,"_do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1995,performance,Error,Error,1995,"alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyproces",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1971,safety,Error,Error,1971,"_do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1995,safety,Error,Error,1995,"alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyproces",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:2439,safety,except,exceptiongroup,2439,"e erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. za",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:3642,safety,updat,updated,3642,"``python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. zarr 2.14.2. zc NA. zipp NA. zoneinfo NA. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-05-15 18:46. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:3622,security,Session,Session,3622,"``python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. zarr 2.14.2. zc NA. zipp NA. zoneinfo NA. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-05-15 18:46. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:3642,security,updat,updated,3642,"``python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. zarr 2.14.2. zc NA. zipp NA. zoneinfo NA. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-05-15 18:46. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:633,testability,observ,observations,633,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:195,usability,confirm,confirmed,195,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:278,usability,confirm,confirmed,278,"Wrongly ordered DotPlot totals in `scanpy` 1.10.1 with Pandas 1.x; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? In `scanpy-1.9.8` DotPlots the default ordering of categories is alphabetical, adjusting to what was requested via `groupby`. This also worked when multiple columns were requested, eliminating the need to manually compose the alphabetical ordering of all existing combinations of observations in the plot. The default ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1665,usability,Minim,Minimal,1665,"t ordering in `scanpy>=1.10.0` DotPlots has changed, and resulting plots display wrong data:. - Ordering is no longer alphabetical. It seems that the categories are being ordered as if a dendrogram had been requested. - Additionally, when adding totals with `add_totals()`, the bar plots with cell counts _do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1971,usability,Error,Error,1971,"_do_ follow the default alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1995,usability,Error,Error,1995,"alphabetical ordering, making the plot display wrong data (!). The example below shows the misbehaviour using the example in https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html. Using the code example below; here is the expected plot with `scanpy-1.9.8` (same result as in the URL above):. <img width=""463"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/3f32bc81-8e7a-4f41-b3f6-09e5937f2b6d"">. and here is the erroneous result with `scanpy-1.10.1` and `1.10.0` (wrong ordering, mismatching totals):. <img width=""456"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/14fe6419-2f1b-4ec9-b3d8-e42ad3930e32"">. ### Minimal code sample. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyproces",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:3314,usability,tool,toolz,3314,"``python. import scanpy as sc. pbmc = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}. dp = sc.pl.dotplot(pbmc, markers, 'bulk_labels', return_fig=True). dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). ```. ### Error output. ```pytb. (Error output is a bad plot, included in the description above.). ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. IPython 8.13.2. PIL 10.0.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.0. dask 2023.10.1. dateutil 2.8.2. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.6. dot_parser NA. entrypoints 0.4. exceptiongroup 1.1.1. executing 1.2.0. fasteners 0.17.3. flytekitplugins NA. gmpy2 2.1.2. google NA. h5py 3.8.0. icu 2.11. igraph 0.11.2. jedi 0.19.1. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. lz4 4.3.2. markupsafe 2.1.2. matplotlib 3.8.3. mpl_toolkits NA. mpmath 1.3.0. msgpack 1.0.5. natsort 8.3.1. numba 0.59.1. numcodecs 0.11.0. numexpr 2.7.3. numpy 1.26.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. plotly 5.14.1. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pydot 1.4.2. pygments 2.15.1. pyparsing 3.0.9. pyteomics NA. pytz 2023.3.post1. scipy 1.13.0. session_info 1.0.0. setuptools 67.7.2. setuptools_scm NA. six 1.16.0. sklearn 1.2.2. stack_data 0.6.2. sympy 1.11.1. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.11.2. torch 2.1.1. torchgen NA. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. wcwidth 0.2.6. xxhash NA. yaml 5.4.1. zarr 2.14.2. zc NA. zipp NA. zoneinfo NA. -----. Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:17:34) [Clang 14.0.6 ]. macOS-14.4.1-x86_64-i386-64bit. -----. Session information updated at 2024-05-15 18:46. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3063:441,integrability,filter,filter,441,"sc.get.aggregate summary statistics; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be nice if `sc.get.aggregate` provided a way to compute summary statistics and put them in `.obs` of the aggregated AnnData object. . Most important would be for me to store the number of cells per aggregated sample, for being able to filter out samples below a certain threshold. . Not even sure if there are other metrics that are relevant, but in the most general case it would take a callback function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/issues/3063:109,modifiability,paramet,parameters,109,"sc.get.aggregate summary statistics; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. It would be nice if `sc.get.aggregate` provided a way to compute summary statistics and put them in `.obs` of the aggregated AnnData object. . Most important would be for me to store the number of cells per aggregated sample, for being able to filter out samples below a certain threshold. . Not even sure if there are other metrics that are relevant, but in the most general case it would take a callback function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/pull/3064:117,modifiability,extens,extensions,117,"Import types only in `if TYPE_CHECKING` blocks; this allows us to just import stuff from `typing` instead of `typing-extensions`, so we can use `Self` and friends",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3064
https://github.com/scverse/scanpy/pull/3065:94,deployability,releas,released,94,"Upper-bound numpy below 2 for now; Once https://github.com/lmcinnes/pynndescent/issues/241 is released, we should be able to get numpy 2 compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3065
https://github.com/scverse/scanpy/pull/3065:137,interoperability,compatib,compatibility,137,"Upper-bound numpy below 2 for now; Once https://github.com/lmcinnes/pynndescent/issues/241 is released, we should be able to get numpy 2 compatibility.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3065
https://github.com/scverse/scanpy/issues/3068:596,availability,error,errors,596,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:742,availability,Error,Error,742,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:800,availability,toler,tolerance,800,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:190,deployability,version,version,190,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:451,deployability,build,buildId,451,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:469,deployability,log,logs,469,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1370,deployability,Version,Versions,1370,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1404,deployability,Version,Version,1404,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:190,integrability,version,version,190,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1370,integrability,Version,Versions,1370,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1404,integrability,Version,Version,1404,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1989,integrability,wrap,wrapt,1989,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:840,interoperability,Mismatch,Mismatched,840,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:190,modifiability,version,version,190,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1370,modifiability,Version,Versions,1370,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1396,modifiability,Pac,Package,1396,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1404,modifiability,Version,Version,1404,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1869,modifiability,extens,extensions,1869,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:596,performance,error,errors,596,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:742,performance,Error,Error,742,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:800,reliability,toleran,tolerance,800,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:810,reliability,rto,rtol,810,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:16,safety,Test,Test,16,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:469,safety,log,logs,469,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:596,safety,error,errors,596,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:742,safety,Error,Error,742,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:469,security,log,logs,469,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1548,security,session,session-info,1548,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:16,testability,Test,Test,16,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:469,testability,log,logs,469,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:767,testability,Assert,AssertionError,767,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:150,usability,confirm,confirmed,150,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:233,usability,confirm,confirmed,233,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:596,usability,error,errors,596,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:655,usability,Minim,Minimal,655,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:742,usability,Error,Error,742,"Broken Scrublet Test; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1822,usability,tool,toolz,1822,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/issues/3068:1930,usability,learn,learn,1930,"hese conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Both https://github.com/scverse/scanpy/commit/23c20bc4dd3b1a1e5432ad4e23f56cf5efcf7ebe and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&s=96ac2280-8cb4-5df5-99de-dd2da759617d show errors from scrublet which I cannot reproduce locally. ### Minimal code sample. ```python. See `test_scrublet_data` under `anndata_dev`. ```. ### Error output. ```pytb. E AssertionError: . E Not equal to tolerance rtol=1e-15, atol=1e-15. E . E Mismatched elements: 1 / 200 (0.5%). E Max absolute difference: 0.0126501664. E Max relative difference: 0.1823112224. E x: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... E y: array([0.033079, 0.039326, 0.047022, 0.069388, 0.047022, 0.033079,. E 0.069388, 0.019841, 0.069388, 0.069388, 0.069388, 0.039326,. E 0.033079, 0.149254, 0.047022, 0.056738, 0.047022, 0.023555,... ```. ### Versions. <details>. ```. Package Version. ----------------- -------------------------. anndata 0.11.0.dev114+g105f354. annoy 1.17.3. scipy 1.13.0. scprep 1.1.0. seaborn 0.13.2. session-info 1.0.0. setuptools 69.5.1. setuptools-scm 8.1.0. six 1.16.0. sniffio 1.3.1. sortedcontainers 2.4.0. sparse 0.16.0a6. statsmodels 0.14.2. stdlib-list 0.10.0. tasklogger 1.2.0. tblib 3.0.0. texttable 1.7.0. textual 0.60.1. threadpoolctl 3.5.0. tifffile 2024.5.10. toolz 0.12.1. tornado 6.4. tqdm 4.66.4. typing-extensions 4.12.0rc1. tzdata 2024.1. uc-micro-py 1.0.3. umap-learn 0.5.6. urllib3 2.2.1. uv 0.1.44. virtualenv 20.26.2. wrapt 1.16.0. zarr 2.18.1. zict 3.0.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3068
https://github.com/scverse/scanpy/pull/3069:31,availability,failur,failure,31,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:31,deployability,fail,failure,31,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:471,deployability,releas,release,471,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:496,deployability,Releas,Release,496,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:31,performance,failur,failure,31,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:31,reliability,fail,failure,31,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:26,safety,test,test,26,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:259,safety,review,review,259,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:373,safety,Test,Tests,373,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:26,testability,test,test,26,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:259,testability,review,review,259,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:373,testability,Test,Tests,373,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:110,usability,guid,guidelines,110,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:141,usability,guid,guide,141,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:237,usability,workflow,workflow,237,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:343,usability,Help,Helps,343,Upload scrublet scores on test failure; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Helps debugging #3068 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [ ] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/issues/3070:0,availability,Error,Error,0,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:852,availability,error,error,852,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6127,availability,Error,Error,6127,"\GSE148071_RAW\GSM4453609_P34_exp.txt.gz').T. alldata = lung_ti_p2.concatenate(lung_tm_p2,. lung_ti1_P3,lung_tm1_P3,lung_ti2_P3,lung_tm2_P3,. lung_ti_p4,lung_ts1_p4,lung_ts2_p4,. lung_P2, lung_P5, lung_P8, lung_P9,. lung_P13, lung_P16,. lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,. lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,. batch_categories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11096,availability,mask,mask,11096,"_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if neede",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11137,availability,mask,mask,11137,"305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11156,availability,mask,mask,11156,"r('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeErr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11233,availability,mask,mask,11233,"ans, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11238,availability,mask,mask,11238,"bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11488,availability,mask,mask,11488,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11583,availability,mask,mask,11583,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11656,availability,mask,mask,11656,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11661,availability,mask,mask,11661,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11762,availability,mask,mask,11762,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11925,availability,mask,mask,11925,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:12032,availability,mask,mask,12032,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:12124,availability,mask,mask,12124,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:195,deployability,version,version,195,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:710,deployability,compos,composition,710,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6485,deployability,log,log-transformed,6485,"egories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8050,deployability,version,version,8050,"mData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8306,deployability,log,log,8306,"ional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8322,deployability,log,logged,8322,"eturn fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8393,deployability,log,logged,8393,"= args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8425,deployability,log,logged,8425,"all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9113,deployability,fail,failed,9113,"_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:12213,deployability,Version,Versions,12213,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:487,energy efficiency,profil,profiling,487,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:3135,energy efficiency,cloud,cloud,3135,"e_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/developer/article/2385592. lung_ti_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047637_P4-2T1_matrix.tsv.gz')).T. # lung_ni_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047638_P4-2T2_matrix.tsv.gz')).T. lung_ts1_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047639_P4-2N_matrix.tsv.gz')).T. lung_ts2_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047640_P4-1T_matrix.tsv.gz')).T. # lung_ns_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047641_P4-1N_matrix.tsv.gz')).T. # 240520. lung_P5 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453580_P5_exp.txt.gz').T. lung_P8 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453583_P8_exp.txt.gz').T. lung_P16 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453591_P16_exp.txt.gz').T. lung_P24 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453599_P24_exp.txt.gz').T. lung_P28 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453603_P28_exp.txt.gz').",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:10315,energy efficiency,core,core,10315,"toff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:10703,energy efficiency,core,core,10703,"llowing quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11012,energy efficiency,core,core,11012,"l\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11412,energy efficiency,core,core,11412,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11456,energy efficiency,reduc,reduction,11456,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11846,energy efficiency,core,core,11846,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:195,integrability,version,version,195,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6489,integrability,transform,transformed,6489,"ories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:7151,integrability,wrap,wrapper,7151," of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:7204,integrability,wrap,wraps,7204,"let. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8050,integrability,version,version,8050,"mData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8552,integrability,filter,filtered,8552,"crublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8680,integrability,wrap,wrapper,8680,"ling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8733,integrability,wrap,wraps,8733,"form, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gen",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:12213,integrability,Version,Versions,12213,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:506,interoperability,heterogen,heterogeneity,506,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:734,interoperability,architectur,architecture,734,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6489,interoperability,transform,transformed,6489,"ories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:7151,interoperability,wrapper,wrapper,7151," of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8680,interoperability,wrapper,wrapper,8680,"ling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:195,modifiability,version,version,195,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:710,modifiability,compos,composition,710,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6283,modifiability,pac,packages,6283,",lung_ts1_p4,lung_ts2_p4,. lung_P2, lung_P5, lung_P8, lung_P9,. lung_P13, lung_P16,. lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,. lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,. batch_categories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6520,modifiability,variab,variable,6520,"TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6578,modifiability,pac,packages,6578,"TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:7087,modifiability,pac,packages,7087,"s removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:7495,modifiability,pac,packages,7495,"d. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8050,modifiability,version,version,8050,"mData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8173,modifiability,pac,packages,8173,"ible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8616,modifiability,pac,packages,8616,"_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9024,modifiability,pac,packages,9024,"ct from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9295,modifiability,layer,layer,9295,"s needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9301,modifiability,layer,layer,9301,"s log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9435,modifiability,layer,layer,9435,"ighly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9441,modifiability,layer,layer,9441,"variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9547,modifiability,pac,packages,9547," filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9654,modifiability,layer,layer,9654,"in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramDa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:10025,modifiability,pac,packages,10025,"ges\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:40",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:10299,modifiability,pac,packages,10299,"yer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:10687,modifiability,pac,packages,10687," all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:10996,modifiability,pac,packages,10996,"aconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavor, n_bins). 304 else:. 305 raise ValueError('`flavor` needs to be ""seurat"" or ""cell_ranger""'). --> 307 return pd.cut(means, bins=bins). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.cop",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11396,modifiability,pac,packages,11396,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:11830,modifiability,pac,packages,11830,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:12213,modifiability,Version,Versions,12213,"vs\dl\lib\site-packages\pandas\core\reshape\tile.py:258, in cut(x, bins, right, labels, retbins, precision, include_lowest, duplicates, ordered). 255 if sz == 0:. 256 raise ValueError(""Cannot cut empty array""). --> 258 rng = (nanops.nanmin(x), nanops.nanmax(x)). 259 mn, mx = (mi + 0.0 for mi in rng). 261 if np.isinf(mn) or np.isinf(mx):. 262 # GH 24314. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:147, in bottleneck_switch.__call__.<locals>.f(values, axis, skipna, **kwds). 145 result = alt(values, axis=axis, skipna=skipna, **kwds). 146 else:. --> 147 result = alt(values, axis=axis, skipna=skipna, **kwds). 149 return result. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:404, in _datetimelike_compat.<locals>.new_func(values, axis, skipna, mask, **kwargs). 401 if datetimelike and mask is None:. 402 mask = isna(values). --> 404 result = func(values, axis=axis, skipna=skipna, mask=mask, **kwargs). 406 if datetimelike:. 407 result = _wrap_results(result, orig_values.dtype, fill_value=iNaT). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:1089, in _nanminmax.<locals>.reduction(values, axis, skipna, mask). 1086 if values.size == 0:. 1087 return _na_for_min_count(values, axis). -> 1089 values, mask = _get_values(. 1090 values, skipna, fill_value_typ=fill_value_typ, mask=mask. 1091 ). 1092 result = getattr(values, meth)(axis). 1093 result = _maybe_null_out(result, axis, mask, values.shape). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\pandas\core\nanops.py:316, in _get_values(values, skipna, fill_value, fill_value_typ, mask). 314 if datetimelike or _na_ok_dtype(dtype):. 315 values = values.copy(). --> 316 np.putmask(values, mask, fill_value). 317 else:. 318 # np.where will promote if needed. 319 values = np.where(~mask, values, fill_value). TypeError: putmask: first argument must be an array. ```. ### Versions. <details>. ```. scanpy 1.10.1. numpy 1.26.0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:0,performance,Error,Error,0,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:487,performance,profil,profiling,487,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:852,performance,error,error,852,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:1043,performance,cach,cache,1043,"e these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:1199,performance,cach,cache,1199," of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:1355,performance,cach,cache,1355,"ove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:1511,performance,cach,cache,1511,"neity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:1684,performance,cach,cache,1684,"terization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:1838,performance,cach,cache,1838,"ere was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:1994,performance,cach,cache,1994,"6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:2150,performance,cach,cache,2150,"6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:2306,performance,cach,cache,2306,"6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/developer/article/2385592. lung_ti_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047637_P4-2T1_matrix.tsv.gz')).T. # lung_ni_p4 = s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:2462,performance,cach,cache,2462,"6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/developer/article/2385592. lung_ti_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047637_P4-2T1_matrix.tsv.gz')).T. # lung_ni_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047638_P4-2T2_matrix.tsv.gz')).T. lung_ts1_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM60",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:2618,performance,cach,cache,2618,"200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/developer/article/2385592. lung_ti_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047637_P4-2T1_matrix.tsv.gz')).T. # lung_ni_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047638_P4-2T2_matrix.tsv.gz')).T. lung_ts1_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047639_P4-2N_matrix.tsv.gz')).T. lung_ts2_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047640_P4-1T_matrix.tsv.gz')).T. # lung_ns_p4 = sc.read_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:2774,performance,cach,cache,2774,"0972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/developer/article/2385592. lung_ti_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047637_P4-2T1_matrix.tsv.gz')).T. # lung_ni_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047638_P4-2T2_matrix.tsv.gz')).T. lung_ts1_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047639_P4-2N_matrix.tsv.gz')).T. lung_ts2_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047640_P4-1T_matrix.tsv.gz')).T. # lung_ns_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047641_P4-1N_matrix.tsv.gz')).T. # 240520. lung_P5 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453580_P",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:2930,performance,cach,cache,2930,"0972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/developer/article/2385592. lung_ti_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047637_P4-2T1_matrix.tsv.gz')).T. # lung_ni_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047638_P4-2T2_matrix.tsv.gz')).T. lung_ts1_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047639_P4-2N_matrix.tsv.gz')).T. lung_ts2_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047640_P4-1T_matrix.tsv.gz')).T. # lung_ns_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047641_P4-1N_matrix.tsv.gz')).T. # 240520. lung_P5 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453580_P5_exp.txt.gz').T. lung_P8 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453583_P8_exp.txt.gz').T. lung_P16 = sc.read_text('D:\\\\GSE148071_R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:3086,performance,cach,cache,3086,"0972_RAW', 'GSM6047630_P2_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047631_P8_T1_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm1_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047634_P8_T1_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047633_P8_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047636_P8_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_ti2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047632_P8_T2_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm2_P3 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047635_P8_T2_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # https://cloud.tencent.com/developer/article/2385592. lung_ti_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047637_P4-2T1_matrix.tsv.gz')).T. # lung_ni_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047638_P4-2T2_matrix.tsv.gz')).T. lung_ts1_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047639_P4-2N_matrix.tsv.gz')).T. lung_ts2_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047640_P4-1T_matrix.tsv.gz')).T. # lung_ns_p4 = sc.read_text(os.path.join(root, 'GSE200972_RAW', 'GSM6047641_P4-1N_matrix.tsv.gz')).T. # 240520. lung_P5 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453580_P5_exp.txt.gz').T. lung_P8 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453583_P8_exp.txt.gz').T. lung_P16 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453591_P16_exp.txt.gz').T. lung_P24 = sc.read_text('D:\\\\GSE148071_RAW\GSM4453599_P24_exp.txt.gz').T. lung_P28 = sc.read_text('D:\\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6127,performance,Error,Error,6127,"\GSE148071_RAW\GSM4453609_P34_exp.txt.gz').T. alldata = lung_ti_p2.concatenate(lung_tm_p2,. lung_ti1_P3,lung_tm1_P3,lung_ti2_P3,lung_tm2_P3,. lung_ti_p4,lung_ts1_p4,lung_ts2_p4,. lung_P2, lung_P5, lung_P8, lung_P9,. lung_P13, lung_P16,. lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,. lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,. batch_categories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:9113,reliability,fail,failed,9113,"_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 654 ). File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:281, in _highly_variable_genes_single_batch(adata, layer, cutoff, n_bins, flavor). 279 # all of the following quantities are ""per-gene"" here. 280 df = pd.DataFrame(dict(zip([""means"", ""dispersions""], (mean, dispersion)))). --> 281 df[""mean_bin""] = _get_mean_bins(df[""means""], flavor, n_bins). 282 disp_stats = _get_disp_stats(df, flavor). 284 # actually do the normalization. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:307, in _get_mean_bins(means, flavo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:0,safety,Error,Error,0,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:852,safety,error,error,852,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6127,safety,Error,Error,6127,"\GSE148071_RAW\GSM4453609_P34_exp.txt.gz').T. alldata = lung_ti_p2.concatenate(lung_tm_p2,. lung_ti1_P3,lung_tm1_P3,lung_ti2_P3,lung_tm2_P3,. lung_ti_p4,lung_ts1_p4,lung_ts2_p4,. lung_P2, lung_P5, lung_P8, lung_P9,. lung_P13, lung_P16,. lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,. lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,. batch_categories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6485,safety,log,log-transformed,6485,"egories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8018,safety,input,input,8018," alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8306,safety,log,log,8306,"ional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8322,safety,log,logged,8322,"eturn fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8393,safety,log,logged,8393,"= args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8425,safety,log,logged,8425,"all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6485,security,log,log-transformed,6485,"egories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8306,security,log,log,8306,"ional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8322,security,log,logged,8322,"eturn fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8393,security,log,logged,8393,"= args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8425,security,log,logged,8425,"all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6485,testability,log,log-transformed,6485,"egories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\sit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6783,testability,Trace,Traceback,6783,"_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8306,testability,log,log,8306,"ional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8322,testability,log,logged,8322,"eturn fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8393,testability,log,logged,8393,"= args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8425,testability,log,logged,8425,"all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8470,testability,Simul,Simulate,8470,"da3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py:648, in highly_variable_genes(***failed resolving arguments***). 645 del min_disp, max_disp, min_mean, max_mean, n_top_genes. 647 if batch_key is None:. --> 648 df = _highly_variable_genes_single_batch(. 649 adata, layer=layer, cutoff=cutoff, n_bins=n_bins, flavor=flavor. 650 ). 651 else:. 652 df = _highly_variable_genes_batched(. 653 adata, batch_key, layer=layer, cutoff=cutoff, n_bins=n_bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:0,usability,Error,Error,0,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:155,usability,confirm,confirmed,155,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:238,usability,confirm,confirmed,238,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:852,usability,error,error,852,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:879,usability,Minim,Minimal,879,"Error in running scrublet; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Hi, I am running the Scrublet function to remove doublets. the annadata was generated by concat several samples from two articles:. [1] Wu F, Fan J, He Y, et al. Single-cell profiling of tumor heterogeneity and the microenvironment in advanced non-small cell lung cancer[J]. Nature Communications, 2021, 12(1): 2540. [2] Wang Y, Chen D, Liu Y, et al. Multidirectional characterization of cellular composition and spatial architecture in human multiple primary lung cancers[J]. Cell Death & Disease, 2023, 14(7): 462. However, there was an error I cann't handle. ### Minimal code sample. ```python. # 240520. # lung_ti_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047623_P1_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_tm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047624_P1_N_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_nm_p1 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047626_P1_N_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # 240520 . lung_ti_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047627_P2_T_R_I'), var_names='gene_symbols', cache=True, cache_compression='gzip'). lung_tm_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047629_P2_T_R_M'), var_names='gene_symbols', cache=True, cache_compression='gzip'). # lung_ni_p2 = sc.read_10x_mtx(os.path.join(root, 'GSE200972_RAW', 'GSM6047628_P2_N_R_I'), var_names='gene_symbols', cache=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6127,usability,Error,Error,6127,"\GSE148071_RAW\GSM4453609_P34_exp.txt.gz').T. alldata = lung_ti_p2.concatenate(lung_tm_p2,. lung_ti1_P3,lung_tm1_P3,lung_ti2_P3,lung_tm2_P3,. lung_ti_p4,lung_ts1_p4,lung_ts2_p4,. lung_P2, lung_P5, lung_P8, lung_P9,. lung_P13, lung_P16,. lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,. lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,. batch_categories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6336,usability,User,UserWarning,6336,"ung_P9,. lung_P13, lung_P16,. lung_P20, lung_P21, lung_P24, lung_P28, lung_P29,. lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,. batch_categories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_al",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:6383,usability,User,UserWarning,6383,"1, lung_P24, lung_P28, lung_P29,. lung_P32, lung_P33, lung_P34, lung_P35, lung_P38, lung_P39,. batch_categories = [""TI-P2"", ""TM-P2"",. ""TI1-P3"", 'TM1-P3', 'TI2-P3', 'TM2-P3',. ""TI-P4"",'TS1-P4','TS2-P4',. 'lung_P2', 'lung_P5', 'lung_P8', 'lung_P9',. 'lung_P13', 'lung_P16',. 'lung_P20', 'lung_P21', 'lung_P24', 'lung_P28', 'lung_P29',. 'lung_P32', 'lung_P33', 'lung_P34', 'lung_P35', 'lung_P38', 'lung_P39'],. join='outer'). print('Begin of post doublets removal and QC plot'). sc.pp.scrublet(alldata, n_neighbors=10). alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). n1 = alldata.shape[0]. print(f'Cells retained after scrublet: {n1}, {n0-n1} removed.'). print(f'End of post doublets removal and QC plots.'). ```. ### Error output. ```pytb. Begin of post doublets removal and QC plot. Running Scrublet. normalizing counts per cell. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_normalization.py:233: UserWarning: Some cells have zero counts. warn(UserWarning(""Some cells have zero counts"")). finished (0:00:00). WARNING: adata.X seems to be already log-transformed. extracting highly variable genes. C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_simple.py:377: RuntimeWarning: invalid value encountered in log1p. np.log1p(X, out=X). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[59], line 2. 1 print('Begin of post doublets removal and QC plot'). ----> 2 sc.pp.scrublet(alldata, n_neighbors=10). 3 alldata = alldata[alldata.obs['predicted_doublet']==False, :].copy(). 4 n1 = alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, arg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3070:8018,usability,input,input,8018," alldata.shape[0]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:282, in scrublet(adata, adata_sim, batch_key, sim_doublet_ratio, expected_doublet_rate, stdev_doublet_rate, synthetic_doublet_umi_subsampling, knn_dist_metric, normalize_variance, log_transform, mean_center, n_prin_comps, use_approx_neighbors, get_doublet_neighbor_parents, n_neighbors, threshold, verbose, copy, random_state). 279 adata.uns[""scrublet""][""batched_by""] = batch_key. 281 else:. --> 282 scrubbed = _run_scrublet(adata_obs, adata_sim). 284 # Copy outcomes to input object from our processed version. 286 adata.obs[""doublet_score""] = scrubbed[""obs""][""doublet_score""]. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\scanpy\preprocessing\_scrublet\__init__.py:204, in scrublet.<locals>._run_scrublet(ad_obs, ad_sim). 201 # HVG process needs log'd data. 203 logged = pp.log1p(ad_obs, copy=True). --> 204 pp.highly_variable_genes(logged). 205 ad_obs = ad_obs[:, logged.var[""highly_variable""]].copy(). 207 # Simulate the doublets based on the raw expressions from the normalised. 208 # and filtered object. File C:\ProgramData\Anaconda3\envs\dl\lib\site-packages\legacy_api_wrap\__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File C:\ProgramData\Anaconda3\envs\dl\lib\si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3070
https://github.com/scverse/scanpy/issues/3071:0,availability,error,error,0,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:460,availability,Error,Error,460,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:191,deployability,version,version,191,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:493,deployability,Version,Versions,493,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:524,deployability,instal,installed,524,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:191,integrability,version,version,191,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:493,integrability,Version,Versions,493,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:191,modifiability,version,version,191,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:493,modifiability,Version,Versions,493,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:515,modifiability,pac,packages,515,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:0,performance,error,error,0,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:460,performance,Error,Error,460,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:0,safety,error,error,0,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:460,safety,Error,Error,460,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:0,usability,error,error,0,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:151,usability,confirm,confirmed,151,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:234,usability,confirm,confirmed,234,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:404,usability,Minim,Minimal,404,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/issues/3071:460,usability,Error,Error,460,"error in readwrite.py; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? On import, I'm getting:. `scanpy/readwrite.py:1015 ) as t, ^ SyntaxError: invalid syntax`. ### Minimal code sample. ```python. import scanpy. ```. ### Error output. _No response_. ### Versions. python 3.8, packages installed through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3071
https://github.com/scverse/scanpy/pull/3072:35,availability,error,errors,35,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:110,availability,error,errors,110,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:35,performance,error,errors,35,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:110,performance,error,errors,110,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:35,safety,error,errors,35,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:110,safety,error,errors,110,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:35,usability,error,errors,35,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:64,usability,support,supported,64,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:110,usability,error,errors,110,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/pull/3072:139,usability,support,supported,139,Backport PR #3048: (feat): raising errors where `backed` is not supported; Backport PR #3048: (feat): raising errors where `backed` is not supported,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3072
https://github.com/scverse/scanpy/issues/3073:1226,availability,slo,slot,1226,"sion of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1421,availability,Error,Error,1421,"d then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:29,deployability,log,log,29,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:225,deployability,version,version,225,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:708,deployability,log,lognormized,708,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1329,deployability,log,logaritmize,1329,"ppened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1454,deployability,Version,Versions,1454,"en used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1726,energy efficiency,cloud,cloudpickle,1726,"y adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:225,integrability,version,version,225,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:443,integrability,filter,filtering,443,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1454,integrability,Version,Versions,1454,"en used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:2637,interoperability,platform,platformdirs,2637,otli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 2.4.7. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.3.0. tlz 0.12.3. toolz 0.12.1. tornado 6.3.3. traitlets 5.14.1. typing_extensions NA. uri_template NA. urllib3 1.26.15. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.2. zoneinfo NA. zope NA. zstandard 0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:225,modifiability,version,version,225,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:857,modifiability,layer,layers,857,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1454,modifiability,Version,Versions,1454,"en used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1869,modifiability,deco,decorator,1869,"nt to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pyde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:2544,modifiability,pac,packaging,2544,0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 2.4.7. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.3.0. tlz 0.12.3. toolz 0.12.1. tornado 6.3.3. traitlets 5.14.1. typing_extensions NA. uri_template NA. urllib3 1.26.15. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:3772,modifiability,pac,packaged,3772,".1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 2.4.7. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.3.0. tlz 0.12.3. toolz 0.12.1. tornado 6.3.3. traitlets 5.14.1. typing_extensions NA. uri_template NA. urllib3 1.26.15. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.2. zoneinfo NA. zope NA. zstandard 0.22.0. -----. IPython 8.15.0. jupyter_client 8.6.0. jupyter_core 5.7.1. jupyterlab 4.1.1. notebook 7.1.0. -----. Python 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1127,performance,cach,cache,1127,"this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1421,performance,Error,Error,1421,"d then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1623,performance,bottleneck,bottleneck,1623,"To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1226,reliability,slo,slot,1226,"sion of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:29,safety,log,log,29,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:708,safety,log,lognormized,708,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:798,safety,avoid,avoid,798,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1329,safety,log,logaritmize,1329,"ppened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1421,safety,Error,Error,1421,"d then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1904,safety,except,exceptiongroup,1904,"heck the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynnd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:15,security,modif,modified,15,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:29,security,log,log,29,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:708,security,log,lognormized,708,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1329,security,log,logaritmize,1329,"ppened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1652,security,certif,certifi,1652," the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:2068,security,iso,isoduration,2068,"ture_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 2.4.7. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_valida",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:3226,security,soc,socks,3226,".1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 2.4.7. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.3.0. tlz 0.12.3. toolz 0.12.1. tornado 6.3.3. traitlets 5.14.1. typing_extensions NA. uri_template NA. urllib3 1.26.15. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.2. zoneinfo NA. zope NA. zstandard 0.22.0. -----. IPython 8.15.0. jupyter_client 8.6.0. jupyter_core 5.7.1. jupyterlab 4.1.1. notebook 7.1.0. -----. Python 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:29,testability,log,log,29,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:708,testability,log,lognormized,708,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:880,testability,understand,understand,880,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1329,testability,log,logaritmize,1329,"ppened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlit",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:185,usability,confirm,confirmed,185,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:268,usability,confirm,confirmed,268,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:809,usability,behavi,behavior,809,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:974,usability,Minim,Minimal,974,"Adata.raw gets modified upon log normalization of adata; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? I am working with a set of 2 10x scRNA samples. I read them, concatenated them and then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1421,usability,Error,Error,1421,"d then I did basic filtering. I then used ""adata.raw = adata"" to freeze the counts on adata.raw before proceding. Then I ran: . ```. sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). ```. To my surprise, when I check the adata.raw I see that the values have been also lognormized (and not only adata). . Is that how it is supposed to be? Is there any way to avoid this behavior ? I know I can store the raw counts in layers, I just want to understand how it works. . To check the data I used : . `print(adata.raw.X[1:10,1:10]) `. ### Minimal code sample. ```python. #read the data. Data1_adata= sc.read_10x_mtx(. '/Data_1/filtered_feature_bc_matrix', . var_names='gene_symbols', index). cache=True) . #concatenate. adata = Data1_adata.concatenate(Data2_adata). # save raw counts in raw slot. adata.raw = adata . # normalize to depth 10 000. sc.pp.normalize_total(adata, target_sum=1e4). # logaritmize. sc.pp.log1p(adata). #check adata.raw . print(adata.raw.X[1:10,1:10]). ```. ### Error output. _No response_. ### Versions. <details>. ```. anndata 0.10.7. scanpy 1.10.0. -----. PIL 8.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. backcall 0.2.0. bottleneck 1.3.7. brotli NA. certifi 2024.02.02. cffi 1.16.0. chardet 5.2.0. charset_normalizer 3.3.2. cloudpickle 3.0.0. colorama 0.4.6. comm 0.2.1. cycler 0.12.1. cython_runtime NA. cytoolz 0.12.3. dask 2024.2.0. dateutil 2.8.2. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:3358,usability,tool,toolz,3358,".1. exceptiongroup 1.2.0. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.7.0. idna 3.6. igraph 0.11.4. importlib_resources NA. ipykernel 6.29.2. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.9.0. jupyter_server 2.12.5. jupyterlab_server 2.25.3. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.40.0. louvain 0.8.0. lz4 4.3.3. markupsafe 2.1.5. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. nt NA. numba 0.57.1. numexpr 2.8.7. numpy 1.23.0. overrides NA. packaging 23.2. pandas 1.5.3. parso 0.8.3. patsy 0.5.6. pickleshare 0.7.5. pkg_resources NA. platformdirs 4.2.0. plotly 5.19.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.11. pyparsing 2.4.7. pythoncom NA. pythonjsonlogger NA. pytz 2024.1. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. seaborn 0.13.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 3.0.0. texttable 1.7.0. threadpoolctl 3.3.0. tlz 0.12.3. toolz 0.12.1. tornado 6.3.3. traitlets 5.14.1. typing_extensions NA. uri_template NA. urllib3 1.26.15. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.1. zipp NA. zmq 25.1.2. zoneinfo NA. zope NA. zstandard 0.22.0. -----. IPython 8.15.0. jupyter_client 8.6.0. jupyter_core 5.7.1. jupyterlab 4.1.1. notebook 7.1.0. -----. Python 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:29:04) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22631-SP0. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3074:582,availability,error,error,582,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:774,availability,error,errors,774,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1379,availability,Error,Error,1379,"`ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:233,deployability,version,version,233,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:824,deployability,log,logging,824,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:3329,deployability,Version,Versions,3329,", neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:5294,deployability,updat,updated,5294,"<details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-05-22 17:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:233,integrability,version,version,233,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:588,integrability,messag,message,588,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1773,integrability,wrap,wrapper,1773,"ors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1826,integrability,wrap,wraps,1826,"ng.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:3329,integrability,Version,Versions,3329,", neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:588,interoperability,messag,message,588,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1773,interoperability,wrapper,wrapper,1773,"ors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:4306,interoperability,platform,platformdirs,4306,"e_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-05",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:233,modifiability,version,version,233,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1709,modifiability,pac,packages,1709," import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:2116,modifiability,pac,packages,2116,". adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if isspa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:2489,modifiability,pac,packages,2489," Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. bro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:2736,modifiability,pac,packages,2736,"__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:2998,modifiability,pac,packages,2998,"_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:3329,modifiability,Version,Versions,3329,", neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometh",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:3656,modifiability,deco,decorator,3656,"m[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_valid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:4244,modifiability,pac,packaging,4244,"red:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:5150,modifiability,pac,packaged,5150,"<details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-05-22 17:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:582,performance,error,error,582,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:774,performance,error,errors,774,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1379,performance,Error,Error,1379,"`ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:582,safety,error,error,582,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:774,safety,error,errors,774,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:824,safety,log,logging,824,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1379,safety,Error,Error,1379,"`ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:5294,safety,updat,updated,5294,"<details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-05-22 17:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:824,security,log,logging,824,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:3504,security,certif,certifi,3504,"ls/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:3810,security,iso,isoduration,3810,"f._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:4798,security,soc,socks,4798,"<details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-05-22 17:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:5274,security,Session,Session,5274,"<details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-05-22 17:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:5294,security,updat,updated,5294,"<details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0. kiwisolver 1.4.5. legacy_api_wrap NA. leidenalg 0.10.2. llvmlite 0.42.0. markupsafe 2.1.5. matplotlib 3.8.4. matplotlib_inline 0.1.7. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. numba 0.59.1. numpy 1.26.4. overrides NA. packaging 24.0. pandas 1.5.3. parso 0.8.4. pickleshare 0.7.5. platformdirs 4.2.0. prometheus_client NA. prompt_toolkit 3.0.42. psutil 5.9.8. pure_eval 0.2.2. pycparser 2.22. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.17.2. pynndescent 0.5.12. pyparsing 3.1.2. pythonjsonlogger NA. pytz 2024.1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.4.2. sniffio 1.3.1. socks 1.7.1. stack_data 0.6.2. texttable 1.7.0. threadpoolctl 3.4.0. tornado 6.4. tqdm 4.66.2. traitlets 5.14.3. umap 0.5.5. uri_template NA. urllib3 2.2.1. wcwidth 0.2.13. webcolors 1.13. websocket 1.7.0. yaml 6.0.1. zmq 26.0.2. -----. IPython 8.22.2. jupyter_client 8.6.1. jupyter_core 5.7.2. jupyterlab 4.1.6. notebook 7.1.3. -----. Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:38:13) [GCC 12.3.0]. Linux-5.4.0-150-generic-x86_64-with-glibc2.27. -----. Session information updated at 2024-05-22 17:19. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:824,testability,log,logging,824,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1494,testability,Trace,Traceback,1494,"t.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:193,usability,confirm,confirmed,193,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:276,usability,confirm,confirmed,276,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:582,usability,error,error,582,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:661,usability,Minim,Minimal,661,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:774,usability,error,errors,774,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:810,usability,hint,hints,810,"AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the main branch of scanpy. ### What happened? Attempted label transfer using `ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:1379,usability,Error,Error,1379,"`ingest`, using the example code on the [docs page](https://scanpy.readthedocs.io/en/1.10.x/generated/scanpy.tl.ingest.html). The fix is trivial (you must run `sc.pp.pca(adata_ref)` as well), but the error message is cryptic so I got stuck for a bit! I'll create the PR too. ### Minimal code sample. ```python. import scanpy as sc. import pandas as pd. sc.settings.verbosity = 1 # verbosity: errors (0), warnings (1), info (2), hints (3). sc.logging.print_versions(). sc.settings.set_figure_params(dpi=80, frameon=False, figsize=(3, 3), facecolor=""white""). adata_ref = sc.datasets.pbmc3k_processed(). adata = sc.datasets.pbmc68k_reduced(). var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:2132,usability,tool,tools,2132,"[:, var_names]. # start from scratch. del adata.obs[""louvain""]. adata.uns = {}. adata_ref.uns = {}. # example code for ingest function:. sc.pp.neighbors(adata_ref). sc.tl.umap(adata_ref). sc.tl.ingest(adata, adata_ref, obs=""louvain""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:2505,usability,tool,tools,2505,"t recent call last). Cell In[11], line 23. 21 sc.pp.neighbors(adata_ref). 22 sc.tl.umap(adata_ref). ---> 23 sc.tl.ingest(adata, adata_ref, obs=""louvain""). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/legacy_api_wrap/__init__.py:80, in legacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. cert",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:2752,usability,tool,tools,2752,"gacy_api.<locals>.wrapper.<locals>.fn_compatible(*args_all, **kw). 77 @wraps(fn). 78 def fn_compatible(*args_all: P.args, **kw: P.kwargs) -> R:. 79 if len(args_all) <= n_positional:. ---> 80 return fn(*args_all, **kw). 82 args_pos: P.args. 83 args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/issues/3074:3014,usability,tool,tools,3014," = args_all[:n_positional], args_all[n_positional:]. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:141, in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 138 labeling_method = labeling_method * len(obs). 140 ing = Ingest(adata_ref, neighbors_key). --> 141 ing.fit(adata). 143 for method in embedding_method:. 144 ing.map_embedding(method). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:404, in Ingest.fit(self, adata_new). 401 self._obsm = _DimDict(adata_new.n_obs, axis=0). 403 self._adata_new = adata_new. --> 404 self._obsm[""rep""] = self._same_rep(). File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:371, in Ingest._same_rep(self). 369 adata = self._adata_new. 370 if self._n_pcs is not None:. --> 371 return self._pca(self._n_pcs). 372 if self._use_rep == ""X"":. 373 return adata.X. File ~/miniconda3/envs/sc/lib/python3.12/site-packages/scanpy/tools/_ingest.py:361, in Ingest._pca(self, n_pcs). 359 X = self._adata_new.X. 360 X = X.toarray() if issparse(X) else X.copy(). --> 361 if self._pca_use_hvg:. 362 X = X[:, self._adata_ref.var[""highly_variable""]]. 363 if self._pca_centered:. AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'. ```. ### Versions. <details>. ```. -----. anndata 0.10.7. scanpy 1.10.1. -----. PIL 10.3.0. anyio NA. arrow 1.3.0. asttokens NA. attr 23.2.0. attrs 23.2.0. babel 2.14.0. brotli 1.1.0. certifi 2024.02.02. cffi 1.16.0. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0. debugpy 1.8.1. decorator 5.1.1. defusedxml 0.7.1. executing 2.0.1. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.7. igraph 0.10.8. ipykernel 6.29.3. ipywidgets 8.1.2. isoduration NA. jedi 0.19.1. jinja2 3.1.3. joblib 1.4.0. json5 0.9.25. jsonpointer 2.4. jsonschema 4.21.1. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.0. jupyterlab_server 2.27.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3074
https://github.com/scverse/scanpy/pull/3075:0,deployability,Updat,Update,0,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:517,deployability,releas,release,517,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:542,deployability,Releas,Release,542,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:0,safety,Updat,Update,0,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:315,safety,review,review,315,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:419,safety,Test,Tests,419,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:0,security,Updat,Update,0,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:315,testability,review,review,315,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:419,testability,Test,Tests,419,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:166,usability,guid,guidelines,166,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:197,usability,guid,guide,197,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:293,usability,workflow,workflow,293,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3075:399,usability,Close,Closes,399,Update ingest example. Fixes `AttributeError: 'Ingest' object has no attribute '_pca_use_hvg'`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074. - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because: trivial change.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3075
https://github.com/scverse/scanpy/pull/3076:1114,deployability,releas,release,1114,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:577,modifiability,variab,variable-genes,577,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:795,modifiability,variab,variable-genes,795,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:15,safety,valid,valid,15,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:305,safety,review,review,305,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:1105,safety,test,tests,1105,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:305,testability,review,review,305,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:1105,testability,test,tests,1105,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:156,usability,guid,guidelines,156,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:187,usability,guid,guide,187,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/pull/3076:283,usability,workflow,workflow,283,"Add `str` as a valid option for the `save` argument in `scanpy.pl.rank_genes_groups`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This is a very small pull request to add `str` to the possible arguments for saving a figure from [`scanpy.pl.rank_genes_groups`][rank-genes-groups]. This addition matches other `save=` arguments, such as from [`scanpy.plotting.highly_variable_genes`][highly-variable-genes], [`sc.plotting.pca_variance_ratio`][pca-variance-ratio], and [`scanpy.plotting.umap`][umap]. [rank-genes-groups]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [highly-variable-genes]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_preprocessing.py. [pca-variance-ratio]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/__init__.py. [umap]: https://github.com/scverse/scanpy/blob/main/scanpy/plotting/_tools/scatterplots.py. I have not included tests or release notes due to the single-line change nature of this pull request",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3076
https://github.com/scverse/scanpy/issues/3077:242,integrability,filter,filter,242,"Only show the genes that have significant statistics; ### What kind of feature would you like to request? New plotting function: A kind of plot you would like to seein `sc.pl`? ### Please describe your wishes. I wonder that whether pl method filter the genes that have p_adjusted values < 0.05 before plotting figures? If not, could you please add one more method to do this? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3077
https://github.com/scverse/scanpy/issues/3077:30,security,sign,significant,30,"Only show the genes that have significant statistics; ### What kind of feature would you like to request? New plotting function: A kind of plot you would like to seein `sc.pl`? ### Please describe your wishes. I wonder that whether pl method filter the genes that have p_adjusted values < 0.05 before plotting figures? If not, could you please add one more method to do this? Thank you very much.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3077
https://github.com/scverse/scanpy/pull/3079:666,deployability,releas,release,666,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
https://github.com/scverse/scanpy/pull/3079:691,deployability,Releas,Release,691,(fix): write out full PCA results when not run before neighbors; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. I think this is a better fix since we were already writing out `X_pca`. The tests seem to pass and `pca` should be idempotent so this really shouldn't break anything (hopefully). <!-- Please check (- [x]) and fill in the following boxes -->. - [x] Closes #3074 . - [x] Tests included or not required because:. <!-- Only check the following box if you did not include release notes -->. - [x] Release notes not necessary because:.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3079
